reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52546968-172.17.0.4-1598498199145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42753,DS-b1d5fbbd-7e72-4c5e-a8ef-b72e38859a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-33128e4f-92f8-4c40-a9d3-70a1b51cb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-774dc58c-2056-47c9-adcc-e0129ee056dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-3c994720-881a-4cc7-bf1a-3f55b94b96de,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-c4164640-17d7-4ed1-bb33-eb2c6866f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-fc21ab19-962d-4fcd-bfc7-5eea38074587,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-4ba97115-a1cd-4594-b151-be55e4f7a429,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-1d5ddeee-2fe0-49b9-8c55-11dcd5174769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52546968-172.17.0.4-1598498199145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42753,DS-b1d5fbbd-7e72-4c5e-a8ef-b72e38859a17,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-33128e4f-92f8-4c40-a9d3-70a1b51cb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-774dc58c-2056-47c9-adcc-e0129ee056dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-3c994720-881a-4cc7-bf1a-3f55b94b96de,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-c4164640-17d7-4ed1-bb33-eb2c6866f009,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-fc21ab19-962d-4fcd-bfc7-5eea38074587,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-4ba97115-a1cd-4594-b151-be55e4f7a429,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-1d5ddeee-2fe0-49b9-8c55-11dcd5174769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125374663-172.17.0.4-1598498374111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-6114c3c7-363c-4873-9b37-75dd8e4da6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-cc084381-9d05-4df0-9471-b9bdcf55d496,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-cc521b87-074c-4773-9210-5c54f77c3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-fe7f1e86-1bd1-46fb-8fda-092580fe1ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-8c4f3187-6e64-4428-b5a7-a3ee7aa8039a,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-f2f3cbc2-394a-4931-898b-0037b0048b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-07c44d9e-7126-41a9-839a-9165b5aa119c,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-60413d9c-b11c-45d1-8158-bf104fe9c97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125374663-172.17.0.4-1598498374111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-6114c3c7-363c-4873-9b37-75dd8e4da6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-cc084381-9d05-4df0-9471-b9bdcf55d496,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-cc521b87-074c-4773-9210-5c54f77c3a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-fe7f1e86-1bd1-46fb-8fda-092580fe1ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-8c4f3187-6e64-4428-b5a7-a3ee7aa8039a,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-f2f3cbc2-394a-4931-898b-0037b0048b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-07c44d9e-7126-41a9-839a-9165b5aa119c,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-60413d9c-b11c-45d1-8158-bf104fe9c97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309813165-172.17.0.4-1598498837057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-85c471ce-74f5-4ef1-a5cf-adbd95e0b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b7f001ed-b3d8-4c3f-b679-154d96e7e231,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-392fb332-fdf2-48ca-bba2-79a0284be957,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-cb462aea-1ed5-4429-ada2-68f676b58b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-074d6333-6838-4274-926f-94f8a279c713,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-768e8c37-3d61-4fa2-930b-35ecdacd390d,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-2ea2b840-fe82-49ad-a72d-66e86204b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-3448587e-baee-46a4-b9c3-f383b96ce82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309813165-172.17.0.4-1598498837057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-85c471ce-74f5-4ef1-a5cf-adbd95e0b22c,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-b7f001ed-b3d8-4c3f-b679-154d96e7e231,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-392fb332-fdf2-48ca-bba2-79a0284be957,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-cb462aea-1ed5-4429-ada2-68f676b58b02,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-074d6333-6838-4274-926f-94f8a279c713,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-768e8c37-3d61-4fa2-930b-35ecdacd390d,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-2ea2b840-fe82-49ad-a72d-66e86204b4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-3448587e-baee-46a4-b9c3-f383b96ce82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204085407-172.17.0.4-1598499610970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-ab858397-a0d5-426d-8dde-7ba8a9a925c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-98461f4b-492b-4e8f-86d1-0b49b40639b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-5373c060-9663-4fcd-bd5e-7913424682ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-34ba4e35-1d50-4743-abae-add7c7024541,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-4a680798-ff74-4875-83ee-dffb18b82d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-1553ab5d-8187-4903-bac5-d190f29343f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-595e01ca-2531-47b3-b5dd-66b3f2d2c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-c43cf086-b790-44bf-a560-2e7d48d27755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204085407-172.17.0.4-1598499610970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-ab858397-a0d5-426d-8dde-7ba8a9a925c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-98461f4b-492b-4e8f-86d1-0b49b40639b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-5373c060-9663-4fcd-bd5e-7913424682ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-34ba4e35-1d50-4743-abae-add7c7024541,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-4a680798-ff74-4875-83ee-dffb18b82d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-1553ab5d-8187-4903-bac5-d190f29343f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-595e01ca-2531-47b3-b5dd-66b3f2d2c18f,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-c43cf086-b790-44bf-a560-2e7d48d27755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199326434-172.17.0.4-1598499802813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-ef0d437c-1807-431d-bb18-de7b5678ee22,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-6968b2f3-93c3-484a-905c-b9152c4f94e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-58a4482d-99a4-40c7-bf55-85582e99bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-62a9e2ab-5e19-4739-b627-905b5361dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-4caa87c6-63d6-4ad3-9a60-c68122b721e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-a55ca9f1-5c30-4315-afff-644782bdcaac,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3049a349-407e-4f3c-b5a4-602739224d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-f0d16299-d7ce-4a18-81f0-02626365eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199326434-172.17.0.4-1598499802813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39589,DS-ef0d437c-1807-431d-bb18-de7b5678ee22,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-6968b2f3-93c3-484a-905c-b9152c4f94e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-58a4482d-99a4-40c7-bf55-85582e99bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-62a9e2ab-5e19-4739-b627-905b5361dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-4caa87c6-63d6-4ad3-9a60-c68122b721e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-a55ca9f1-5c30-4315-afff-644782bdcaac,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-3049a349-407e-4f3c-b5a4-602739224d25,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-f0d16299-d7ce-4a18-81f0-02626365eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965984927-172.17.0.4-1598500294600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-65dc5e96-dfc3-40f7-bf1c-0092f838a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-8522fd8c-998f-40e9-ad77-0d0ef3b26d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-548e3b20-cc5c-4d87-a5f5-999b08ee8870,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-382abf88-b425-4e0c-8b18-b1a4ebca3682,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b84a42de-e4ea-4d5b-97b9-64040caa128c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-6e977276-dee0-456e-9d3f-7eda228cc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-39d630c9-392e-4e6b-b84c-20b67e7e0851,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-c20f6a88-a80b-4dc9-9516-bb775c6434fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965984927-172.17.0.4-1598500294600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-65dc5e96-dfc3-40f7-bf1c-0092f838a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-8522fd8c-998f-40e9-ad77-0d0ef3b26d33,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-548e3b20-cc5c-4d87-a5f5-999b08ee8870,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-382abf88-b425-4e0c-8b18-b1a4ebca3682,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b84a42de-e4ea-4d5b-97b9-64040caa128c,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-6e977276-dee0-456e-9d3f-7eda228cc15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-39d630c9-392e-4e6b-b84c-20b67e7e0851,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-c20f6a88-a80b-4dc9-9516-bb775c6434fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346258118-172.17.0.4-1598500541832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-aa980882-e3a6-47c4-930e-55f82bfa7232,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-21a485d0-2234-4887-9a12-20ab92db35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-c40ae2d1-1a9a-45d8-b2ef-b0d309dca5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-740dc052-05f2-4d76-8a02-3bb1b3f1cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-ade391b8-9bde-4cb8-8817-8a6599fe7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-5d6e8d6e-cecd-4611-b7d2-1c918a3eacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-360b56f0-184c-468a-88a6-f4fb52a0db35,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-1465311e-7ab1-44e5-a58e-d4c1aa92dfd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346258118-172.17.0.4-1598500541832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-aa980882-e3a6-47c4-930e-55f82bfa7232,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-21a485d0-2234-4887-9a12-20ab92db35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-c40ae2d1-1a9a-45d8-b2ef-b0d309dca5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-740dc052-05f2-4d76-8a02-3bb1b3f1cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-ade391b8-9bde-4cb8-8817-8a6599fe7c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-5d6e8d6e-cecd-4611-b7d2-1c918a3eacb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-360b56f0-184c-468a-88a6-f4fb52a0db35,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-1465311e-7ab1-44e5-a58e-d4c1aa92dfd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456119570-172.17.0.4-1598500798441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-f00774f1-1263-44b3-bb97-3f3c286fba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-8756b0fe-139d-4501-abcc-8249be0c4dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-0add100b-647f-4566-999a-c09f2a389651,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-4391e814-ab77-4c9b-996d-e3cd95aab0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-e605271a-e96d-4e5c-aafc-12ad6af73430,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-c0727e6a-c966-473c-816e-45a8423f15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-531196ee-fd24-486c-9335-38707ecef294,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-01887262-ee06-420b-b145-6ff2b4d41704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456119570-172.17.0.4-1598500798441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41736,DS-f00774f1-1263-44b3-bb97-3f3c286fba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-8756b0fe-139d-4501-abcc-8249be0c4dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-0add100b-647f-4566-999a-c09f2a389651,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-4391e814-ab77-4c9b-996d-e3cd95aab0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-e605271a-e96d-4e5c-aafc-12ad6af73430,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-c0727e6a-c966-473c-816e-45a8423f15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-531196ee-fd24-486c-9335-38707ecef294,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-01887262-ee06-420b-b145-6ff2b4d41704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534589905-172.17.0.4-1598501979597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-42c2eb76-f424-4885-b606-7bfe3212981b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-4b627427-aa58-4a25-b2f0-3449f98dbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-11041e72-8cee-4f3e-8c55-22ba143fcada,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-3da71945-6bc5-4570-abe0-1900f9fe0d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-566671cf-1851-4514-86b7-5871fc2ac7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-68109482-14a4-4f52-a413-34619530f9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-869012b2-ca95-4b51-9d46-2246feaed905,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-c7afdc43-def7-40af-bd63-6de22a388cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534589905-172.17.0.4-1598501979597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40962,DS-42c2eb76-f424-4885-b606-7bfe3212981b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-4b627427-aa58-4a25-b2f0-3449f98dbde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-11041e72-8cee-4f3e-8c55-22ba143fcada,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-3da71945-6bc5-4570-abe0-1900f9fe0d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-566671cf-1851-4514-86b7-5871fc2ac7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-68109482-14a4-4f52-a413-34619530f9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-869012b2-ca95-4b51-9d46-2246feaed905,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-c7afdc43-def7-40af-bd63-6de22a388cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113998729-172.17.0.4-1598502084100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bb02434e-029a-437d-bedf-56b50bc9c190,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-0cca507d-3ea8-4299-a42f-38ee1fcb7f16,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4b6b9f12-8816-47f4-b47f-3c91da870c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-3e330cf3-9b1d-47af-a27f-c3725e05e855,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-57d07bd2-fa63-4123-9b20-5fe59fc23b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-7b2a3cb0-9874-450c-b3c3-34d68e24d117,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-80f6c71a-9719-4557-b504-47c7291b2811,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-44ab61c3-d690-474a-9923-a8cb07dc4ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113998729-172.17.0.4-1598502084100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-bb02434e-029a-437d-bedf-56b50bc9c190,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-0cca507d-3ea8-4299-a42f-38ee1fcb7f16,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-4b6b9f12-8816-47f4-b47f-3c91da870c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-3e330cf3-9b1d-47af-a27f-c3725e05e855,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-57d07bd2-fa63-4123-9b20-5fe59fc23b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-7b2a3cb0-9874-450c-b3c3-34d68e24d117,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-80f6c71a-9719-4557-b504-47c7291b2811,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-44ab61c3-d690-474a-9923-a8cb07dc4ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122137344-172.17.0.4-1598502153971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-95e257a3-efb9-4a6a-9ab1-ce43778ee8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-b53f5426-7ca4-4a39-85db-84136e94b515,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-d9fef40b-d1f5-4bd5-aeaa-1dee88b1df0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-d6d9d721-5657-4c41-8bab-5a51af130a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-97838337-85b2-4e90-b970-f7119c97a311,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-fb6cba7a-069a-4836-a9d7-6f9dd0d16e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-3044bda0-6778-4730-8c3f-efbc1cb2b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-3ba1d40e-d567-419d-986d-73b1b3bdf32c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122137344-172.17.0.4-1598502153971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41536,DS-95e257a3-efb9-4a6a-9ab1-ce43778ee8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-b53f5426-7ca4-4a39-85db-84136e94b515,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-d9fef40b-d1f5-4bd5-aeaa-1dee88b1df0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-d6d9d721-5657-4c41-8bab-5a51af130a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-97838337-85b2-4e90-b970-f7119c97a311,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-fb6cba7a-069a-4836-a9d7-6f9dd0d16e69,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-3044bda0-6778-4730-8c3f-efbc1cb2b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-3ba1d40e-d567-419d-986d-73b1b3bdf32c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213231057-172.17.0.4-1598502269596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-ec3ed8d1-e0fe-4c82-8392-8e86117cfc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-231ab051-8e88-4a00-a2e1-e43587658edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-0839aa6e-250f-40a9-bb82-ce145d06256e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-859cb8a0-9f54-4e53-88a2-4d1e6906c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-064a05ae-9ab7-4cfb-a87a-283dd47f3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-ec041865-d47a-42e7-a004-e2600ceffc40,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-3ccb63b9-0159-4140-8186-b8248c59e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-e0b594dc-0ed9-466b-9b5a-d08c637e9de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213231057-172.17.0.4-1598502269596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-ec3ed8d1-e0fe-4c82-8392-8e86117cfc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-231ab051-8e88-4a00-a2e1-e43587658edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-0839aa6e-250f-40a9-bb82-ce145d06256e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-859cb8a0-9f54-4e53-88a2-4d1e6906c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-064a05ae-9ab7-4cfb-a87a-283dd47f3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-ec041865-d47a-42e7-a004-e2600ceffc40,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-3ccb63b9-0159-4140-8186-b8248c59e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-e0b594dc-0ed9-466b-9b5a-d08c637e9de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191305287-172.17.0.4-1598502306372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-6d0c9e90-d37a-4cd1-afb5-e799e0dd090f,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b040b4a7-e27d-4509-a5c6-39c6e15126bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-75faf760-678d-4757-9566-2ed548244b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a39795fd-85a7-4565-ae23-c2133d820de3,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-8f0c00fe-5669-4749-8117-8833001899df,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-e8770aab-3f75-431d-97c6-ca3761d9f038,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-81feb682-669b-4056-9374-adb024de5914,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-af49ec30-6f13-467b-b04c-6588b7a636f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191305287-172.17.0.4-1598502306372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-6d0c9e90-d37a-4cd1-afb5-e799e0dd090f,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-b040b4a7-e27d-4509-a5c6-39c6e15126bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-75faf760-678d-4757-9566-2ed548244b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a39795fd-85a7-4565-ae23-c2133d820de3,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-8f0c00fe-5669-4749-8117-8833001899df,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-e8770aab-3f75-431d-97c6-ca3761d9f038,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-81feb682-669b-4056-9374-adb024de5914,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-af49ec30-6f13-467b-b04c-6588b7a636f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135619712-172.17.0.4-1598502601294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-97be3f02-9637-49f8-a551-7428433434c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cc14c00f-d524-46f9-a0bb-e60ce7c27c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c585cbd4-dadf-43d9-83bf-1f4950709169,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-6f803e33-04c9-440b-91f2-08d8889db4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-15d3c0e1-f842-47e2-9907-7d1eb4ab94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a5eeaad7-89b0-4d3e-b337-389943281ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d8d93ac9-df6a-4463-8b8e-139b70b0a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-89b26f27-a682-48fb-96db-a8f443da0f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135619712-172.17.0.4-1598502601294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-97be3f02-9637-49f8-a551-7428433434c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-cc14c00f-d524-46f9-a0bb-e60ce7c27c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c585cbd4-dadf-43d9-83bf-1f4950709169,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-6f803e33-04c9-440b-91f2-08d8889db4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-15d3c0e1-f842-47e2-9907-7d1eb4ab94c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-a5eeaad7-89b0-4d3e-b337-389943281ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d8d93ac9-df6a-4463-8b8e-139b70b0a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-89b26f27-a682-48fb-96db-a8f443da0f22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041361706-172.17.0.4-1598502697974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41590,DS-542b87cc-50d3-4a27-bdd7-a2c45e4f7710,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-bb4b44f6-4885-4462-b95b-d0fcaba82466,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4a17a8ed-b864-4a5c-802a-dbb66f00e649,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-f86ed656-cacd-4615-9a14-9611dff6a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-2fa1dcfa-086c-4cef-80bf-5881f04cb47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-de5b2a5d-36ec-4531-8fae-d8ee87adbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-036863cb-bacc-47e8-b8da-58f523d28460,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-59d6ab39-be28-4f64-9679-ee181a035fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041361706-172.17.0.4-1598502697974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41590,DS-542b87cc-50d3-4a27-bdd7-a2c45e4f7710,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-bb4b44f6-4885-4462-b95b-d0fcaba82466,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4a17a8ed-b864-4a5c-802a-dbb66f00e649,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-f86ed656-cacd-4615-9a14-9611dff6a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-2fa1dcfa-086c-4cef-80bf-5881f04cb47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-de5b2a5d-36ec-4531-8fae-d8ee87adbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-036863cb-bacc-47e8-b8da-58f523d28460,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-59d6ab39-be28-4f64-9679-ee181a035fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5079
