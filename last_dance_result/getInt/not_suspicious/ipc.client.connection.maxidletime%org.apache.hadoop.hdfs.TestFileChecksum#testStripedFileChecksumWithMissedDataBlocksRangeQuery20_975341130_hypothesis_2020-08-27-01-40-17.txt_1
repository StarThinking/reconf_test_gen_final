reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396009844-172.17.0.14-1598492610866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-b32766cf-00c6-44b2-a66e-855ab1fcae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-2b3c7c1a-d3ae-48d2-8e75-94a1188505f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-777388da-7bc4-4e45-933d-7f8971331cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-0736d532-6dbd-46de-8108-c03b3f4101a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-89f20f64-9115-4d3c-ab5f-341be8310683,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-dc37218a-4e34-4465-beea-d1c30fb5d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-394e0e01-3b19-4f1d-a30f-5e2c7f899f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-ae8f683b-e009-4944-8443-ad51c85a96ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396009844-172.17.0.14-1598492610866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-b32766cf-00c6-44b2-a66e-855ab1fcae8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-2b3c7c1a-d3ae-48d2-8e75-94a1188505f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-777388da-7bc4-4e45-933d-7f8971331cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-0736d532-6dbd-46de-8108-c03b3f4101a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-89f20f64-9115-4d3c-ab5f-341be8310683,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-dc37218a-4e34-4465-beea-d1c30fb5d4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-394e0e01-3b19-4f1d-a30f-5e2c7f899f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-ae8f683b-e009-4944-8443-ad51c85a96ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043805211-172.17.0.14-1598492894425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-c36f410b-5c04-48ad-8113-94752b1eb80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-ff49c793-d543-4c74-93ec-29494f560aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-8ef111d6-b501-4217-bde2-43761bf7ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-de1fd001-044e-48d9-b2c8-29dcc6e5c7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-0fbafdb0-b2fa-469e-8845-0e744b95e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-71df7544-7e75-43f8-8488-d6f54e99449e,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-6bbe7ae4-bd69-43c7-b4ab-ddad711af43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-2a2217c5-6f33-497b-8ce0-130ac9aa7690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043805211-172.17.0.14-1598492894425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-c36f410b-5c04-48ad-8113-94752b1eb80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-ff49c793-d543-4c74-93ec-29494f560aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-8ef111d6-b501-4217-bde2-43761bf7ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-de1fd001-044e-48d9-b2c8-29dcc6e5c7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-0fbafdb0-b2fa-469e-8845-0e744b95e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-71df7544-7e75-43f8-8488-d6f54e99449e,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-6bbe7ae4-bd69-43c7-b4ab-ddad711af43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-2a2217c5-6f33-497b-8ce0-130ac9aa7690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103869662-172.17.0.14-1598492925029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-b6ec73cb-27f0-44f1-9bd8-086a498db05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-2d98bf1c-276e-4436-8af5-7fb04361f6de,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-d7b8b40a-2703-4d28-b8eb-7869f3ccf2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-cc939646-b0a1-4042-a5d7-78993e1fbc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-499ed9bd-242d-4659-8bca-f9c669b0d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ed9ed7c2-a846-46d9-ba01-714c6e07e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-967f2824-800b-4115-b830-9063afdc86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-b2e83e0c-9fbf-41ba-97c3-b27a7157df7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103869662-172.17.0.14-1598492925029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38240,DS-b6ec73cb-27f0-44f1-9bd8-086a498db05a,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-2d98bf1c-276e-4436-8af5-7fb04361f6de,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-d7b8b40a-2703-4d28-b8eb-7869f3ccf2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-cc939646-b0a1-4042-a5d7-78993e1fbc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-499ed9bd-242d-4659-8bca-f9c669b0d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-ed9ed7c2-a846-46d9-ba01-714c6e07e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-967f2824-800b-4115-b830-9063afdc86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-b2e83e0c-9fbf-41ba-97c3-b27a7157df7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486688757-172.17.0.14-1598493370215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-9b0d821d-e841-4698-acda-df3ee6d87575,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-451ce84a-74b6-493f-bc51-2ea560246ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-0433d6d0-28c5-477b-bb65-5c8b30350fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f27e6a49-d5b3-450f-84d4-b105cb37645d,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-7bdf2472-806f-42d0-bb9b-b2c89e816f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-82508a3f-4e18-43af-9772-e846bd416622,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-17e05333-62d5-494c-9195-8aa3b9ab91ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-a90ac4fb-68df-4f5c-a50d-474627530940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486688757-172.17.0.14-1598493370215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36119,DS-9b0d821d-e841-4698-acda-df3ee6d87575,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-451ce84a-74b6-493f-bc51-2ea560246ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-0433d6d0-28c5-477b-bb65-5c8b30350fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f27e6a49-d5b3-450f-84d4-b105cb37645d,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-7bdf2472-806f-42d0-bb9b-b2c89e816f25,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-82508a3f-4e18-43af-9772-e846bd416622,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-17e05333-62d5-494c-9195-8aa3b9ab91ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-a90ac4fb-68df-4f5c-a50d-474627530940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411758994-172.17.0.14-1598494354083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-fca376cb-212b-45ce-84e5-a5cacb0cdcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-de64e50f-3b11-4b05-a92e-c34da31837e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-74f77bee-4432-4392-8efb-0d01f678b526,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-d97152be-cd47-498b-b230-dc34b4c1cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-cb94abe1-62f9-49ba-93b1-1d6e37b10e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-c7f338ce-943a-4350-b0e4-a731c1d47cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-32b90e81-c44e-42ee-97f3-eebb9e8bb953,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-f63b509c-52a2-4fa8-b6af-6975b8fe10c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411758994-172.17.0.14-1598494354083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-fca376cb-212b-45ce-84e5-a5cacb0cdcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-de64e50f-3b11-4b05-a92e-c34da31837e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-74f77bee-4432-4392-8efb-0d01f678b526,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-d97152be-cd47-498b-b230-dc34b4c1cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-cb94abe1-62f9-49ba-93b1-1d6e37b10e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-c7f338ce-943a-4350-b0e4-a731c1d47cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-32b90e81-c44e-42ee-97f3-eebb9e8bb953,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-f63b509c-52a2-4fa8-b6af-6975b8fe10c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417054689-172.17.0.14-1598494821105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-c93fbc34-42b7-4ff7-a957-d3c67141bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-bc1b5c28-651c-4864-b9dd-d4f9ea77b497,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0f7d3c1b-6343-4468-9953-71e825c897d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-30923912-e6a4-4787-81d3-efce7c3d4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-a98d28e5-793a-413e-96b0-788e97a7eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-79782219-42fa-49e8-9dbe-611f8ab334b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-5390fd52-6c03-4015-a84c-ec60b4dabddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-af2dd954-4164-425a-aab0-a5709d5a8bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417054689-172.17.0.14-1598494821105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-c93fbc34-42b7-4ff7-a957-d3c67141bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-bc1b5c28-651c-4864-b9dd-d4f9ea77b497,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0f7d3c1b-6343-4468-9953-71e825c897d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-30923912-e6a4-4787-81d3-efce7c3d4ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-a98d28e5-793a-413e-96b0-788e97a7eec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-79782219-42fa-49e8-9dbe-611f8ab334b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-5390fd52-6c03-4015-a84c-ec60b4dabddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-af2dd954-4164-425a-aab0-a5709d5a8bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607957241-172.17.0.14-1598495111811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-635d75c8-865b-4daf-81fa-335d834546fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-53a59862-c8d0-44de-993d-8398bb59eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-8bbdc7ec-c275-4d95-8bbb-e0c71a264e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-4aa19318-6d0f-439b-9e37-b9cfa6a6a956,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-0cee8a6a-bdce-47c4-9d60-90c03d964e50,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-8be463cf-6261-4e20-b149-a01588963c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-ec3d08d6-b567-4b3a-b976-8a7a8a8a5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-44ae2980-3385-4920-8a59-b59a2de02d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607957241-172.17.0.14-1598495111811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32875,DS-635d75c8-865b-4daf-81fa-335d834546fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-53a59862-c8d0-44de-993d-8398bb59eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-8bbdc7ec-c275-4d95-8bbb-e0c71a264e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-4aa19318-6d0f-439b-9e37-b9cfa6a6a956,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-0cee8a6a-bdce-47c4-9d60-90c03d964e50,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-8be463cf-6261-4e20-b149-a01588963c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-ec3d08d6-b567-4b3a-b976-8a7a8a8a5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-44ae2980-3385-4920-8a59-b59a2de02d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583740388-172.17.0.14-1598495249413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-7c705bfc-ca19-4e64-b613-7abc77b42d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7214362a-05a1-478d-88d6-a91096a59626,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f226c084-b096-4afb-a8ee-fdad1ab1b265,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-10e309f6-ec14-4ed1-8051-7a369f7a4345,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-e6cff3db-935b-41f3-846c-153ee1e9389d,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-c2fea758-f515-4228-a6d4-f894ae164426,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-2b8006cf-b4e3-4cd1-a73b-9483e20463ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-74838804-ae8c-4fbb-acd9-9fadc16de89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583740388-172.17.0.14-1598495249413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40429,DS-7c705bfc-ca19-4e64-b613-7abc77b42d42,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7214362a-05a1-478d-88d6-a91096a59626,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f226c084-b096-4afb-a8ee-fdad1ab1b265,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-10e309f6-ec14-4ed1-8051-7a369f7a4345,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-e6cff3db-935b-41f3-846c-153ee1e9389d,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-c2fea758-f515-4228-a6d4-f894ae164426,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-2b8006cf-b4e3-4cd1-a73b-9483e20463ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-74838804-ae8c-4fbb-acd9-9fadc16de89b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307440025-172.17.0.14-1598495959383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-539589ea-78e1-4568-b5e7-42752b73d612,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-5fc04062-3037-45a6-b791-84ed6b5893a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-7954e808-7da1-4f26-8dfc-8047e2baffab,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-926073fe-eb77-4140-9ca1-f038bf75f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-2a7a6caf-a37b-4db2-9940-75f5604071bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-15c45a23-2ae7-445b-a104-ece724e52ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-37157ad6-5233-41ef-a3b0-90c550dac717,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-5a57cc7f-b229-452f-bb20-677c5e73b4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307440025-172.17.0.14-1598495959383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-539589ea-78e1-4568-b5e7-42752b73d612,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-5fc04062-3037-45a6-b791-84ed6b5893a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-7954e808-7da1-4f26-8dfc-8047e2baffab,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-926073fe-eb77-4140-9ca1-f038bf75f7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-2a7a6caf-a37b-4db2-9940-75f5604071bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-15c45a23-2ae7-445b-a104-ece724e52ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-37157ad6-5233-41ef-a3b0-90c550dac717,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-5a57cc7f-b229-452f-bb20-677c5e73b4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83273384-172.17.0.14-1598496519620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-818c6b0c-d16c-4639-b463-dc60b66839b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-06992fb8-3515-44b1-8cc0-e0dc2a3b64c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-f128f283-00ca-4e24-9172-c89014e9edae,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-125535a7-1e38-451b-be5b-ffd1a4aa54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-f09de889-b636-4656-b4fe-a31b402f85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-bb568084-018f-4300-be35-eb2859bf865b,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-0f613642-d112-4a73-9022-e42fff652ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-67d2ce2d-49dd-47a2-b1a2-653af6c10f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83273384-172.17.0.14-1598496519620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-818c6b0c-d16c-4639-b463-dc60b66839b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-06992fb8-3515-44b1-8cc0-e0dc2a3b64c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-f128f283-00ca-4e24-9172-c89014e9edae,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-125535a7-1e38-451b-be5b-ffd1a4aa54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-f09de889-b636-4656-b4fe-a31b402f85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-bb568084-018f-4300-be35-eb2859bf865b,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-0f613642-d112-4a73-9022-e42fff652ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-67d2ce2d-49dd-47a2-b1a2-653af6c10f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710393828-172.17.0.14-1598496592841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-4bd7ae31-8926-4471-9b82-8071004e63a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-58937041-a48e-4c47-8be5-89e2007d8e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-283ebc93-3ae3-4ae3-ad06-0c06f393dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-df41e5c9-7dbf-4f4d-8ce4-3a235898c524,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-366ef406-6833-4028-909d-5706bfbc6d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-481a2719-a356-47f3-9611-2ea16d3b5f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-735e7c1b-248a-49ba-b9f0-906998d03e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e9b36c78-8900-4bd4-9ed7-ec38e1e966f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710393828-172.17.0.14-1598496592841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35264,DS-4bd7ae31-8926-4471-9b82-8071004e63a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-58937041-a48e-4c47-8be5-89e2007d8e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-283ebc93-3ae3-4ae3-ad06-0c06f393dc36,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-df41e5c9-7dbf-4f4d-8ce4-3a235898c524,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-366ef406-6833-4028-909d-5706bfbc6d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-481a2719-a356-47f3-9611-2ea16d3b5f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-735e7c1b-248a-49ba-b9f0-906998d03e14,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-e9b36c78-8900-4bd4-9ed7-ec38e1e966f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795216033-172.17.0.14-1598496760501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-4cf743b6-6996-49a2-bbc8-dca060c5b31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-cf6ca5fe-6c8a-49e5-a607-19d3714fc6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a4307e2d-d481-4f52-b336-519f8c9ff55c,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-9adaf55b-00bd-4440-9f2f-c4e53105fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-165191da-f238-4951-b545-e4bb0c2dd2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-f1ee0262-915e-4263-951f-3f3325a0f955,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-dffd9226-2517-459b-9f2c-c3494b919cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-02a9fdf8-399a-42c5-a98d-9ac37aada6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795216033-172.17.0.14-1598496760501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39665,DS-4cf743b6-6996-49a2-bbc8-dca060c5b31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-cf6ca5fe-6c8a-49e5-a607-19d3714fc6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a4307e2d-d481-4f52-b336-519f8c9ff55c,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-9adaf55b-00bd-4440-9f2f-c4e53105fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-165191da-f238-4951-b545-e4bb0c2dd2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-f1ee0262-915e-4263-951f-3f3325a0f955,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-dffd9226-2517-459b-9f2c-c3494b919cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-02a9fdf8-399a-42c5-a98d-9ac37aada6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477872574-172.17.0.14-1598496870610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-0c8c1407-b37d-4fd2-8964-0774fd1760fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-e950485f-6397-46ec-82d8-0b94d4a771ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-b0c0a3e8-bfa8-4198-8ee0-0b17a416c690,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-073ba622-8618-457a-acc3-3a64d6b4a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-26bec479-7df2-45d7-b6ee-abaacecbfc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-d8d39c9b-a245-4870-8981-3a46d66d1923,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-f4f5a484-88ad-4929-9e84-ac81716da52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-143752fa-1303-4a01-800c-6161a2385e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477872574-172.17.0.14-1598496870610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43867,DS-0c8c1407-b37d-4fd2-8964-0774fd1760fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-e950485f-6397-46ec-82d8-0b94d4a771ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-b0c0a3e8-bfa8-4198-8ee0-0b17a416c690,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-073ba622-8618-457a-acc3-3a64d6b4a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-26bec479-7df2-45d7-b6ee-abaacecbfc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-d8d39c9b-a245-4870-8981-3a46d66d1923,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-f4f5a484-88ad-4929-9e84-ac81716da52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-143752fa-1303-4a01-800c-6161a2385e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463873781-172.17.0.14-1598496995918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-9c8cd28a-4afa-4691-ba4d-7d76034ef074,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-58b8df6d-6bb5-4735-9d4c-31ad242fbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-54cb24c9-0c94-43f3-8005-5b544df845cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-f5025f08-b81f-4488-893a-fc253ec403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-8feabeed-ac63-4eeb-8b99-42615f088aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-d7526930-d4cc-4f42-bddc-e38fe427e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-4dc3914b-326f-404a-8c2c-c5b1837704af,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-35156809-3d84-430b-bd78-67251714d505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463873781-172.17.0.14-1598496995918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-9c8cd28a-4afa-4691-ba4d-7d76034ef074,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-58b8df6d-6bb5-4735-9d4c-31ad242fbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-54cb24c9-0c94-43f3-8005-5b544df845cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-f5025f08-b81f-4488-893a-fc253ec403cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-8feabeed-ac63-4eeb-8b99-42615f088aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44517,DS-d7526930-d4cc-4f42-bddc-e38fe427e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-4dc3914b-326f-404a-8c2c-c5b1837704af,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-35156809-3d84-430b-bd78-67251714d505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486597363-172.17.0.14-1598497380279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-48a36af2-099b-4743-a5a2-c744a4440c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-be92d0ea-ff07-406b-b89c-065f6a5422dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-30017004-71b7-43a1-916a-38a2b67ecd68,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3534280d-ded0-47ae-be32-112d5d8bb8df,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-74b4e6b2-6d0d-49a9-b889-b89ad487a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-948273a1-e3e0-4312-a3a7-dfac0e410f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-6f49e8d2-d095-4896-aca4-3e7254378433,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-b27341ca-208b-418d-9508-c4b0b7393317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486597363-172.17.0.14-1598497380279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-48a36af2-099b-4743-a5a2-c744a4440c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-be92d0ea-ff07-406b-b89c-065f6a5422dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-30017004-71b7-43a1-916a-38a2b67ecd68,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-3534280d-ded0-47ae-be32-112d5d8bb8df,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-74b4e6b2-6d0d-49a9-b889-b89ad487a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-948273a1-e3e0-4312-a3a7-dfac0e410f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-6f49e8d2-d095-4896-aca4-3e7254378433,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-b27341ca-208b-418d-9508-c4b0b7393317,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393900710-172.17.0.14-1598497530203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-21a756af-c97f-43f9-b617-482c2b244f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-be183001-2755-4bd7-bdde-07c71a1ae0df,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-5c11a4c0-aef0-41d1-ba26-19de2a98e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-8e1d2d15-b434-4b77-84a8-61f5fac8e3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-706d0c6b-df15-48a0-adb4-f340a219b913,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-c7c49045-9e2c-4a36-a5ec-a60399508a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b9a2696f-7565-48ca-bbb8-c80af954e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-83fdc244-18d4-4849-ac24-33996df330b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393900710-172.17.0.14-1598497530203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-21a756af-c97f-43f9-b617-482c2b244f41,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-be183001-2755-4bd7-bdde-07c71a1ae0df,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-5c11a4c0-aef0-41d1-ba26-19de2a98e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-8e1d2d15-b434-4b77-84a8-61f5fac8e3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-706d0c6b-df15-48a0-adb4-f340a219b913,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-c7c49045-9e2c-4a36-a5ec-a60399508a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-b9a2696f-7565-48ca-bbb8-c80af954e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-83fdc244-18d4-4849-ac24-33996df330b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 10000
v2: 20000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77209059-172.17.0.14-1598497608997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-3b671b07-9e60-44b4-9585-20af9d945def,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-3e9819a7-4059-4c81-a182-e6f5e173cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-fccef0ad-757f-4e24-924e-fcbc6b78972f,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-e169aa4f-7aae-49ba-92b0-5b107f5285e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-9498f49e-a1af-4015-94b6-1387995e8494,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-ec8e6118-7164-47f6-96e2-c13702c7563a,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3e15c6ee-dbac-4ac9-808c-97c40bc4d301,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-de0a06fd-0044-4a23-ab60-a3094038e259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77209059-172.17.0.14-1598497608997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-3b671b07-9e60-44b4-9585-20af9d945def,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-3e9819a7-4059-4c81-a182-e6f5e173cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-fccef0ad-757f-4e24-924e-fcbc6b78972f,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-e169aa4f-7aae-49ba-92b0-5b107f5285e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-9498f49e-a1af-4015-94b6-1387995e8494,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-ec8e6118-7164-47f6-96e2-c13702c7563a,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-3e15c6ee-dbac-4ac9-808c-97c40bc4d301,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-de0a06fd-0044-4a23-ab60-a3094038e259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5329
