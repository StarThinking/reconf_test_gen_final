reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-75d52864-db54-4336-8780-79b05b078c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-1f180d0e-dea3-43f0-82c9-9e07b603a115,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-993bbe6a-e7f2-48eb-a07e-915b6ec19257,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-1f180d0e-dea3-43f0-82c9-9e07b603a115,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-75d52864-db54-4336-8780-79b05b078c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-993bbe6a-e7f2-48eb-a07e-915b6ec19257,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41450,DS-75d52864-db54-4336-8780-79b05b078c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-1f180d0e-dea3-43f0-82c9-9e07b603a115,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-993bbe6a-e7f2-48eb-a07e-915b6ec19257,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-1f180d0e-dea3-43f0-82c9-9e07b603a115,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-75d52864-db54-4336-8780-79b05b078c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-993bbe6a-e7f2-48eb-a07e-915b6ec19257,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38510,DS-5056dcc5-1952-4ddb-ab49-f2be6690d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-5668bd0c-721f-4f92-a44b-6a4859d0de38,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-914284a3-e9e5-49be-bcc7-28bb7c4d6723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-5668bd0c-721f-4f92-a44b-6a4859d0de38,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-5056dcc5-1952-4ddb-ab49-f2be6690d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-914284a3-e9e5-49be-bcc7-28bb7c4d6723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38510,DS-5056dcc5-1952-4ddb-ab49-f2be6690d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-5668bd0c-721f-4f92-a44b-6a4859d0de38,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-914284a3-e9e5-49be-bcc7-28bb7c4d6723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-5668bd0c-721f-4f92-a44b-6a4859d0de38,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-5056dcc5-1952-4ddb-ab49-f2be6690d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-914284a3-e9e5-49be-bcc7-28bb7c4d6723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-abdf5231-8019-4704-9e9f-f3fb96580c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-091a50f7-66de-4591-b1ad-98c54de436a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-26695201-07ad-463e-84d7-b052dae2ba5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-26695201-07ad-463e-84d7-b052dae2ba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-091a50f7-66de-4591-b1ad-98c54de436a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-abdf5231-8019-4704-9e9f-f3fb96580c5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-abdf5231-8019-4704-9e9f-f3fb96580c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-091a50f7-66de-4591-b1ad-98c54de436a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-26695201-07ad-463e-84d7-b052dae2ba5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35028,DS-26695201-07ad-463e-84d7-b052dae2ba5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-091a50f7-66de-4591-b1ad-98c54de436a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-abdf5231-8019-4704-9e9f-f3fb96580c5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33546,DS-97f14b94-15ef-4adb-a3fc-4b2374138843,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-2b0387f1-4303-449b-8ad4-f84614fabedf,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b5619489-e387-4ae0-bdce-c17ef325603d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-b5619489-e387-4ae0-bdce-c17ef325603d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-2b0387f1-4303-449b-8ad4-f84614fabedf,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-97f14b94-15ef-4adb-a3fc-4b2374138843,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33546,DS-97f14b94-15ef-4adb-a3fc-4b2374138843,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-2b0387f1-4303-449b-8ad4-f84614fabedf,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-b5619489-e387-4ae0-bdce-c17ef325603d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-b5619489-e387-4ae0-bdce-c17ef325603d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-2b0387f1-4303-449b-8ad4-f84614fabedf,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-97f14b94-15ef-4adb-a3fc-4b2374138843,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-a8c23efb-fee2-4184-9774-7b621fc0dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-5080f159-912b-4ed9-aed0-d0c727c18ac1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-a8c23efb-fee2-4184-9774-7b621fc0dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-5080f159-912b-4ed9-aed0-d0c727c18ac1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-a8c23efb-fee2-4184-9774-7b621fc0dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-5080f159-912b-4ed9-aed0-d0c727c18ac1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-a8c23efb-fee2-4184-9774-7b621fc0dfea,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-5080f159-912b-4ed9-aed0-d0c727c18ac1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-16c84820-fcf5-4bda-8ecd-292ed3c0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-c1408257-8e07-44a9-a80b-0eb695e7846c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-15626b24-c80c-44e9-9165-0aa4ca3eb587,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-16c84820-fcf5-4bda-8ecd-292ed3c0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-c1408257-8e07-44a9-a80b-0eb695e7846c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-15626b24-c80c-44e9-9165-0aa4ca3eb587,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-16c84820-fcf5-4bda-8ecd-292ed3c0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-c1408257-8e07-44a9-a80b-0eb695e7846c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-15626b24-c80c-44e9-9165-0aa4ca3eb587,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-16c84820-fcf5-4bda-8ecd-292ed3c0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-c1408257-8e07-44a9-a80b-0eb695e7846c,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-15626b24-c80c-44e9-9165-0aa4ca3eb587,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44703,DS-4fe8f758-2749-43a0-b6ee-1512932f18fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-db4d091b-eebe-4798-b480-cf29474a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8c4a7b27-4595-4aaa-a051-7e3084b1cc74,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-8c4a7b27-4595-4aaa-a051-7e3084b1cc74,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-db4d091b-eebe-4798-b480-cf29474a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-4fe8f758-2749-43a0-b6ee-1512932f18fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44703,DS-4fe8f758-2749-43a0-b6ee-1512932f18fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-db4d091b-eebe-4798-b480-cf29474a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8c4a7b27-4595-4aaa-a051-7e3084b1cc74,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-8c4a7b27-4595-4aaa-a051-7e3084b1cc74,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-db4d091b-eebe-4798-b480-cf29474a687c,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-4fe8f758-2749-43a0-b6ee-1512932f18fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-ceeb3bc5-cf46-4d21-b1c5-92709b7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0d658f62-e4b8-4114-8df6-51fd7fe1e955,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-3ded6773-f836-4233-a6fb-2e09007d3fd8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-ceeb3bc5-cf46-4d21-b1c5-92709b7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0d658f62-e4b8-4114-8df6-51fd7fe1e955,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-3ded6773-f836-4233-a6fb-2e09007d3fd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-ceeb3bc5-cf46-4d21-b1c5-92709b7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0d658f62-e4b8-4114-8df6-51fd7fe1e955,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-3ded6773-f836-4233-a6fb-2e09007d3fd8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36998,DS-ceeb3bc5-cf46-4d21-b1c5-92709b7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-0d658f62-e4b8-4114-8df6-51fd7fe1e955,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-3ded6773-f836-4233-a6fb-2e09007d3fd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-5296c50c-5d60-4e8c-8427-5976860884e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-0ca99c0e-6408-494b-8809-babfd8687397,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-898cf90b-0c47-49cd-9d53-f0b23e8ccc9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-898cf90b-0c47-49cd-9d53-f0b23e8ccc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-0ca99c0e-6408-494b-8809-babfd8687397,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-5296c50c-5d60-4e8c-8427-5976860884e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-5296c50c-5d60-4e8c-8427-5976860884e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-0ca99c0e-6408-494b-8809-babfd8687397,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-898cf90b-0c47-49cd-9d53-f0b23e8ccc9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-898cf90b-0c47-49cd-9d53-f0b23e8ccc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-0ca99c0e-6408-494b-8809-babfd8687397,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-5296c50c-5d60-4e8c-8427-5976860884e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-374dddba-8b89-493a-a1ec-e549aea10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-ae4daf66-ea61-418e-b8da-ac05864098e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-200a1cb8-3369-4539-a326-5bc45d5b7494,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-374dddba-8b89-493a-a1ec-e549aea10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-ae4daf66-ea61-418e-b8da-ac05864098e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-200a1cb8-3369-4539-a326-5bc45d5b7494,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-374dddba-8b89-493a-a1ec-e549aea10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-ae4daf66-ea61-418e-b8da-ac05864098e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-200a1cb8-3369-4539-a326-5bc45d5b7494,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-374dddba-8b89-493a-a1ec-e549aea10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-ae4daf66-ea61-418e-b8da-ac05864098e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-200a1cb8-3369-4539-a326-5bc45d5b7494,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-220c808d-c8ec-4fac-8b6e-6270e4cd1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-11ea2ef6-504e-4a25-8543-1adce6913793,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-220c808d-c8ec-4fac-8b6e-6270e4cd1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-11ea2ef6-504e-4a25-8543-1adce6913793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-220c808d-c8ec-4fac-8b6e-6270e4cd1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-11ea2ef6-504e-4a25-8543-1adce6913793,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-220c808d-c8ec-4fac-8b6e-6270e4cd1f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-11ea2ef6-504e-4a25-8543-1adce6913793,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate#testUpdateQuotaForFSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-cdfadd52-34a3-4690-b6a7-244954ceb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-94c02d31-ae5e-48f7-99ef-53f661545ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e435fb81-8e31-4a6c-813c-74d4b4219156,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-94c02d31-ae5e-48f7-99ef-53f661545ade,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-cdfadd52-34a3-4690-b6a7-244954ceb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e435fb81-8e31-4a6c-813c-74d4b4219156,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-cdfadd52-34a3-4690-b6a7-244954ceb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-94c02d31-ae5e-48f7-99ef-53f661545ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e435fb81-8e31-4a6c-813c-74d4b4219156,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35295,DS-94c02d31-ae5e-48f7-99ef-53f661545ade,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-cdfadd52-34a3-4690-b6a7-244954ceb8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e435fb81-8e31-4a6c-813c-74d4b4219156,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 3604
