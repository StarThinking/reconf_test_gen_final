reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263168967-172.17.0.10-1598639833187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-501a7ea3-16c3-4759-9689-b1a4ce944298,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-0acbb58d-3ab3-4e70-b403-775fad365337,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-e51464e9-c929-41d5-8cc6-a367e4e3c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-a28cb1a9-23fb-43ba-842e-4cc800ccec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-6d269282-b3b2-446e-aef3-13fecd0b554f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-589e1e0d-54c7-477a-b521-63eefac9f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-706cbb76-7818-4fb8-8967-fa29ba27b749,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-8b6e5436-f795-4657-9ba2-ed249045e02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263168967-172.17.0.10-1598639833187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39449,DS-501a7ea3-16c3-4759-9689-b1a4ce944298,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-0acbb58d-3ab3-4e70-b403-775fad365337,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-e51464e9-c929-41d5-8cc6-a367e4e3c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-a28cb1a9-23fb-43ba-842e-4cc800ccec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-6d269282-b3b2-446e-aef3-13fecd0b554f,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-589e1e0d-54c7-477a-b521-63eefac9f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-706cbb76-7818-4fb8-8967-fa29ba27b749,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-8b6e5436-f795-4657-9ba2-ed249045e02b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955117834-172.17.0.10-1598640011112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-2e23743c-c958-414b-909a-6a450fd47337,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b9115142-6e48-4b0b-adc0-2babf50c210c,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-840fd916-2f73-4c43-a6f8-d7bfc205ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-1bc7ada5-ad88-40c1-b547-66c9b2c64d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b5c496fb-c7bc-49b1-ab63-8242b24f4740,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-b17532da-728f-45bf-abd5-7562e9290c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-6f6b2b34-8dd7-4813-b6b0-db8a4f4b557a,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-f157576d-3571-425f-bcfe-135c52411731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955117834-172.17.0.10-1598640011112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-2e23743c-c958-414b-909a-6a450fd47337,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b9115142-6e48-4b0b-adc0-2babf50c210c,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-840fd916-2f73-4c43-a6f8-d7bfc205ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-1bc7ada5-ad88-40c1-b547-66c9b2c64d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b5c496fb-c7bc-49b1-ab63-8242b24f4740,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-b17532da-728f-45bf-abd5-7562e9290c06,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-6f6b2b34-8dd7-4813-b6b0-db8a4f4b557a,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-f157576d-3571-425f-bcfe-135c52411731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559130302-172.17.0.10-1598640109020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-7a45b43e-88ff-4634-adb1-e509d76cc91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-a9064af7-fa2b-4ce2-b4cb-ba8619667d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-0a704e7a-15ea-45b4-9654-5912626674da,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-4d890220-ea7e-4f56-8651-2b4214d68965,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-89ba153a-4306-4419-ac6b-83d759ef2dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-d1090217-afa1-4c75-9fce-24642f6fce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-e2907464-37e8-430f-ad38-37fe3c6af0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-ecac9478-4d36-4762-80ca-68d0e8ec52ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559130302-172.17.0.10-1598640109020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-7a45b43e-88ff-4634-adb1-e509d76cc91e,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-a9064af7-fa2b-4ce2-b4cb-ba8619667d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-0a704e7a-15ea-45b4-9654-5912626674da,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-4d890220-ea7e-4f56-8651-2b4214d68965,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-89ba153a-4306-4419-ac6b-83d759ef2dac,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-d1090217-afa1-4c75-9fce-24642f6fce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-e2907464-37e8-430f-ad38-37fe3c6af0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-ecac9478-4d36-4762-80ca-68d0e8ec52ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613700838-172.17.0.10-1598640218209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-df41b845-82ec-4133-8bce-a08e4e5cf849,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-1d4b632e-d4ba-4b6b-8907-405d19f6d22a,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-a1535ba4-9c3a-4b5f-9d3b-daa388e995bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-a4f69341-e2ee-4ed7-af53-f266e7d6051e,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-dad9d505-55ea-4662-9097-4fb40365a582,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-5f664cab-3d1b-4b53-880c-04946426e173,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0f0cd931-2600-4b46-884d-cfd0fc6baa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-424fccc1-f390-44e8-a6d0-bb210dfb3228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613700838-172.17.0.10-1598640218209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-df41b845-82ec-4133-8bce-a08e4e5cf849,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-1d4b632e-d4ba-4b6b-8907-405d19f6d22a,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-a1535ba4-9c3a-4b5f-9d3b-daa388e995bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-a4f69341-e2ee-4ed7-af53-f266e7d6051e,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-dad9d505-55ea-4662-9097-4fb40365a582,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-5f664cab-3d1b-4b53-880c-04946426e173,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-0f0cd931-2600-4b46-884d-cfd0fc6baa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-424fccc1-f390-44e8-a6d0-bb210dfb3228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857429495-172.17.0.10-1598640251545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-7dd29d0d-2eb9-443f-af99-10dfb380ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-09104f4c-c192-4a76-9a20-1ff7c8f471d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-096794f9-95a6-44c6-8033-2b270de6bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-dbcfcb2e-95c1-45af-a328-ee845a1c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c1505be9-35c9-4a7c-8461-5732508462ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-91d0fe66-f91a-49c2-b809-5ba97af2d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d598b97d-aa94-47f9-9b66-3381ddf30611,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-076fce9c-f4d0-4698-8377-19116522257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857429495-172.17.0.10-1598640251545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39511,DS-7dd29d0d-2eb9-443f-af99-10dfb380ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-09104f4c-c192-4a76-9a20-1ff7c8f471d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-096794f9-95a6-44c6-8033-2b270de6bee2,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-dbcfcb2e-95c1-45af-a328-ee845a1c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c1505be9-35c9-4a7c-8461-5732508462ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-91d0fe66-f91a-49c2-b809-5ba97af2d17f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d598b97d-aa94-47f9-9b66-3381ddf30611,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-076fce9c-f4d0-4698-8377-19116522257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673019176-172.17.0.10-1598640285054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-efc18bc9-ffe3-4fb4-b6ba-bdf4c1352b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-3ea7c35a-0db9-443e-8b64-eab077b279e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-b47c6b40-f076-4a76-8fdd-f6985fc05289,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-c1f94f09-7ad6-4559-a50b-7d621a0ed450,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-2c358a6f-37b2-496c-a416-e5454e2f79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-d7fc841f-b8c6-4956-b694-90db5627c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-83992bca-ce54-483d-ae8b-c7a38d77c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-778a4e65-5daf-432b-82a3-834f18d6be39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673019176-172.17.0.10-1598640285054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38031,DS-efc18bc9-ffe3-4fb4-b6ba-bdf4c1352b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-3ea7c35a-0db9-443e-8b64-eab077b279e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-b47c6b40-f076-4a76-8fdd-f6985fc05289,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-c1f94f09-7ad6-4559-a50b-7d621a0ed450,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-2c358a6f-37b2-496c-a416-e5454e2f79a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-d7fc841f-b8c6-4956-b694-90db5627c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-83992bca-ce54-483d-ae8b-c7a38d77c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-778a4e65-5daf-432b-82a3-834f18d6be39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659115455-172.17.0.10-1598640800657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-cc347624-d319-4d14-b5b4-ba9fb2f94044,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-c64dea9c-d037-4d94-8897-812a2ecee9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-850dc55f-c7cc-4c74-88a0-2c02631fc0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-85442114-1bc3-41c5-8101-23145763392c,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0f652954-2c15-40cb-aa82-8fb37befe412,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-3d348d0d-6b16-472e-aae2-00ba1092ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e3db36f2-829f-4ff2-8679-f7c147287826,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-97caeb21-ef7e-4929-9872-fa55c10a35f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659115455-172.17.0.10-1598640800657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39045,DS-cc347624-d319-4d14-b5b4-ba9fb2f94044,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-c64dea9c-d037-4d94-8897-812a2ecee9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-850dc55f-c7cc-4c74-88a0-2c02631fc0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-85442114-1bc3-41c5-8101-23145763392c,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0f652954-2c15-40cb-aa82-8fb37befe412,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-3d348d0d-6b16-472e-aae2-00ba1092ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-e3db36f2-829f-4ff2-8679-f7c147287826,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-97caeb21-ef7e-4929-9872-fa55c10a35f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003138095-172.17.0.10-1598640900813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-9184c14d-62cd-411d-8113-139deba44b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-d35b4c9c-204c-4a6c-8b06-09bfd729a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-6ae50ebc-8244-41c8-a412-5fb83b142b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-b0e628f9-8f33-450c-9fb5-ec5f65b1aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-c5cee0f7-7081-4dc2-bf35-7df6b6f5e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-0ea0ea1c-dc26-4f22-ac11-0efdffc9f814,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-6951352f-7b37-43f3-8b66-5fe0dd3acd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-fc79cbc1-60f5-4e15-8fc9-90509a1c132a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003138095-172.17.0.10-1598640900813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44509,DS-9184c14d-62cd-411d-8113-139deba44b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-d35b4c9c-204c-4a6c-8b06-09bfd729a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-6ae50ebc-8244-41c8-a412-5fb83b142b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-b0e628f9-8f33-450c-9fb5-ec5f65b1aa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-c5cee0f7-7081-4dc2-bf35-7df6b6f5e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-0ea0ea1c-dc26-4f22-ac11-0efdffc9f814,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-6951352f-7b37-43f3-8b66-5fe0dd3acd70,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-fc79cbc1-60f5-4e15-8fc9-90509a1c132a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631936077-172.17.0.10-1598640932991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-44ce05eb-f865-4ec1-80ad-b80b1377d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-92686c7c-bf7d-4977-ad17-ee792bf16e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-433133fa-c89a-41af-bd09-1ad3a074bfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-7bf2144d-b4f4-4617-a252-1d0bad582835,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-8fa6822c-a8d7-444b-a7ee-1f15b6b35012,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5ec0dc6f-09e6-4024-adfe-46835420b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c057e168-1613-4fcc-87d1-1bb75b31b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ce90cb08-fcc5-40b8-93b6-e36bb14e76cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631936077-172.17.0.10-1598640932991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-44ce05eb-f865-4ec1-80ad-b80b1377d7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-92686c7c-bf7d-4977-ad17-ee792bf16e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-433133fa-c89a-41af-bd09-1ad3a074bfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-7bf2144d-b4f4-4617-a252-1d0bad582835,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-8fa6822c-a8d7-444b-a7ee-1f15b6b35012,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-5ec0dc6f-09e6-4024-adfe-46835420b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-c057e168-1613-4fcc-87d1-1bb75b31b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-ce90cb08-fcc5-40b8-93b6-e36bb14e76cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740279900-172.17.0.10-1598641205922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-1687da6c-4351-4a33-aea5-de2b106806d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-682d9482-47fb-450a-b035-09c87dc8fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-37ed2652-65dc-45b8-9b58-72dbf55c3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-cb725b54-fd1e-4e34-af9d-78139ad4b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-204cbc65-2ff0-4f0d-b7c6-d6e0ae341424,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-fc718aa7-ffe3-47d9-8453-d2689a1c3642,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-c86a5259-3734-4876-a800-8cc0aabff72e,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-92bbd73d-22ad-442e-8342-bd2872116a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740279900-172.17.0.10-1598641205922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40055,DS-1687da6c-4351-4a33-aea5-de2b106806d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-682d9482-47fb-450a-b035-09c87dc8fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-37ed2652-65dc-45b8-9b58-72dbf55c3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-cb725b54-fd1e-4e34-af9d-78139ad4b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-204cbc65-2ff0-4f0d-b7c6-d6e0ae341424,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-fc718aa7-ffe3-47d9-8453-d2689a1c3642,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-c86a5259-3734-4876-a800-8cc0aabff72e,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-92bbd73d-22ad-442e-8342-bd2872116a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271773686-172.17.0.10-1598641305132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-ed6b33c5-e6ad-49f4-bd2e-d3890869f870,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-316167d0-0b97-4e11-9009-bbb8ae82203c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-a38f677f-bdc9-40c9-afe7-c0ef6a217907,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-f80d5f7c-028a-4f07-b8f2-1464bd66e404,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-0048cfe2-d994-4303-904c-d226ae6d4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-5a962ae5-ce95-4c69-bd5f-6ad128603b09,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-0eceb734-d3e0-49e2-9a2e-9033153702fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4ac86a31-b593-4cc0-b6b3-8a6bb348e719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271773686-172.17.0.10-1598641305132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-ed6b33c5-e6ad-49f4-bd2e-d3890869f870,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-316167d0-0b97-4e11-9009-bbb8ae82203c,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-a38f677f-bdc9-40c9-afe7-c0ef6a217907,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-f80d5f7c-028a-4f07-b8f2-1464bd66e404,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-0048cfe2-d994-4303-904c-d226ae6d4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-5a962ae5-ce95-4c69-bd5f-6ad128603b09,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-0eceb734-d3e0-49e2-9a2e-9033153702fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4ac86a31-b593-4cc0-b6b3-8a6bb348e719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534387311-172.17.0.10-1598641611487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-2b6bf49d-1267-4022-9c33-f8c08bf77c57,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-15d203ac-9269-47db-8375-feee11d1469c,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-7f03b737-9923-4dd0-918e-ed1311b2d300,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-c1d3ddb4-f439-48d6-9280-4b0956e815f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-92fac6e1-401d-4ec9-9996-1a0e24856774,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-8fa25640-77fc-41a0-9eed-5dac8025f507,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-59e8c821-edb2-480c-b127-98f1433c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-068615ac-0b32-42a9-a1ba-cb65d4e9d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-534387311-172.17.0.10-1598641611487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46574,DS-2b6bf49d-1267-4022-9c33-f8c08bf77c57,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-15d203ac-9269-47db-8375-feee11d1469c,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-7f03b737-9923-4dd0-918e-ed1311b2d300,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-c1d3ddb4-f439-48d6-9280-4b0956e815f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-92fac6e1-401d-4ec9-9996-1a0e24856774,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-8fa25640-77fc-41a0-9eed-5dac8025f507,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-59e8c821-edb2-480c-b127-98f1433c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-068615ac-0b32-42a9-a1ba-cb65d4e9d130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998616196-172.17.0.10-1598641999747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-0b9b4ee5-f86a-4764-bb5f-58399597a368,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-01bd0ea0-6f5d-47b3-b946-45347a6ee5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-b819b98e-3db0-4ae0-ba90-c0956b6f6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-99c36402-2fcf-44bc-9e24-ab0be960f159,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-d411f4c1-1faa-40d7-bfae-85b1b04844a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-7c7d6c44-c9ae-4c98-8f25-263402ba8314,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-d503b687-36f0-4915-a8c2-7196d6fa15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-a599bb4a-61f6-45a4-9e67-19879f8e1f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998616196-172.17.0.10-1598641999747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-0b9b4ee5-f86a-4764-bb5f-58399597a368,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-01bd0ea0-6f5d-47b3-b946-45347a6ee5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-b819b98e-3db0-4ae0-ba90-c0956b6f6ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-99c36402-2fcf-44bc-9e24-ab0be960f159,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-d411f4c1-1faa-40d7-bfae-85b1b04844a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-7c7d6c44-c9ae-4c98-8f25-263402ba8314,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-d503b687-36f0-4915-a8c2-7196d6fa15b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-a599bb4a-61f6-45a4-9e67-19879f8e1f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089613508-172.17.0.10-1598642180704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-59d641e0-c78c-4e60-b5bc-d8e3da17d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-753dc9e0-f448-4d1a-8ac7-35f5da45245d,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-d8736a97-d7e5-4002-bf0c-9f1b1ac9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-0414057a-d3e3-47a1-882b-8b1c5b926e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-dba83aac-7b5c-4aff-b8de-7cca64a64f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-6e6cf872-5dc1-4b69-a6fc-b80a574e755e,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-ed4a70e6-6ee5-4d4c-aa61-41d33fe483d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-6c6c8534-b963-4a97-8ce8-5cb2dca84cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089613508-172.17.0.10-1598642180704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33726,DS-59d641e0-c78c-4e60-b5bc-d8e3da17d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-753dc9e0-f448-4d1a-8ac7-35f5da45245d,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-d8736a97-d7e5-4002-bf0c-9f1b1ac9e614,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-0414057a-d3e3-47a1-882b-8b1c5b926e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-dba83aac-7b5c-4aff-b8de-7cca64a64f98,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-6e6cf872-5dc1-4b69-a6fc-b80a574e755e,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-ed4a70e6-6ee5-4d4c-aa61-41d33fe483d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-6c6c8534-b963-4a97-8ce8-5cb2dca84cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678399369-172.17.0.10-1598642406432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-cfb9f01c-b0f6-48bd-8d1e-003e489d0670,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-383d69eb-e605-40d5-962b-26bbd473b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-54b5a7bd-bbba-4ecc-b019-ed76b8a9d703,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-b7d2a9df-c418-4354-acfc-08a410cd7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f01993a1-cc13-4a00-bce5-d63297a919bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-1227fa3c-2dc5-46fc-bbe1-8ff6c8210f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-53d7c1ea-25af-4f4d-afc8-2ca6e89a4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-ddbc7698-b584-4b69-a893-2aad77e28c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678399369-172.17.0.10-1598642406432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-cfb9f01c-b0f6-48bd-8d1e-003e489d0670,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-383d69eb-e605-40d5-962b-26bbd473b0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-54b5a7bd-bbba-4ecc-b019-ed76b8a9d703,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-b7d2a9df-c418-4354-acfc-08a410cd7d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f01993a1-cc13-4a00-bce5-d63297a919bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-1227fa3c-2dc5-46fc-bbe1-8ff6c8210f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-53d7c1ea-25af-4f4d-afc8-2ca6e89a4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-ddbc7698-b584-4b69-a893-2aad77e28c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697690318-172.17.0.10-1598642545876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-b6ae10ad-9787-491d-8b1d-a4e3dd1ab8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d0122d0b-cdc7-4dc0-8c78-121f2993767b,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-31546ef3-810e-4a70-9db2-ab7607915576,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-55a91038-24d0-4498-861c-888e1cf6d74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-4122e2e0-14f7-42d0-b1bf-c7c23d3a6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-29dd2a05-4fb5-4919-9bf9-c0eb3c524ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-2977c211-47fa-4d1c-b4c4-9a7705e54b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-da7663bf-47d3-4bef-9db0-0a210914ae3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697690318-172.17.0.10-1598642545876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-b6ae10ad-9787-491d-8b1d-a4e3dd1ab8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d0122d0b-cdc7-4dc0-8c78-121f2993767b,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-31546ef3-810e-4a70-9db2-ab7607915576,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-55a91038-24d0-4498-861c-888e1cf6d74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-4122e2e0-14f7-42d0-b1bf-c7c23d3a6bff,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-29dd2a05-4fb5-4919-9bf9-c0eb3c524ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-2977c211-47fa-4d1c-b4c4-9a7705e54b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-da7663bf-47d3-4bef-9db0-0a210914ae3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525252304-172.17.0.10-1598642865616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-b620f4cb-7b6f-4295-a76a-0706ad0eb99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-bdd2391a-b670-4d90-9c52-927d8b5883c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-8d82dc54-9260-4752-a947-99b4c7035c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-3bb434e1-545d-4a6b-b07d-35d2fee54b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-850a9a42-2923-4e1f-b2e7-9d1f3c12cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e46cd22a-a599-4132-ae73-8c21dcc0c599,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-248024b2-e4a9-4979-8379-3a8d45296e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f68253e1-3bf0-4e54-9c09-84c641249703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525252304-172.17.0.10-1598642865616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-b620f4cb-7b6f-4295-a76a-0706ad0eb99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-bdd2391a-b670-4d90-9c52-927d8b5883c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-8d82dc54-9260-4752-a947-99b4c7035c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-3bb434e1-545d-4a6b-b07d-35d2fee54b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-850a9a42-2923-4e1f-b2e7-9d1f3c12cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e46cd22a-a599-4132-ae73-8c21dcc0c599,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-248024b2-e4a9-4979-8379-3a8d45296e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f68253e1-3bf0-4e54-9c09-84c641249703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50835436-172.17.0.10-1598643079763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-b0286df0-1918-422f-8251-a1bd7300c32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-4f9b9258-1ea2-4a6c-942a-ba61e751f992,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-33b1028b-a7f7-41c7-85a2-0aace26e5657,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-fc1ab631-1cbd-49c1-90c7-26ededd0bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e9bf12bb-ca36-46f8-983e-caacc8a67f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-b310affd-5264-42bf-8f7b-372f562653a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-1f13bdeb-277e-4f66-8023-ee3836f82bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-9180d288-a6a0-4e9c-b2d7-7be513fa74eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50835436-172.17.0.10-1598643079763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-b0286df0-1918-422f-8251-a1bd7300c32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-4f9b9258-1ea2-4a6c-942a-ba61e751f992,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-33b1028b-a7f7-41c7-85a2-0aace26e5657,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-fc1ab631-1cbd-49c1-90c7-26ededd0bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e9bf12bb-ca36-46f8-983e-caacc8a67f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-b310affd-5264-42bf-8f7b-372f562653a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-1f13bdeb-277e-4f66-8023-ee3836f82bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-9180d288-a6a0-4e9c-b2d7-7be513fa74eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913068146-172.17.0.10-1598643408907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-7401827b-bbcf-430a-ab05-b3f103064d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-920619c0-d1f3-483b-a83e-8f0f9231e7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4b3d97c5-39f5-489c-ae2f-b5491dad7584,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-8ad150c9-2505-408b-a131-f3a13bfc083e,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-71f8f77c-49a7-4d19-b218-81d655353da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-7c3d72ee-2602-4a78-87ef-68717ab9ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-93adf38a-bc13-43c4-8a39-026082ee6aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-b8c872b8-c5e6-4299-8620-2b0789186a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913068146-172.17.0.10-1598643408907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-7401827b-bbcf-430a-ab05-b3f103064d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-920619c0-d1f3-483b-a83e-8f0f9231e7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4b3d97c5-39f5-489c-ae2f-b5491dad7584,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-8ad150c9-2505-408b-a131-f3a13bfc083e,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-71f8f77c-49a7-4d19-b218-81d655353da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-7c3d72ee-2602-4a78-87ef-68717ab9ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-93adf38a-bc13-43c4-8a39-026082ee6aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-b8c872b8-c5e6-4299-8620-2b0789186a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231821035-172.17.0.10-1598643622877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-c13be6b8-bf5a-4304-bd3e-4d8a8d6fcb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-086306ff-561a-42a7-9ac9-f119dae7e084,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-97815d1e-d1ad-4dfe-b917-7b1e8a7ad3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-1562bb9e-3ea8-469e-b0cd-3830fa4c787b,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-5e19b028-bde5-4991-9865-74f6a33c6d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-4842ea75-5276-48aa-b358-574524fb7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-36214533-69be-48b3-a61e-64409cdd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-8c43df7d-ffff-42fc-9964-227a5e002f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231821035-172.17.0.10-1598643622877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-c13be6b8-bf5a-4304-bd3e-4d8a8d6fcb09,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-086306ff-561a-42a7-9ac9-f119dae7e084,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-97815d1e-d1ad-4dfe-b917-7b1e8a7ad3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-1562bb9e-3ea8-469e-b0cd-3830fa4c787b,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-5e19b028-bde5-4991-9865-74f6a33c6d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-4842ea75-5276-48aa-b358-574524fb7d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-36214533-69be-48b3-a61e-64409cdd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-8c43df7d-ffff-42fc-9964-227a5e002f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987024028-172.17.0.10-1598643773913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-f60dd446-af58-4725-9cb9-965a78064a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4d7d9692-e1cc-456c-8712-8aedccaa978a,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-af7d5404-49a9-458d-8285-5b56fe7e0a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-92e49403-a244-4aef-8ae4-af00c02a9997,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-681d85e2-258b-4c32-900e-0df19f5452f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-a68e034f-b055-4499-a012-dda9aad5e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-00b46788-6152-425a-8200-bfa809c18625,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-c7b26415-ec58-43b2-b208-5913a3213fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987024028-172.17.0.10-1598643773913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-f60dd446-af58-4725-9cb9-965a78064a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4d7d9692-e1cc-456c-8712-8aedccaa978a,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-af7d5404-49a9-458d-8285-5b56fe7e0a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-92e49403-a244-4aef-8ae4-af00c02a9997,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-681d85e2-258b-4c32-900e-0df19f5452f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-a68e034f-b055-4499-a012-dda9aad5e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-00b46788-6152-425a-8200-bfa809c18625,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-c7b26415-ec58-43b2-b208-5913a3213fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532382791-172.17.0.10-1598643844395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-f879b43d-dd69-4146-9e86-633b27f7891f,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-be40e575-f81c-4417-a315-ec9edbe1abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-01583cd6-dbc9-4692-b303-6b1b5d26fb83,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-56ea2320-3bea-403e-8e5f-add2d7e8d661,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-fd01f427-1938-4513-b655-9ab20d59dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-376715b3-cce6-46a9-b598-78b92573b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-85a3b6da-7afd-4965-97de-3c321ae3495c,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-546caee1-5983-43e2-9e40-59d40c0460aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532382791-172.17.0.10-1598643844395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-f879b43d-dd69-4146-9e86-633b27f7891f,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-be40e575-f81c-4417-a315-ec9edbe1abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-01583cd6-dbc9-4692-b303-6b1b5d26fb83,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-56ea2320-3bea-403e-8e5f-add2d7e8d661,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-fd01f427-1938-4513-b655-9ab20d59dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-376715b3-cce6-46a9-b598-78b92573b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-85a3b6da-7afd-4965-97de-3c321ae3495c,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-546caee1-5983-43e2-9e40-59d40c0460aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062173758-172.17.0.10-1598644172384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-4c4524f8-dc78-4730-99b2-8c320e4c30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-73a15931-f832-4a4f-84b5-d65e843382f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-cefd17f8-6e93-427e-a16f-c05755f9e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-1ba3cb0b-f35c-49c1-a330-34250a4ec730,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-23a3f403-8f4e-43f7-a11f-3156f89bdcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6e7f804d-b62f-44ff-800f-bf795d60d254,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-e2afbea7-5904-4fe5-b945-5d119850e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-276d044f-ddb8-4c1a-acf1-e140eadcbde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062173758-172.17.0.10-1598644172384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-4c4524f8-dc78-4730-99b2-8c320e4c30f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-73a15931-f832-4a4f-84b5-d65e843382f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-cefd17f8-6e93-427e-a16f-c05755f9e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-1ba3cb0b-f35c-49c1-a330-34250a4ec730,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-23a3f403-8f4e-43f7-a11f-3156f89bdcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6e7f804d-b62f-44ff-800f-bf795d60d254,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-e2afbea7-5904-4fe5-b945-5d119850e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-276d044f-ddb8-4c1a-acf1-e140eadcbde7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5214
