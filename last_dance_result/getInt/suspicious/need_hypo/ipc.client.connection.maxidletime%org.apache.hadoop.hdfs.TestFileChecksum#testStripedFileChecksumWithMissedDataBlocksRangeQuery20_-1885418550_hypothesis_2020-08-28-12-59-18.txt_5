reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497608721-172.17.0.18-1598619673453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-5e4f0d54-d7e5-48a7-9285-ce4b14f4f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-01469024-2c40-45c2-9f99-06ed2429fa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-a74642ad-cc26-49c1-8217-e9e6bbcfb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-45fed50b-1b76-4a6f-b8e6-7fbfe57ef977,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-94d328f5-b42c-4478-b296-afc470c5c581,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-2979cb44-0891-45f5-8274-512f7bf49cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-c52201ab-1609-4af5-a316-8d5ec3ecfdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-41d7e693-ae9d-465c-9720-f4803fe1553b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497608721-172.17.0.18-1598619673453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-5e4f0d54-d7e5-48a7-9285-ce4b14f4f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-01469024-2c40-45c2-9f99-06ed2429fa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-a74642ad-cc26-49c1-8217-e9e6bbcfb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-45fed50b-1b76-4a6f-b8e6-7fbfe57ef977,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-94d328f5-b42c-4478-b296-afc470c5c581,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-2979cb44-0891-45f5-8274-512f7bf49cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-c52201ab-1609-4af5-a316-8d5ec3ecfdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-41d7e693-ae9d-465c-9720-f4803fe1553b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184520585-172.17.0.18-1598620494144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-32ce7144-bc0f-4ed4-81a2-8ea506865123,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b3bef961-741d-40e1-9c43-9a155cbfde9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-b3759288-1856-4a7c-8e50-427ca0b420c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-65e9595d-20ee-47db-b9b2-897325fe7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-43c4a5ed-4c79-486c-a7d4-91258ed14d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-13e07ac3-1585-4467-8d79-afc44926ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-2de0531b-8c34-45dd-ae4d-14c2864abfac,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e9178b01-8175-45e0-9740-2a0caad0a84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184520585-172.17.0.18-1598620494144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-32ce7144-bc0f-4ed4-81a2-8ea506865123,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-b3bef961-741d-40e1-9c43-9a155cbfde9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-b3759288-1856-4a7c-8e50-427ca0b420c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-65e9595d-20ee-47db-b9b2-897325fe7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-43c4a5ed-4c79-486c-a7d4-91258ed14d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-13e07ac3-1585-4467-8d79-afc44926ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-2de0531b-8c34-45dd-ae4d-14c2864abfac,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e9178b01-8175-45e0-9740-2a0caad0a84a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580637018-172.17.0.18-1598620597908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-2a6b40d6-dccf-4987-88d3-a23d792fc320,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-01e04c58-ed1e-478a-afeb-bb17d09315bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-2a240dfb-8f1b-407a-b24f-6fe6bd344f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-30936708-2c30-4841-950b-145876a7648c,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-f3c17fe7-5e40-42c2-adc6-c0d4dcd8a6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-75467fe5-ebca-4a35-8b24-c089c47e32e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-904c9cf9-e22e-4d33-8cab-69fc4f2567d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-3fec731e-17bb-4294-a3e6-b97e86870651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580637018-172.17.0.18-1598620597908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33681,DS-2a6b40d6-dccf-4987-88d3-a23d792fc320,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-01e04c58-ed1e-478a-afeb-bb17d09315bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-2a240dfb-8f1b-407a-b24f-6fe6bd344f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-30936708-2c30-4841-950b-145876a7648c,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-f3c17fe7-5e40-42c2-adc6-c0d4dcd8a6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-75467fe5-ebca-4a35-8b24-c089c47e32e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-904c9cf9-e22e-4d33-8cab-69fc4f2567d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-3fec731e-17bb-4294-a3e6-b97e86870651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777320244-172.17.0.18-1598620913857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-5ae11d93-440e-46de-a1a1-e40be568e8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-490a9ea9-75a7-44a9-81b8-88d92bd92d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-f25c643b-4e97-48c3-a567-7814b65e8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-cd23fc45-7e7b-4ac9-bb80-2d78186f1d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e4ffe5a9-91b5-4c93-ad87-815baf932ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-e74faa2f-67b3-452e-8a11-74543a715bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-36ac605c-9e5d-4eb6-b970-bb3c1f6978dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-adaf9f4c-65db-499b-b353-24dccdfae6df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777320244-172.17.0.18-1598620913857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43932,DS-5ae11d93-440e-46de-a1a1-e40be568e8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-490a9ea9-75a7-44a9-81b8-88d92bd92d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-f25c643b-4e97-48c3-a567-7814b65e8abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-cd23fc45-7e7b-4ac9-bb80-2d78186f1d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e4ffe5a9-91b5-4c93-ad87-815baf932ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-e74faa2f-67b3-452e-8a11-74543a715bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-36ac605c-9e5d-4eb6-b970-bb3c1f6978dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-adaf9f4c-65db-499b-b353-24dccdfae6df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364102033-172.17.0.18-1598621470091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-2df3b9e7-4539-498a-992f-4222700829ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-6c842351-6645-4774-8405-6941a9572f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-9a8f475c-c317-42da-aa4c-3512df4c47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-defabbf3-4a59-4f6c-b5de-e7258200150b,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-e07784bb-a168-47d9-a633-6fdd0c0e0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-76e42706-034a-4520-9d81-4e11cafaffa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-4e8acd82-ad31-455d-ad84-4544d6541a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-e6127a41-ca9f-43cb-a376-4901f2bc774a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364102033-172.17.0.18-1598621470091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-2df3b9e7-4539-498a-992f-4222700829ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-6c842351-6645-4774-8405-6941a9572f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-9a8f475c-c317-42da-aa4c-3512df4c47e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-defabbf3-4a59-4f6c-b5de-e7258200150b,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-e07784bb-a168-47d9-a633-6fdd0c0e0c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-76e42706-034a-4520-9d81-4e11cafaffa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-4e8acd82-ad31-455d-ad84-4544d6541a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-e6127a41-ca9f-43cb-a376-4901f2bc774a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838731831-172.17.0.18-1598621886524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32885,DS-0569c267-23a2-4c9b-9e1d-499da4b6ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-a116d84a-483f-44f8-82f9-c88659b7bed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-7a533aa7-1f0a-4f6f-a86a-b3edf908c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-8a9b7020-4d83-46b5-8bff-e0a1de44835c,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-90894885-4b4c-4353-bba6-b2263c641e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-ab1d2a9b-5a07-4aba-a143-5a9a2ee39ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-4f236306-c2c5-4db6-8c77-5ef08b0c8d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-6acdf2f3-b247-4b37-8afd-4292b9e91ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838731831-172.17.0.18-1598621886524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32885,DS-0569c267-23a2-4c9b-9e1d-499da4b6ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-a116d84a-483f-44f8-82f9-c88659b7bed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-7a533aa7-1f0a-4f6f-a86a-b3edf908c57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-8a9b7020-4d83-46b5-8bff-e0a1de44835c,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-90894885-4b4c-4353-bba6-b2263c641e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-ab1d2a9b-5a07-4aba-a143-5a9a2ee39ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-4f236306-c2c5-4db6-8c77-5ef08b0c8d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-6acdf2f3-b247-4b37-8afd-4292b9e91ce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661447486-172.17.0.18-1598622104533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45080,DS-1d16cacd-0453-48fb-99ed-f6268ae05c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-afdb42c6-dc02-49a5-a595-e3279a7d9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-31709528-2173-497c-a359-51496f03a474,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-27fe966b-ba42-4adb-a43d-b6f29b498e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-edbfc9b5-1b0e-46dd-a79b-181bbd18348e,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-64c855ed-c521-4f18-9e36-39ec059147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-ecea4ba9-a3f2-43a3-9f08-cc7ecc6c7d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-cd4b63ca-fbb3-450c-b98f-ff306019926f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661447486-172.17.0.18-1598622104533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45080,DS-1d16cacd-0453-48fb-99ed-f6268ae05c95,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-afdb42c6-dc02-49a5-a595-e3279a7d9d00,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-31709528-2173-497c-a359-51496f03a474,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-27fe966b-ba42-4adb-a43d-b6f29b498e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-edbfc9b5-1b0e-46dd-a79b-181bbd18348e,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-64c855ed-c521-4f18-9e36-39ec059147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-ecea4ba9-a3f2-43a3-9f08-cc7ecc6c7d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-cd4b63ca-fbb3-450c-b98f-ff306019926f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967758725-172.17.0.18-1598622196252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-3e374848-8c23-4425-a9f7-052adfe28e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-3ba8b598-adc2-4ff4-8852-8dcdb86f62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-e364a867-d020-4782-8d24-fb6967561312,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-00729ee3-695a-4853-bad5-9dfb0f2210fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-2c98d199-0774-4e2c-a53c-7360e00dc824,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-51252e63-b429-4c00-bd3b-4751c8055855,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-0a52fc93-ad3a-43ce-8a6b-5c62c4ae90bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-90bc869e-575b-429b-a013-58a84e9eb9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967758725-172.17.0.18-1598622196252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-3e374848-8c23-4425-a9f7-052adfe28e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-3ba8b598-adc2-4ff4-8852-8dcdb86f62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-e364a867-d020-4782-8d24-fb6967561312,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-00729ee3-695a-4853-bad5-9dfb0f2210fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-2c98d199-0774-4e2c-a53c-7360e00dc824,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-51252e63-b429-4c00-bd3b-4751c8055855,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-0a52fc93-ad3a-43ce-8a6b-5c62c4ae90bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-90bc869e-575b-429b-a013-58a84e9eb9d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557849036-172.17.0.18-1598622364493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-8c226cff-d676-49a8-b849-49027b6e4d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-e9c5cbde-a143-44a1-a4ed-d597857976b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-cc6e948b-8d7a-40bd-bca2-aad13e02139b,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-94ebcd81-970a-4bbd-810f-1e74a2a98cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-e825e1cc-9c32-42ad-9916-b15c315528f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-53daea64-f74a-4d3e-8e96-0329dce6765e,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-8865f1ac-b7b8-418d-912c-f1e72758eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-2111b8da-177b-4f67-9f17-3205fc8aef5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557849036-172.17.0.18-1598622364493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-8c226cff-d676-49a8-b849-49027b6e4d74,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-e9c5cbde-a143-44a1-a4ed-d597857976b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-cc6e948b-8d7a-40bd-bca2-aad13e02139b,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-94ebcd81-970a-4bbd-810f-1e74a2a98cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-e825e1cc-9c32-42ad-9916-b15c315528f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-53daea64-f74a-4d3e-8e96-0329dce6765e,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-8865f1ac-b7b8-418d-912c-f1e72758eaef,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-2111b8da-177b-4f67-9f17-3205fc8aef5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774842311-172.17.0.18-1598622676601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-81b41870-1167-4cce-ae61-40fbf640c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-6d224c58-ffc9-4c27-a2ae-57e33594d493,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-7cfae15b-f6b8-4c53-b28e-225f22fe3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-85c72af3-213a-40d1-a64f-fdd80d6671d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-7609d655-c48a-453c-8d4e-3c07857e43cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-29edf8c5-998b-4823-b5f2-add2f83cc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ba08ee1a-cf68-437d-83d9-b72c56607c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6a1885c7-9fcd-449a-9dc2-6778a4cde79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774842311-172.17.0.18-1598622676601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-81b41870-1167-4cce-ae61-40fbf640c6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-6d224c58-ffc9-4c27-a2ae-57e33594d493,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-7cfae15b-f6b8-4c53-b28e-225f22fe3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-85c72af3-213a-40d1-a64f-fdd80d6671d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-7609d655-c48a-453c-8d4e-3c07857e43cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-29edf8c5-998b-4823-b5f2-add2f83cc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-ba08ee1a-cf68-437d-83d9-b72c56607c99,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6a1885c7-9fcd-449a-9dc2-6778a4cde79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128577311-172.17.0.18-1598622770690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-9e5274c7-63f9-4bd5-b3d1-6bb1192e7232,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-b55e4dcb-b252-48c0-a74b-3c4f2b6f1112,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-0bb59ad6-1532-4b07-8b24-e0bb7b69d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-86f770b1-94f3-4015-b1c4-59b4ef77a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-ab6a4f0d-e3f5-465f-9b3a-ec3010a57dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-01823970-892a-4959-8858-e60c0b82cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-2ed17aca-5a9c-4b2d-857e-fb1bf72e9200,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-08fd9522-9562-456f-9e77-b727e56c0ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128577311-172.17.0.18-1598622770690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-9e5274c7-63f9-4bd5-b3d1-6bb1192e7232,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-b55e4dcb-b252-48c0-a74b-3c4f2b6f1112,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-0bb59ad6-1532-4b07-8b24-e0bb7b69d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-86f770b1-94f3-4015-b1c4-59b4ef77a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-ab6a4f0d-e3f5-465f-9b3a-ec3010a57dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-01823970-892a-4959-8858-e60c0b82cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-2ed17aca-5a9c-4b2d-857e-fb1bf72e9200,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-08fd9522-9562-456f-9e77-b727e56c0ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205436884-172.17.0.18-1598622980896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-ba22e693-4138-4134-80c3-69b75be2951b,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-09d4c404-e16a-4d10-86c0-9a0cf4f935f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ce5eba74-4555-4b97-be07-0732aeddb144,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-e0b3fbde-2196-443c-ab6c-6839c953d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-ff12747a-e510-4c36-8152-21840726cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-367a225c-bc2f-4cad-bcb3-0853157ed2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-b451e797-b238-4226-ba70-d0f0f67ded9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8b8dd9d6-90b4-4cd0-a511-f3562d4ca592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205436884-172.17.0.18-1598622980896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-ba22e693-4138-4134-80c3-69b75be2951b,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-09d4c404-e16a-4d10-86c0-9a0cf4f935f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ce5eba74-4555-4b97-be07-0732aeddb144,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-e0b3fbde-2196-443c-ab6c-6839c953d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-ff12747a-e510-4c36-8152-21840726cefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-367a225c-bc2f-4cad-bcb3-0853157ed2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-b451e797-b238-4226-ba70-d0f0f67ded9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-8b8dd9d6-90b4-4cd0-a511-f3562d4ca592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583006827-172.17.0.18-1598623048719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-67d99b44-b080-40b3-8aee-7001baeb93ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-752e5550-1ab4-438d-8480-e0cfb9dc2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-55737d1c-49cd-4554-8100-635aa89eb346,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-8bc8f127-6ee3-4fb5-a86a-01a3faad4023,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-6e2117e4-262c-44d7-a418-ce4315b132a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-a9e87e7e-b55f-455c-b47c-44e1ea601ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-feb3feef-8638-4e02-b454-8e1cd851c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-932d01d5-9c3c-4566-9f99-8e9022344a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583006827-172.17.0.18-1598623048719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40309,DS-67d99b44-b080-40b3-8aee-7001baeb93ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-752e5550-1ab4-438d-8480-e0cfb9dc2c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-55737d1c-49cd-4554-8100-635aa89eb346,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-8bc8f127-6ee3-4fb5-a86a-01a3faad4023,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-6e2117e4-262c-44d7-a418-ce4315b132a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-a9e87e7e-b55f-455c-b47c-44e1ea601ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-feb3feef-8638-4e02-b454-8e1cd851c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-932d01d5-9c3c-4566-9f99-8e9022344a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484028372-172.17.0.18-1598623140072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-da4f48a7-b2fe-4c72-bd9f-53b9afd75adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-12ca2792-c609-4352-b8ca-a8a097addcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-651910f8-14be-40be-b7e3-2fe2c21ce4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-6107bd76-cb4c-43cd-97cb-038315038685,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a9470796-07f4-4721-b5a7-019d54ee1ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-27ac53a3-59ef-44a3-b325-60da039da448,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-c9af9af1-8e7d-4c7f-ae9f-42b85d26e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-a0e7e0cf-cdae-46ef-888a-13bd8a53f183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484028372-172.17.0.18-1598623140072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-da4f48a7-b2fe-4c72-bd9f-53b9afd75adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-12ca2792-c609-4352-b8ca-a8a097addcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-651910f8-14be-40be-b7e3-2fe2c21ce4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-6107bd76-cb4c-43cd-97cb-038315038685,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a9470796-07f4-4721-b5a7-019d54ee1ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-27ac53a3-59ef-44a3-b325-60da039da448,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-c9af9af1-8e7d-4c7f-ae9f-42b85d26e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-a0e7e0cf-cdae-46ef-888a-13bd8a53f183,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341451101-172.17.0.18-1598623178166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-cd4fe8a6-2c30-4118-968a-d0e0a888255f,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-3668e8ec-9f4b-42b5-84ce-537bf448b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5487ce0f-cd1a-40cd-ac12-9b3bb3daff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-d13a9492-310f-4ce1-8453-e1df429a5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-4338c16f-bdd1-4892-861a-386ed41acdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-c13369e5-af9f-4a41-a2fa-da8c95ccc5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d17383a0-f955-478b-8bd3-887bd8c3ee9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-e66403d3-0def-4a93-8773-ad737e019ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341451101-172.17.0.18-1598623178166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-cd4fe8a6-2c30-4118-968a-d0e0a888255f,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-3668e8ec-9f4b-42b5-84ce-537bf448b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5487ce0f-cd1a-40cd-ac12-9b3bb3daff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-d13a9492-310f-4ce1-8453-e1df429a5d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-4338c16f-bdd1-4892-861a-386ed41acdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-c13369e5-af9f-4a41-a2fa-da8c95ccc5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d17383a0-f955-478b-8bd3-887bd8c3ee9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-e66403d3-0def-4a93-8773-ad737e019ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944524355-172.17.0.18-1598624170297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-de316d61-2a85-451c-a483-4311ed8cb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-bb76168f-e859-48ef-a759-2570d3e02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-9fd3ecf7-8956-45ed-ad07-225b03a0df25,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-bbcaa207-7002-4449-a311-edccef6b010b,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b342b435-2b2a-4711-bcb9-d1cf343321fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-24caa635-1b32-4861-aa0d-0fa781cca01c,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-9b9b8248-8c36-4222-84a6-17ff8fd4ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-22d246c3-9a47-4ed7-8803-9a06d5aa05c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944524355-172.17.0.18-1598624170297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-de316d61-2a85-451c-a483-4311ed8cb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-bb76168f-e859-48ef-a759-2570d3e02b96,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-9fd3ecf7-8956-45ed-ad07-225b03a0df25,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-bbcaa207-7002-4449-a311-edccef6b010b,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b342b435-2b2a-4711-bcb9-d1cf343321fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-24caa635-1b32-4861-aa0d-0fa781cca01c,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-9b9b8248-8c36-4222-84a6-17ff8fd4ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-22d246c3-9a47-4ed7-8803-9a06d5aa05c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5028
