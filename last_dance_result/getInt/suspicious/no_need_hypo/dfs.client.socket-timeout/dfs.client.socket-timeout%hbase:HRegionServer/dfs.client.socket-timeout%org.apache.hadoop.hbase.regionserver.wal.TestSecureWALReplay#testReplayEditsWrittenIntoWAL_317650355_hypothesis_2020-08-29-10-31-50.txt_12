reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-10a9eb85-4fb4-4f83-9007-febe0290591a,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-f6bdb631-ea32-409b-926b-f57f947f298a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33581,DS-f6bdb631-ea32-409b-926b-f57f947f298a,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-10a9eb85-4fb4-4f83-9007-febe0290591a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38381,DS-10a9eb85-4fb4-4f83-9007-febe0290591a,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-f6bdb631-ea32-409b-926b-f57f947f298a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33581,DS-f6bdb631-ea32-409b-926b-f57f947f298a,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-10a9eb85-4fb4-4f83-9007-febe0290591a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-6832c9d9-1656-4ba5-a805-8190c39fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1a9bdb8-97a4-4f7f-90e5-6cb9c8766fd9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-6832c9d9-1656-4ba5-a805-8190c39fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1a9bdb8-97a4-4f7f-90e5-6cb9c8766fd9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-6832c9d9-1656-4ba5-a805-8190c39fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1a9bdb8-97a4-4f7f-90e5-6cb9c8766fd9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-6832c9d9-1656-4ba5-a805-8190c39fc7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-a1a9bdb8-97a4-4f7f-90e5-6cb9c8766fd9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-43e8f118-d3db-48ec-b769-d3cb793b36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-37fa3a54-b280-415f-badc-3c0366e87328,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-43e8f118-d3db-48ec-b769-d3cb793b36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-37fa3a54-b280-415f-badc-3c0366e87328,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-43e8f118-d3db-48ec-b769-d3cb793b36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-37fa3a54-b280-415f-badc-3c0366e87328,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-43e8f118-d3db-48ec-b769-d3cb793b36f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-37fa3a54-b280-415f-badc-3c0366e87328,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-9b275b28-2a89-453e-a32f-9dfa3a9d2d72,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-0b5ddabd-1a4c-4477-8c26-797cd4b31901,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-0b5ddabd-1a4c-4477-8c26-797cd4b31901,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-9b275b28-2a89-453e-a32f-9dfa3a9d2d72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36619,DS-9b275b28-2a89-453e-a32f-9dfa3a9d2d72,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-0b5ddabd-1a4c-4477-8c26-797cd4b31901,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-0b5ddabd-1a4c-4477-8c26-797cd4b31901,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-9b275b28-2a89-453e-a32f-9dfa3a9d2d72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-598effa1-b9f5-48cc-a6a2-61f8c0abf45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-bdb45396-3de6-4cef-bf06-9742daea9ec5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33313,DS-bdb45396-3de6-4cef-bf06-9742daea9ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-598effa1-b9f5-48cc-a6a2-61f8c0abf45c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-598effa1-b9f5-48cc-a6a2-61f8c0abf45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-bdb45396-3de6-4cef-bf06-9742daea9ec5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33313,DS-bdb45396-3de6-4cef-bf06-9742daea9ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-598effa1-b9f5-48cc-a6a2-61f8c0abf45c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f6b3163-eb32-4110-a941-94d724ef4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-25045856-8e9e-4493-9754-697e52f486c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f6b3163-eb32-4110-a941-94d724ef4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-25045856-8e9e-4493-9754-697e52f486c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f6b3163-eb32-4110-a941-94d724ef4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-25045856-8e9e-4493-9754-697e52f486c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-4f6b3163-eb32-4110-a941-94d724ef4e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-25045856-8e9e-4493-9754-697e52f486c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-0f9bdcd0-6912-4f19-b203-37a0b249374f,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ac664e3-61e0-4b04-a785-d9331220992f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-0f9bdcd0-6912-4f19-b203-37a0b249374f,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ac664e3-61e0-4b04-a785-d9331220992f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-0f9bdcd0-6912-4f19-b203-37a0b249374f,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ac664e3-61e0-4b04-a785-d9331220992f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-0f9bdcd0-6912-4f19-b203-37a0b249374f,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ac664e3-61e0-4b04-a785-d9331220992f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-f1539192-6831-4294-9f8c-21dc118360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-26b05b19-5512-4c25-9748-2217116a5898,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-f1539192-6831-4294-9f8c-21dc118360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-26b05b19-5512-4c25-9748-2217116a5898,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-f1539192-6831-4294-9f8c-21dc118360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-26b05b19-5512-4c25-9748-2217116a5898,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42808,DS-f1539192-6831-4294-9f8c-21dc118360ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-26b05b19-5512-4c25-9748-2217116a5898,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43474,DS-7c2876c8-d19c-4cdc-b9d9-60bb1462dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b58ee571-8eb7-4e9b-988d-52ed1e006593,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-b58ee571-8eb7-4e9b-988d-52ed1e006593,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-7c2876c8-d19c-4cdc-b9d9-60bb1462dbe0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43474,DS-7c2876c8-d19c-4cdc-b9d9-60bb1462dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-b58ee571-8eb7-4e9b-988d-52ed1e006593,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-b58ee571-8eb7-4e9b-988d-52ed1e006593,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-7c2876c8-d19c-4cdc-b9d9-60bb1462dbe0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-0792844d-a659-4c39-ab99-1e9e7f88a186,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-28a79c6e-bd09-49ad-8feb-d42c21cab5a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-28a79c6e-bd09-49ad-8feb-d42c21cab5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-0792844d-a659-4c39-ab99-1e9e7f88a186,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33692,DS-0792844d-a659-4c39-ab99-1e9e7f88a186,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-28a79c6e-bd09-49ad-8feb-d42c21cab5a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-28a79c6e-bd09-49ad-8feb-d42c21cab5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-0792844d-a659-4c39-ab99-1e9e7f88a186,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1615
