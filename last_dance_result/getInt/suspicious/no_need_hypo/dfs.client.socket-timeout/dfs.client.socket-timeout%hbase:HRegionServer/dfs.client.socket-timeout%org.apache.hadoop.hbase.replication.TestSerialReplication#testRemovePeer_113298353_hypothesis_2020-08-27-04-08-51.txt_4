reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9e7e79ad-c384-427d-bc35-270f1715e580,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6a702617-af41-4b0a-8135-dbb0c9fd58b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-6a702617-af41-4b0a-8135-dbb0c9fd58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9e7e79ad-c384-427d-bc35-270f1715e580,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9e7e79ad-c384-427d-bc35-270f1715e580,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6a702617-af41-4b0a-8135-dbb0c9fd58b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-6a702617-af41-4b0a-8135-dbb0c9fd58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9e7e79ad-c384-427d-bc35-270f1715e580,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-73341036-ec32-4f9a-9d1b-a05c012ba532,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-82af23c7-f14a-435b-9c1b-93d5d198734f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-73341036-ec32-4f9a-9d1b-a05c012ba532,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-82af23c7-f14a-435b-9c1b-93d5d198734f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-73341036-ec32-4f9a-9d1b-a05c012ba532,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-82af23c7-f14a-435b-9c1b-93d5d198734f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-73341036-ec32-4f9a-9d1b-a05c012ba532,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-82af23c7-f14a-435b-9c1b-93d5d198734f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-a331cd3a-a129-41dd-92c7-1ffbb3e8b140,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-7f838abc-7360-4953-bbfb-2cd441c022ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-a331cd3a-a129-41dd-92c7-1ffbb3e8b140,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-7f838abc-7360-4953-bbfb-2cd441c022ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-a331cd3a-a129-41dd-92c7-1ffbb3e8b140,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-7f838abc-7360-4953-bbfb-2cd441c022ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43991,DS-a331cd3a-a129-41dd-92c7-1ffbb3e8b140,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-7f838abc-7360-4953-bbfb-2cd441c022ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-3fe051d0-6915-4fc1-8018-7f0df830e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0bbea217-cc0d-4740-959f-3213ad34b9dc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-3fe051d0-6915-4fc1-8018-7f0df830e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0bbea217-cc0d-4740-959f-3213ad34b9dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-3fe051d0-6915-4fc1-8018-7f0df830e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0bbea217-cc0d-4740-959f-3213ad34b9dc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-3fe051d0-6915-4fc1-8018-7f0df830e07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0bbea217-cc0d-4740-959f-3213ad34b9dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-27eaca99-bc7e-4e20-aab9-280ae1f76d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-27218fd0-6c65-4ff4-bb06-775d812c5cef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-27218fd0-6c65-4ff4-bb06-775d812c5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-27eaca99-bc7e-4e20-aab9-280ae1f76d19,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32768,DS-27eaca99-bc7e-4e20-aab9-280ae1f76d19,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-27218fd0-6c65-4ff4-bb06-775d812c5cef,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-27218fd0-6c65-4ff4-bb06-775d812c5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-27eaca99-bc7e-4e20-aab9-280ae1f76d19,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-ed8ebc53-737f-4eb8-a6ee-065a9ba99a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a82e75c7-35a3-4a67-8319-ebf1103b89e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-ed8ebc53-737f-4eb8-a6ee-065a9ba99a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a82e75c7-35a3-4a67-8319-ebf1103b89e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-ed8ebc53-737f-4eb8-a6ee-065a9ba99a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a82e75c7-35a3-4a67-8319-ebf1103b89e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-ed8ebc53-737f-4eb8-a6ee-065a9ba99a31,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-a82e75c7-35a3-4a67-8319-ebf1103b89e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc6fa86b-9e36-4d7d-8e1c-1b6c77baf64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-938af129-da67-47f6-9482-e85c8c55d6db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-938af129-da67-47f6-9482-e85c8c55d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc6fa86b-9e36-4d7d-8e1c-1b6c77baf64c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc6fa86b-9e36-4d7d-8e1c-1b6c77baf64c,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-938af129-da67-47f6-9482-e85c8c55d6db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-938af129-da67-47f6-9482-e85c8c55d6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-fc6fa86b-9e36-4d7d-8e1c-1b6c77baf64c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-73213dd4-98b0-4a55-b75b-52a35c0335e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e516c21d-5c8a-4e20-af1e-c7481de1db6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-73213dd4-98b0-4a55-b75b-52a35c0335e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e516c21d-5c8a-4e20-af1e-c7481de1db6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-73213dd4-98b0-4a55-b75b-52a35c0335e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e516c21d-5c8a-4e20-af1e-c7481de1db6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-73213dd4-98b0-4a55-b75b-52a35c0335e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e516c21d-5c8a-4e20-af1e-c7481de1db6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-e64187fe-066e-4087-aef9-b51d8dc35702,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-259482da-b2c5-4374-83cf-91dda2cd55a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-259482da-b2c5-4374-83cf-91dda2cd55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-e64187fe-066e-4087-aef9-b51d8dc35702,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-e64187fe-066e-4087-aef9-b51d8dc35702,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-259482da-b2c5-4374-83cf-91dda2cd55a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43688,DS-259482da-b2c5-4374-83cf-91dda2cd55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-e64187fe-066e-4087-aef9-b51d8dc35702,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-162ba8f2-801e-4108-a928-1af18edcc7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f624fee4-cdce-41ce-8ed2-14f2166ff71c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-162ba8f2-801e-4108-a928-1af18edcc7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f624fee4-cdce-41ce-8ed2-14f2166ff71c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-162ba8f2-801e-4108-a928-1af18edcc7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f624fee4-cdce-41ce-8ed2-14f2166ff71c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-162ba8f2-801e-4108-a928-1af18edcc7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-f624fee4-cdce-41ce-8ed2-14f2166ff71c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2062
