reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-6f89c877-a5ab-484a-8ca2-96c65d2d79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-5632225b-4c50-4c33-989e-5869f64b0e5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-6f89c877-a5ab-484a-8ca2-96c65d2d79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-5632225b-4c50-4c33-989e-5869f64b0e5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-6f89c877-a5ab-484a-8ca2-96c65d2d79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-5632225b-4c50-4c33-989e-5869f64b0e5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-6f89c877-a5ab-484a-8ca2-96c65d2d79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-5632225b-4c50-4c33-989e-5869f64b0e5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-827cf2b7-325e-4564-a4fa-d0e7e6f508c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-dd0fddd3-7c73-4fe2-9602-a18085d8be8f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-dd0fddd3-7c73-4fe2-9602-a18085d8be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-827cf2b7-325e-4564-a4fa-d0e7e6f508c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-827cf2b7-325e-4564-a4fa-d0e7e6f508c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-dd0fddd3-7c73-4fe2-9602-a18085d8be8f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-dd0fddd3-7c73-4fe2-9602-a18085d8be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-827cf2b7-325e-4564-a4fa-d0e7e6f508c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32846,DS-098d6e07-300a-4ea3-8e11-d4b31fd818fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-50460061-0c92-4cd0-8310-74d8118edc25,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38533,DS-50460061-0c92-4cd0-8310-74d8118edc25,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-098d6e07-300a-4ea3-8e11-d4b31fd818fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-bf027d0e-7481-4f1d-b809-70ad60fde732,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-afcc3635-34b6-45a5-b848-1610c21c98f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-bf027d0e-7481-4f1d-b809-70ad60fde732,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-afcc3635-34b6-45a5-b848-1610c21c98f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-bf027d0e-7481-4f1d-b809-70ad60fde732,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-afcc3635-34b6-45a5-b848-1610c21c98f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-bf027d0e-7481-4f1d-b809-70ad60fde732,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-afcc3635-34b6-45a5-b848-1610c21c98f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-7e694d15-0e3f-40f6-9a05-2c1941b66e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7af42651-1516-4e18-8de3-9192ac1534bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-7e694d15-0e3f-40f6-9a05-2c1941b66e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7af42651-1516-4e18-8de3-9192ac1534bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-7e694d15-0e3f-40f6-9a05-2c1941b66e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7af42651-1516-4e18-8de3-9192ac1534bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-7e694d15-0e3f-40f6-9a05-2c1941b66e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7af42651-1516-4e18-8de3-9192ac1534bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-e9ee6499-0dda-4962-a4df-85498cdc3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-daaed42a-cbef-4d56-bb3e-10fe9f8eac63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-e9ee6499-0dda-4962-a4df-85498cdc3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-daaed42a-cbef-4d56-bb3e-10fe9f8eac63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-e9ee6499-0dda-4962-a4df-85498cdc3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-daaed42a-cbef-4d56-bb3e-10fe9f8eac63,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-e9ee6499-0dda-4962-a4df-85498cdc3cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-daaed42a-cbef-4d56-bb3e-10fe9f8eac63,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-3666c5f7-19cf-43f7-b29f-0e210fc98775,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-eff5b72b-6234-4829-8eab-98041c728a3b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-3666c5f7-19cf-43f7-b29f-0e210fc98775,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-eff5b72b-6234-4829-8eab-98041c728a3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-3666c5f7-19cf-43f7-b29f-0e210fc98775,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-eff5b72b-6234-4829-8eab-98041c728a3b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-3666c5f7-19cf-43f7-b29f-0e210fc98775,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-eff5b72b-6234-4829-8eab-98041c728a3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-edf762e3-7bc9-40e0-adfc-035f5cfa831e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8703811d-5924-46e7-9b8c-c793ed27713b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-edf762e3-7bc9-40e0-adfc-035f5cfa831e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8703811d-5924-46e7-9b8c-c793ed27713b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-edf762e3-7bc9-40e0-adfc-035f5cfa831e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8703811d-5924-46e7-9b8c-c793ed27713b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-edf762e3-7bc9-40e0-adfc-035f5cfa831e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8703811d-5924-46e7-9b8c-c793ed27713b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43341,DS-0ab3db51-f930-48ac-baa6-cda10ae1b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-28440238-fa8e-477c-9c6e-adcec8972ae3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43341,DS-0ab3db51-f930-48ac-baa6-cda10ae1b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-28440238-fa8e-477c-9c6e-adcec8972ae3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43341,DS-0ab3db51-f930-48ac-baa6-cda10ae1b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-28440238-fa8e-477c-9c6e-adcec8972ae3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43341,DS-0ab3db51-f930-48ac-baa6-cda10ae1b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-28440238-fa8e-477c-9c6e-adcec8972ae3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-0878801e-4a9b-49b6-895f-6c8255d487a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-cb9a821b-39c0-40aa-9996-5c9c50c8cc24,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-0878801e-4a9b-49b6-895f-6c8255d487a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-cb9a821b-39c0-40aa-9996-5c9c50c8cc24,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-0878801e-4a9b-49b6-895f-6c8255d487a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-cb9a821b-39c0-40aa-9996-5c9c50c8cc24,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-0878801e-4a9b-49b6-895f-6c8255d487a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-cb9a821b-39c0-40aa-9996-5c9c50c8cc24,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45805,DS-3debc8fc-1b98-4496-ba09-95e1628c1836,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-6cd8c0f4-1bf5-4700-8b3b-c3d07cf1b732,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46455,DS-6cd8c0f4-1bf5-4700-8b3b-c3d07cf1b732,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-3debc8fc-1b98-4496-ba09-95e1628c1836,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-34bf1265-a541-44c2-b601-e220681c9373,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-c1e3061b-4bbf-4b80-a5e3-8cbd46bda13f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-c1e3061b-4bbf-4b80-a5e3-8cbd46bda13f,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-34bf1265-a541-44c2-b601-e220681c9373,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-34bf1265-a541-44c2-b601-e220681c9373,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-c1e3061b-4bbf-4b80-a5e3-8cbd46bda13f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-c1e3061b-4bbf-4b80-a5e3-8cbd46bda13f,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-34bf1265-a541-44c2-b601-e220681c9373,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-c434b5a6-c16a-4a53-bc5b-dfe15c5f09ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-d1f22d23-cf09-4e63-9d6c-86c5b580f3e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-c434b5a6-c16a-4a53-bc5b-dfe15c5f09ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-d1f22d23-cf09-4e63-9d6c-86c5b580f3e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-6790212b-90f2-41ca-a7fa-63a9a041d949,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-55b64d05-7430-46c3-be3b-ba5b0d7dad2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-6790212b-90f2-41ca-a7fa-63a9a041d949,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-55b64d05-7430-46c3-be3b-ba5b0d7dad2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-6790212b-90f2-41ca-a7fa-63a9a041d949,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-55b64d05-7430-46c3-be3b-ba5b0d7dad2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-6790212b-90f2-41ca-a7fa-63a9a041d949,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-55b64d05-7430-46c3-be3b-ba5b0d7dad2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33972,DS-961e2d1a-3331-41c3-a030-c966a7cae695,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-ce68fd55-c535-434a-81e7-e35d109106f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-ce68fd55-c535-434a-81e7-e35d109106f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-961e2d1a-3331-41c3-a030-c966a7cae695,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33972,DS-961e2d1a-3331-41c3-a030-c966a7cae695,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-ce68fd55-c535-434a-81e7-e35d109106f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-ce68fd55-c535-434a-81e7-e35d109106f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-961e2d1a-3331-41c3-a030-c966a7cae695,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: region: testCompactedBulkLoadedFiles,,1598617679067.73153a8d81e0a5cc4ec43a222b5906a6.
stackTrace: org.apache.hadoop.hbase.DroppedSnapshotException: region: testCompactedBulkLoadedFiles,,1598617679067.73153a8d81e0a5cc4ec43a222b5906a6.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2858)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2527)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2499)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2389)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6232)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6116)
	at org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.testCompactedBulkLoadedFiles(AbstractTestWALReplay.java:431)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=6, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	... 1 more
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-562ea048-7778-44bc-8ba1-fb4eca8f6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-f9b009e7-0e54-448d-8c3b-6b0471bf95c7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-562ea048-7778-44bc-8ba1-fb4eca8f6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-f9b009e7-0e54-448d-8c3b-6b0471bf95c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-e62a95f3-e933-4bdc-a0b2-ade3cf0869a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7d32b9ee-5d41-4b36-8705-298f6b47b066,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-e62a95f3-e933-4bdc-a0b2-ade3cf0869a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7d32b9ee-5d41-4b36-8705-298f6b47b066,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-e62a95f3-e933-4bdc-a0b2-ade3cf0869a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7d32b9ee-5d41-4b36-8705-298f6b47b066,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45570,DS-e62a95f3-e933-4bdc-a0b2-ade3cf0869a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-7d32b9ee-5d41-4b36-8705-298f6b47b066,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-8f141342-b57d-470a-a861-aee45b7caedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-b936ed4e-e7d5-4767-be10-ae80699ce03d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-b936ed4e-e7d5-4767-be10-ae80699ce03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-8f141342-b57d-470a-a861-aee45b7caedd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-8f141342-b57d-470a-a861-aee45b7caedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-b936ed4e-e7d5-4767-be10-ae80699ce03d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-b936ed4e-e7d5-4767-be10-ae80699ce03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-8f141342-b57d-470a-a861-aee45b7caedd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-46b889e4-44ac-4396-a255-38ebb1d2a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-5fae5662-2c0f-4d9f-b3a5-cbc33be8efd5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-5fae5662-2c0f-4d9f-b3a5-cbc33be8efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-46b889e4-44ac-4396-a255-38ebb1d2a3d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-46b889e4-44ac-4396-a255-38ebb1d2a3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-5fae5662-2c0f-4d9f-b3a5-cbc33be8efd5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42954,DS-5fae5662-2c0f-4d9f-b3a5-cbc33be8efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-46b889e4-44ac-4396-a255-38ebb1d2a3d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-ed9d56a5-fc1f-42d6-bda2-5c33f813756e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-ed9d56a5-fc1f-42d6-bda2-5c33f813756e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-ed9d56a5-fc1f-42d6-bda2-5c33f813756e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42891,DS-ed9d56a5-fc1f-42d6-bda2-5c33f813756e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41993,DS-f9f5a6a4-c1c6-4d2b-bf67-fe59eeb06d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f9e06217-f5e7-4911-88f1-1a1920e1b94a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41993,DS-f9f5a6a4-c1c6-4d2b-bf67-fe59eeb06d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f9e06217-f5e7-4911-88f1-1a1920e1b94a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41993,DS-f9f5a6a4-c1c6-4d2b-bf67-fe59eeb06d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f9e06217-f5e7-4911-88f1-1a1920e1b94a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41993,DS-f9f5a6a4-c1c6-4d2b-bf67-fe59eeb06d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f9e06217-f5e7-4911-88f1-1a1920e1b94a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-065957e3-9654-4574-930b-a64522d30c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8cc98343-16a0-4f3d-b7f8-6879ce6b4cfa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-065957e3-9654-4574-930b-a64522d30c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8cc98343-16a0-4f3d-b7f8-6879ce6b4cfa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-065957e3-9654-4574-930b-a64522d30c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8cc98343-16a0-4f3d-b7f8-6879ce6b4cfa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-065957e3-9654-4574-930b-a64522d30c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-8cc98343-16a0-4f3d-b7f8-6879ce6b4cfa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-5eef4df6-ecad-462d-8aca-4e9bbdb482a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-312aebec-34b9-4a85-892b-e00dfcf003de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-312aebec-34b9-4a85-892b-e00dfcf003de,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5eef4df6-ecad-462d-8aca-4e9bbdb482a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-5eef4df6-ecad-462d-8aca-4e9bbdb482a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-312aebec-34b9-4a85-892b-e00dfcf003de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-312aebec-34b9-4a85-892b-e00dfcf003de,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-5eef4df6-ecad-462d-8aca-4e9bbdb482a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-b46a75f5-b0df-463e-acf7-183199080977,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0cca8d78-0481-4b81-9cc8-c21943db01cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-b46a75f5-b0df-463e-acf7-183199080977,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0cca8d78-0481-4b81-9cc8-c21943db01cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-b46a75f5-b0df-463e-acf7-183199080977,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0cca8d78-0481-4b81-9cc8-c21943db01cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43207,DS-b46a75f5-b0df-463e-acf7-183199080977,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-0cca8d78-0481-4b81-9cc8-c21943db01cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=8, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=8, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-5f2f2128-4bb3-44fb-aa86-e317857b68ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-9ee5b1ec-c49a-4550-aeb3-1e741bb0d35f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-5f2f2128-4bb3-44fb-aa86-e317857b68ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-9ee5b1ec-c49a-4550-aeb3-1e741bb0d35f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-557538d1-1375-455e-aa1c-112313df5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b9cc01dc-fed6-4ebe-9b78-7bed35ebd6e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-557538d1-1375-455e-aa1c-112313df5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b9cc01dc-fed6-4ebe-9b78-7bed35ebd6e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-557538d1-1375-455e-aa1c-112313df5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b9cc01dc-fed6-4ebe-9b78-7bed35ebd6e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-557538d1-1375-455e-aa1c-112313df5f29,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b9cc01dc-fed6-4ebe-9b78-7bed35ebd6e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=3, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=3, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42736,DS-eff9d7fd-f22d-4a50-a985-08167e50801a,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-e48c5864-08dc-4506-852d-2a607db014ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42736,DS-eff9d7fd-f22d-4a50-a985-08167e50801a,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-e48c5864-08dc-4506-852d-2a607db014ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-94b25540-805b-4ca0-8101-cb75c167133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a115d78d-0543-4e91-a38b-a98597681e5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-94b25540-805b-4ca0-8101-cb75c167133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a115d78d-0543-4e91-a38b-a98597681e5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-94b25540-805b-4ca0-8101-cb75c167133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a115d78d-0543-4e91-a38b-a98597681e5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-94b25540-805b-4ca0-8101-cb75c167133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a115d78d-0543-4e91-a38b-a98597681e5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-3cf85df4-09d1-4b2a-bb39-837df505ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b314f051-c518-4462-a064-6e774c85206b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-3cf85df4-09d1-4b2a-bb39-837df505ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b314f051-c518-4462-a064-6e774c85206b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-3cf85df4-09d1-4b2a-bb39-837df505ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b314f051-c518-4462-a064-6e774c85206b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-3cf85df4-09d1-4b2a-bb39-837df505ea24,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-b314f051-c518-4462-a064-6e774c85206b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-8dfa04f0-df61-40bc-ba1b-e73cc1383432,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5503b3d-1eca-45e1-a351-63c73de39808,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-8dfa04f0-df61-40bc-ba1b-e73cc1383432,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5503b3d-1eca-45e1-a351-63c73de39808,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-8dfa04f0-df61-40bc-ba1b-e73cc1383432,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5503b3d-1eca-45e1-a351-63c73de39808,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46570,DS-8dfa04f0-df61-40bc-ba1b-e73cc1383432,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5503b3d-1eca-45e1-a351-63c73de39808,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-80fcc2f2-a486-4b72-a31a-f5f80b854e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-e4cbecc1-2871-484a-ad85-545824d4bc80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35078,DS-e4cbecc1-2871-484a-ad85-545824d4bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-80fcc2f2-a486-4b72-a31a-f5f80b854e98,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-80fcc2f2-a486-4b72-a31a-f5f80b854e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-e4cbecc1-2871-484a-ad85-545824d4bc80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35078,DS-e4cbecc1-2871-484a-ad85-545824d4bc80,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-80fcc2f2-a486-4b72-a31a-f5f80b854e98,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-589d84e3-3f75-43ac-bc97-38fbd3a1301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-498d2df5-13af-43d5-99e7-35f0bfb66e5d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-589d84e3-3f75-43ac-bc97-38fbd3a1301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-498d2df5-13af-43d5-99e7-35f0bfb66e5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-589d84e3-3f75-43ac-bc97-38fbd3a1301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-498d2df5-13af-43d5-99e7-35f0bfb66e5d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-589d84e3-3f75-43ac-bc97-38fbd3a1301b,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-498d2df5-13af-43d5-99e7-35f0bfb66e5d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-096ac323-c29a-4f0c-a871-6dfe30dcae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f7f0c077-82a1-4d1f-9b0c-86ed2813dab7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-096ac323-c29a-4f0c-a871-6dfe30dcae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f7f0c077-82a1-4d1f-9b0c-86ed2813dab7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-096ac323-c29a-4f0c-a871-6dfe30dcae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f7f0c077-82a1-4d1f-9b0c-86ed2813dab7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-096ac323-c29a-4f0c-a871-6dfe30dcae4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-f7f0c077-82a1-4d1f-9b0c-86ed2813dab7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: region: testCompactedBulkLoadedFiles,,1598620286972.56755e45ad06af96f27a0c89426f101a.
stackTrace: org.apache.hadoop.hbase.DroppedSnapshotException: region: testCompactedBulkLoadedFiles,,1598620286972.56755e45ad06af96f27a0c89426f101a.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2858)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2527)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2499)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2389)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6232)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6116)
	at org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.testCompactedBulkLoadedFiles(AbstractTestWALReplay.java:431)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=6, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	... 1 more
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37306,DS-adcff190-0dd9-40a2-b28a-7ad1d03fdea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-1c3b57b4-e762-4f01-81ae-7e98d4d47c62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33502,DS-1c3b57b4-e762-4f01-81ae-7e98d4d47c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-adcff190-0dd9-40a2-b28a-7ad1d03fdea6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-ab3bb63c-7d79-4d12-b6e7-d7948a4ed0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a138f270-39b5-40fd-a697-093eba405ed7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-ab3bb63c-7d79-4d12-b6e7-d7948a4ed0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a138f270-39b5-40fd-a697-093eba405ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-ab3bb63c-7d79-4d12-b6e7-d7948a4ed0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a138f270-39b5-40fd-a697-093eba405ed7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-ab3bb63c-7d79-4d12-b6e7-d7948a4ed0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a138f270-39b5-40fd-a697-093eba405ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-a48b7add-977d-4d7f-94e0-7c024145bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-a4f1f2ce-6a6a-4594-823a-6ec22ff79260,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-a4f1f2ce-6a6a-4594-823a-6ec22ff79260,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-a48b7add-977d-4d7f-94e0-7c024145bf4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-a48b7add-977d-4d7f-94e0-7c024145bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-a4f1f2ce-6a6a-4594-823a-6ec22ff79260,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-a4f1f2ce-6a6a-4594-823a-6ec22ff79260,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-a48b7add-977d-4d7f-94e0-7c024145bf4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-9a26d859-2a8c-4d09-a654-11c781f445ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-38c7fce7-a274-4c14-ad37-f23febb0449c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-9a26d859-2a8c-4d09-a654-11c781f445ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-38c7fce7-a274-4c14-ad37-f23febb0449c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-9a26d859-2a8c-4d09-a654-11c781f445ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-38c7fce7-a274-4c14-ad37-f23febb0449c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-9a26d859-2a8c-4d09-a654-11c781f445ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-38c7fce7-a274-4c14-ad37-f23febb0449c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-4a856a67-439b-4cc0-9b51-86ac46238a01,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-a48e6c11-f375-468b-8a0c-7281cfca6ce5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-a48e6c11-f375-468b-8a0c-7281cfca6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4a856a67-439b-4cc0-9b51-86ac46238a01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-4a856a67-439b-4cc0-9b51-86ac46238a01,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-a48e6c11-f375-468b-8a0c-7281cfca6ce5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-a48e6c11-f375-468b-8a0c-7281cfca6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4a856a67-439b-4cc0-9b51-86ac46238a01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-aa003118-378c-4019-ae8d-8f9ca7c7b019,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b271418b-f8ba-4882-8992-46adfc77d66b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-aa003118-378c-4019-ae8d-8f9ca7c7b019,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b271418b-f8ba-4882-8992-46adfc77d66b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-aa003118-378c-4019-ae8d-8f9ca7c7b019,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b271418b-f8ba-4882-8992-46adfc77d66b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33416,DS-aa003118-378c-4019-ae8d-8f9ca7c7b019,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b271418b-f8ba-4882-8992-46adfc77d66b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-2b01683f-6bf8-4486-b61d-c135660e8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-51e50b2b-f60c-4754-a899-f196e2e2dc47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-2b01683f-6bf8-4486-b61d-c135660e8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-51e50b2b-f60c-4754-a899-f196e2e2dc47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-2b01683f-6bf8-4486-b61d-c135660e8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-51e50b2b-f60c-4754-a899-f196e2e2dc47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-2b01683f-6bf8-4486-b61d-c135660e8cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-51e50b2b-f60c-4754-a899-f196e2e2dc47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-7d7ac4fb-4743-4d65-ac6d-c8b52bff1afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-6f71556c-85ab-4a06-b67b-3332b2b26f42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-6f71556c-85ab-4a06-b67b-3332b2b26f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-7d7ac4fb-4743-4d65-ac6d-c8b52bff1afb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41246,DS-7d7ac4fb-4743-4d65-ac6d-c8b52bff1afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-6f71556c-85ab-4a06-b67b-3332b2b26f42,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-6f71556c-85ab-4a06-b67b-3332b2b26f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-7d7ac4fb-4743-4d65-ac6d-c8b52bff1afb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-79c66207-9e39-4a32-8c13-b88a2a73e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-d3bfd7eb-025f-4df9-bff8-eb5eba309ae3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-79c66207-9e39-4a32-8c13-b88a2a73e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-d3bfd7eb-025f-4df9-bff8-eb5eba309ae3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-79c66207-9e39-4a32-8c13-b88a2a73e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-d3bfd7eb-025f-4df9-bff8-eb5eba309ae3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-79c66207-9e39-4a32-8c13-b88a2a73e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-d3bfd7eb-025f-4df9-bff8-eb5eba309ae3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-dba0ae67-e34c-4d9f-94a3-ca1a82a29d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-075cd3a3-cee6-4e4e-9def-d16e02e7ded9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-dba0ae67-e34c-4d9f-94a3-ca1a82a29d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-075cd3a3-cee6-4e4e-9def-d16e02e7ded9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-dba0ae67-e34c-4d9f-94a3-ca1a82a29d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-075cd3a3-cee6-4e4e-9def-d16e02e7ded9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-dba0ae67-e34c-4d9f-94a3-ca1a82a29d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-075cd3a3-cee6-4e4e-9def-d16e02e7ded9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-96248c5c-269c-4fd9-b24d-4161f461ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-9b34db5c-253f-4ddc-a9db-655813ef830e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-96248c5c-269c-4fd9-b24d-4161f461ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-9b34db5c-253f-4ddc-a9db-655813ef830e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-96248c5c-269c-4fd9-b24d-4161f461ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-9b34db5c-253f-4ddc-a9db-655813ef830e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-96248c5c-269c-4fd9-b24d-4161f461ad38,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-9b34db5c-253f-4ddc-a9db-655813ef830e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-033fdcd3-3cfd-46ea-97e4-d82866c62b49,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-1ac1d430-3741-4a76-a3e0-def7a0a57d58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-1ac1d430-3741-4a76-a3e0-def7a0a57d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-033fdcd3-3cfd-46ea-97e4-d82866c62b49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-033fdcd3-3cfd-46ea-97e4-d82866c62b49,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-1ac1d430-3741-4a76-a3e0-def7a0a57d58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-1ac1d430-3741-4a76-a3e0-def7a0a57d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-033fdcd3-3cfd-46ea-97e4-d82866c62b49,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbeeb2a8-1f1c-437a-8632-c56b50aec2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c348ccd5-64b6-44e9-aeef-44a0a87d712b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-c348ccd5-64b6-44e9-aeef-44a0a87d712b,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbeeb2a8-1f1c-437a-8632-c56b50aec2b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbeeb2a8-1f1c-437a-8632-c56b50aec2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-c348ccd5-64b6-44e9-aeef-44a0a87d712b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45919,DS-c348ccd5-64b6-44e9-aeef-44a0a87d712b,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-fbeeb2a8-1f1c-437a-8632-c56b50aec2b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-eeb4ff97-be1a-4815-8038-fea50d97f121,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32919b26-ddac-4938-afd6-9d3f04b8ae4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-eeb4ff97-be1a-4815-8038-fea50d97f121,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32919b26-ddac-4938-afd6-9d3f04b8ae4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-eeb4ff97-be1a-4815-8038-fea50d97f121,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32919b26-ddac-4938-afd6-9d3f04b8ae4b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-eeb4ff97-be1a-4815-8038-fea50d97f121,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-32919b26-ddac-4938-afd6-9d3f04b8ae4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-67de48b9-d272-4b98-85a6-3f8fa33c7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-4e4e94b9-bf27-4630-adda-ca3cad706f16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-4e4e94b9-bf27-4630-adda-ca3cad706f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-67de48b9-d272-4b98-85a6-3f8fa33c7efe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-67de48b9-d272-4b98-85a6-3f8fa33c7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-4e4e94b9-bf27-4630-adda-ca3cad706f16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-4e4e94b9-bf27-4630-adda-ca3cad706f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-67de48b9-d272-4b98-85a6-3f8fa33c7efe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=3, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=3, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-4a53df26-1157-4ce8-b5b5-93f8ec351f38,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-6f5271bc-f0af-4279-a812-6fd164ec5170,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-4a53df26-1157-4ce8-b5b5-93f8ec351f38,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-6f5271bc-f0af-4279-a812-6fd164ec5170,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-8099f14f-ede8-439c-a843-cf9321fdf295,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-8099f14f-ede8-439c-a843-cf9321fdf295,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-8099f14f-ede8-439c-a843-cf9321fdf295,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-8099f14f-ede8-439c-a843-cf9321fdf295,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-be677bcf-65e7-4c68-8a9c-1290e5c77d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-65e8fb1e-2a42-4949-9d61-8d1344e424ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-be677bcf-65e7-4c68-8a9c-1290e5c77d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-65e8fb1e-2a42-4949-9d61-8d1344e424ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-be677bcf-65e7-4c68-8a9c-1290e5c77d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-65e8fb1e-2a42-4949-9d61-8d1344e424ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-be677bcf-65e7-4c68-8a9c-1290e5c77d41,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-65e8fb1e-2a42-4949-9d61-8d1344e424ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-65807ebc-55b9-408b-ad8b-7ad3999b89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04478499-20bf-4922-a6e5-4cb20f9fb801,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-65807ebc-55b9-408b-ad8b-7ad3999b89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04478499-20bf-4922-a6e5-4cb20f9fb801,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-65807ebc-55b9-408b-ad8b-7ad3999b89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04478499-20bf-4922-a6e5-4cb20f9fb801,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-65807ebc-55b9-408b-ad8b-7ad3999b89c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-04478499-20bf-4922-a6e5-4cb20f9fb801,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-0d985c43-6c45-4e25-832d-47b52b58f213,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-573baf75-60d3-4ec4-a722-52cb9a01c7a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-0d985c43-6c45-4e25-832d-47b52b58f213,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-573baf75-60d3-4ec4-a722-52cb9a01c7a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-0d985c43-6c45-4e25-832d-47b52b58f213,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-573baf75-60d3-4ec4-a722-52cb9a01c7a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-0d985c43-6c45-4e25-832d-47b52b58f213,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-573baf75-60d3-4ec4-a722-52cb9a01c7a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-565483c6-ba52-4a95-9093-d4c350a57625,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-1926d8cc-feca-4faf-8b43-c7fa5057843c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-1926d8cc-feca-4faf-8b43-c7fa5057843c,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-565483c6-ba52-4a95-9093-d4c350a57625,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-565483c6-ba52-4a95-9093-d4c350a57625,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-1926d8cc-feca-4faf-8b43-c7fa5057843c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46544,DS-1926d8cc-feca-4faf-8b43-c7fa5057843c,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-565483c6-ba52-4a95-9093-d4c350a57625,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38759,DS-f498404a-35da-4019-b7af-325b9ed6b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-3abad592-9c7f-4ba2-820b-253f070ae3ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-3abad592-9c7f-4ba2-820b-253f070ae3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f498404a-35da-4019-b7af-325b9ed6b4f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38759,DS-f498404a-35da-4019-b7af-325b9ed6b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-3abad592-9c7f-4ba2-820b-253f070ae3ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-3abad592-9c7f-4ba2-820b-253f070ae3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f498404a-35da-4019-b7af-325b9ed6b4f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-8b44216d-1b85-441f-96b2-42dea3752c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1d8c0a0-a20d-4a3b-a3d6-4c896beceb1d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-8b44216d-1b85-441f-96b2-42dea3752c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1d8c0a0-a20d-4a3b-a3d6-4c896beceb1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-8b44216d-1b85-441f-96b2-42dea3752c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1d8c0a0-a20d-4a3b-a3d6-4c896beceb1d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-8b44216d-1b85-441f-96b2-42dea3752c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f1d8c0a0-a20d-4a3b-a3d6-4c896beceb1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-5ddb14f6-789f-4cf6-9645-91fdab9e7159,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ab595f-5dae-479c-a245-5399054a91c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-5ddb14f6-789f-4cf6-9645-91fdab9e7159,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ab595f-5dae-479c-a245-5399054a91c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-5ddb14f6-789f-4cf6-9645-91fdab9e7159,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ab595f-5dae-479c-a245-5399054a91c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-5ddb14f6-789f-4cf6-9645-91fdab9e7159,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ab595f-5dae-479c-a245-5399054a91c8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-14ec23ec-ce75-40cb-8901-9565526c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2284c4b0-66be-44aa-9f2a-a1cff796d353,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-14ec23ec-ce75-40cb-8901-9565526c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2284c4b0-66be-44aa-9f2a-a1cff796d353,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-14ec23ec-ce75-40cb-8901-9565526c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2284c4b0-66be-44aa-9f2a-a1cff796d353,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35220,DS-14ec23ec-ce75-40cb-8901-9565526c6f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-2284c4b0-66be-44aa-9f2a-a1cff796d353,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-ccdc2f0b-cbdb-4aac-9868-4fff8d3ca76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-db49b989-6a27-4467-a198-97688f683195,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-ccdc2f0b-cbdb-4aac-9868-4fff8d3ca76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-db49b989-6a27-4467-a198-97688f683195,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-ccdc2f0b-cbdb-4aac-9868-4fff8d3ca76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-db49b989-6a27-4467-a198-97688f683195,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-ccdc2f0b-cbdb-4aac-9868-4fff8d3ca76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-db49b989-6a27-4467-a198-97688f683195,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-a6cced18-c6ef-4b65-8305-5c1fee3465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-ec39a838-7c5a-48ee-9205-049c79f31f5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-a6cced18-c6ef-4b65-8305-5c1fee3465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-ec39a838-7c5a-48ee-9205-049c79f31f5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-a6cced18-c6ef-4b65-8305-5c1fee3465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-ec39a838-7c5a-48ee-9205-049c79f31f5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44522,DS-a6cced18-c6ef-4b65-8305-5c1fee3465b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-ec39a838-7c5a-48ee-9205-049c79f31f5b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-1e4e64ab-8edc-4081-9f1b-b84ec836ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-766e98ef-117b-4988-9513-a3204e5cdeaf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-1e4e64ab-8edc-4081-9f1b-b84ec836ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-766e98ef-117b-4988-9513-a3204e5cdeaf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-4a233cb2-5e25-4cee-8bcc-9cdde3eadc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-24454fbf-5941-4745-ade7-5626e17ce183,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-4a233cb2-5e25-4cee-8bcc-9cdde3eadc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-24454fbf-5941-4745-ade7-5626e17ce183,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-4a233cb2-5e25-4cee-8bcc-9cdde3eadc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-24454fbf-5941-4745-ade7-5626e17ce183,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37483,DS-4a233cb2-5e25-4cee-8bcc-9cdde3eadc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-24454fbf-5941-4745-ade7-5626e17ce183,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=7, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=7, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-6ae60ff8-1392-43f6-9d33-3ccaac79c362,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-660271ae-c29a-40a5-91f5-39140b1fe8df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-6ae60ff8-1392-43f6-9d33-3ccaac79c362,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-660271ae-c29a-40a5-91f5-39140b1fe8df,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38200,DS-e68fcab3-a3ee-48f6-a3a2-471cdd86fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-29598450-8fde-4a07-9510-b4b8caa896d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38200,DS-e68fcab3-a3ee-48f6-a3a2-471cdd86fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-29598450-8fde-4a07-9510-b4b8caa896d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38200,DS-e68fcab3-a3ee-48f6-a3a2-471cdd86fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-29598450-8fde-4a07-9510-b4b8caa896d5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38200,DS-e68fcab3-a3ee-48f6-a3a2-471cdd86fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-29598450-8fde-4a07-9510-b4b8caa896d5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-4c07a5ab-1a0b-487d-8e7d-3eaa89f3bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-7cda6c07-f13b-44b2-8a48-79e0a662b460,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-7cda6c07-f13b-44b2-8a48-79e0a662b460,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-4c07a5ab-1a0b-487d-8e7d-3eaa89f3bc18,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-4c07a5ab-1a0b-487d-8e7d-3eaa89f3bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-7cda6c07-f13b-44b2-8a48-79e0a662b460,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-7cda6c07-f13b-44b2-8a48-79e0a662b460,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-4c07a5ab-1a0b-487d-8e7d-3eaa89f3bc18,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-2451a6c1-96d8-48a7-92ef-208e4c6cd1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-6a32c622-bb3f-47fc-ab09-1e66cdba12db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42405,DS-6a32c622-bb3f-47fc-ab09-1e66cdba12db,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-2451a6c1-96d8-48a7-92ef-208e4c6cd1c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38109,DS-2451a6c1-96d8-48a7-92ef-208e4c6cd1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-6a32c622-bb3f-47fc-ab09-1e66cdba12db,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42405,DS-6a32c622-bb3f-47fc-ab09-1e66cdba12db,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-2451a6c1-96d8-48a7-92ef-208e4c6cd1c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-cd0fc351-bcc1-4f5d-bdc5-d681c1fb55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31e89595-68ff-4381-8c2b-3ed55ac4ea16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-cd0fc351-bcc1-4f5d-bdc5-d681c1fb55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31e89595-68ff-4381-8c2b-3ed55ac4ea16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-cd0fc351-bcc1-4f5d-bdc5-d681c1fb55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31e89595-68ff-4381-8c2b-3ed55ac4ea16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-cd0fc351-bcc1-4f5d-bdc5-d681c1fb55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31e89595-68ff-4381-8c2b-3ed55ac4ea16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-6c6d52ba-fdd8-4d2a-a146-6c6237c13928,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f824a57f-58dd-4814-8be2-31a43d342562,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-6c6d52ba-fdd8-4d2a-a146-6c6237c13928,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f824a57f-58dd-4814-8be2-31a43d342562,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-6c6d52ba-fdd8-4d2a-a146-6c6237c13928,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f824a57f-58dd-4814-8be2-31a43d342562,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-6c6d52ba-fdd8-4d2a-a146-6c6237c13928,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f824a57f-58dd-4814-8be2-31a43d342562,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-175897f3-33f4-4def-bdb1-fb465c5db62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-62e71062-3086-43a7-a9d4-fc6eab233499,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-175897f3-33f4-4def-bdb1-fb465c5db62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-62e71062-3086-43a7-a9d4-fc6eab233499,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-175897f3-33f4-4def-bdb1-fb465c5db62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-62e71062-3086-43a7-a9d4-fc6eab233499,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-175897f3-33f4-4def-bdb1-fb465c5db62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-62e71062-3086-43a7-a9d4-fc6eab233499,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-1a4c97cf-9108-4d87-b5a8-fe5a2ee6a286,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-b1fd992c-3116-4508-95b6-77843e7d5b75,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-b1fd992c-3116-4508-95b6-77843e7d5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-1a4c97cf-9108-4d87-b5a8-fe5a2ee6a286,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36997,DS-1a4c97cf-9108-4d87-b5a8-fe5a2ee6a286,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-b1fd992c-3116-4508-95b6-77843e7d5b75,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-b1fd992c-3116-4508-95b6-77843e7d5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-1a4c97cf-9108-4d87-b5a8-fe5a2ee6a286,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34287,DS-e28eb5ee-2ac0-4a45-9491-573ddcffbbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-a8b7be08-701a-42db-b4da-1d5927b5eac8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-a8b7be08-701a-42db-b4da-1d5927b5eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e28eb5ee-2ac0-4a45-9491-573ddcffbbc6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34287,DS-e28eb5ee-2ac0-4a45-9491-573ddcffbbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-a8b7be08-701a-42db-b4da-1d5927b5eac8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-a8b7be08-701a-42db-b4da-1d5927b5eac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e28eb5ee-2ac0-4a45-9491-573ddcffbbc6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-475d9bc3-f33c-47b5-a5db-67a6a31f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-ba6beb05-7370-47d5-a783-1ce261c3d44d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-475d9bc3-f33c-47b5-a5db-67a6a31f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-ba6beb05-7370-47d5-a783-1ce261c3d44d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-475d9bc3-f33c-47b5-a5db-67a6a31f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-ba6beb05-7370-47d5-a783-1ce261c3d44d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-475d9bc3-f33c-47b5-a5db-67a6a31f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-ba6beb05-7370-47d5-a783-1ce261c3d44d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testCompactedBulkLoadedFiles
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-ec7f69d3-c22b-4079-98f7-2a7a8734c0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-2c7fe7be-7ef7-4ea4-8e6c-ffe7face3378,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-2c7fe7be-7ef7-4ea4-8e6c-ffe7face3378,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-ec7f69d3-c22b-4079-98f7-2a7a8734c0fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43936,DS-ec7f69d3-c22b-4079-98f7-2a7a8734c0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-2c7fe7be-7ef7-4ea4-8e6c-ffe7face3378,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-2c7fe7be-7ef7-4ea4-8e6c-ffe7face3378,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-ec7f69d3-c22b-4079-98f7-2a7a8734c0fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)


v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: might be true error
Total execution time in seconds : 10081
