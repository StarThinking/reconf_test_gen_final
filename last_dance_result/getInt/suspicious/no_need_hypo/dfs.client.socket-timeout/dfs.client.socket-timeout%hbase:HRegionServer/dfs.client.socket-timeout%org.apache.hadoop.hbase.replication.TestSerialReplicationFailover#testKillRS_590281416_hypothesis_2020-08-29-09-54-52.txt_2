reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42742,DS-13df6b26-85ba-45cd-bbac-c397b95e1eee,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5ae8be17-9639-497a-b36c-c5bec338b8a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-5ae8be17-9639-497a-b36c-c5bec338b8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-13df6b26-85ba-45cd-bbac-c397b95e1eee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42742,DS-13df6b26-85ba-45cd-bbac-c397b95e1eee,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-5ae8be17-9639-497a-b36c-c5bec338b8a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-5ae8be17-9639-497a-b36c-c5bec338b8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-13df6b26-85ba-45cd-bbac-c397b95e1eee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38973,DS-5e8fbb06-44ef-451a-a5b6-c575f5654aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-6c6accaa-5785-4dcf-82cc-c1704c0a7772,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-6c6accaa-5785-4dcf-82cc-c1704c0a7772,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-5e8fbb06-44ef-451a-a5b6-c575f5654aeb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38973,DS-5e8fbb06-44ef-451a-a5b6-c575f5654aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-6c6accaa-5785-4dcf-82cc-c1704c0a7772,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-6c6accaa-5785-4dcf-82cc-c1704c0a7772,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-5e8fbb06-44ef-451a-a5b6-c575f5654aeb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-7eb59200-2d35-43db-a7f0-c54249850057,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4bcc1a78-cf7c-40d3-917a-edac0c9b659c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-7eb59200-2d35-43db-a7f0-c54249850057,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4bcc1a78-cf7c-40d3-917a-edac0c9b659c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-7eb59200-2d35-43db-a7f0-c54249850057,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4bcc1a78-cf7c-40d3-917a-edac0c9b659c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-7eb59200-2d35-43db-a7f0-c54249850057,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4bcc1a78-cf7c-40d3-917a-edac0c9b659c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-e9377c7d-07e1-436c-bedf-c7b62c38eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf689d2-c69a-499d-940a-8a7c6e12fdc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-e9377c7d-07e1-436c-bedf-c7b62c38eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf689d2-c69a-499d-940a-8a7c6e12fdc7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-e9377c7d-07e1-436c-bedf-c7b62c38eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf689d2-c69a-499d-940a-8a7c6e12fdc7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-e9377c7d-07e1-436c-bedf-c7b62c38eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-5bf689d2-c69a-499d-940a-8a7c6e12fdc7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-17cc201d-a25a-4447-9a27-9651448ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-08a91d90-172c-43fd-8b4a-3885fa524a44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-17cc201d-a25a-4447-9a27-9651448ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-08a91d90-172c-43fd-8b4a-3885fa524a44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-17cc201d-a25a-4447-9a27-9651448ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-08a91d90-172c-43fd-8b4a-3885fa524a44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-17cc201d-a25a-4447-9a27-9651448ea657,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-08a91d90-172c-43fd-8b4a-3885fa524a44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-2dafc66a-60a2-423f-9c80-34c98c0c59e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f93f0e42-ee3d-4338-80e9-f8910578885b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-2dafc66a-60a2-423f-9c80-34c98c0c59e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f93f0e42-ee3d-4338-80e9-f8910578885b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-2dafc66a-60a2-423f-9c80-34c98c0c59e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f93f0e42-ee3d-4338-80e9-f8910578885b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-2dafc66a-60a2-423f-9c80-34c98c0c59e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-f93f0e42-ee3d-4338-80e9-f8910578885b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-d5660caf-38b4-40f2-9cb8-b53042847c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-834cf4a4-9390-41b7-aaa9-cd217ac014eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-834cf4a4-9390-41b7-aaa9-cd217ac014eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-d5660caf-38b4-40f2-9cb8-b53042847c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-d5660caf-38b4-40f2-9cb8-b53042847c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-834cf4a4-9390-41b7-aaa9-cd217ac014eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39183,DS-834cf4a4-9390-41b7-aaa9-cd217ac014eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-d5660caf-38b4-40f2-9cb8-b53042847c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-d7293ea3-563d-4e01-8131-a09fe00417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b50202d7-53ff-4da0-9e52-e9697af3f1e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-d7293ea3-563d-4e01-8131-a09fe00417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b50202d7-53ff-4da0-9e52-e9697af3f1e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-d7293ea3-563d-4e01-8131-a09fe00417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b50202d7-53ff-4da0-9e52-e9697af3f1e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-d7293ea3-563d-4e01-8131-a09fe00417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-b50202d7-53ff-4da0-9e52-e9697af3f1e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-67276b51-73dd-4d0a-84ab-99cec398099f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-d02494d6-6219-4b35-905a-c36fccf8ae86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-67276b51-73dd-4d0a-84ab-99cec398099f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-d02494d6-6219-4b35-905a-c36fccf8ae86,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-67276b51-73dd-4d0a-84ab-99cec398099f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-d02494d6-6219-4b35-905a-c36fccf8ae86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-67276b51-73dd-4d0a-84ab-99cec398099f,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-d02494d6-6219-4b35-905a-c36fccf8ae86,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplicationFailover#testKillRS
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-0b5d882f-6064-45e5-97cd-605e3d738caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-5c06a64f-f735-40dd-8528-ddf1cdf4b61e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-5c06a64f-f735-40dd-8528-ddf1cdf4b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0b5d882f-6064-45e5-97cd-605e3d738caf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-0b5d882f-6064-45e5-97cd-605e3d738caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-5c06a64f-f735-40dd-8528-ddf1cdf4b61e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-5c06a64f-f735-40dd-8528-ddf1cdf4b61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-0b5d882f-6064-45e5-97cd-605e3d738caf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2241
