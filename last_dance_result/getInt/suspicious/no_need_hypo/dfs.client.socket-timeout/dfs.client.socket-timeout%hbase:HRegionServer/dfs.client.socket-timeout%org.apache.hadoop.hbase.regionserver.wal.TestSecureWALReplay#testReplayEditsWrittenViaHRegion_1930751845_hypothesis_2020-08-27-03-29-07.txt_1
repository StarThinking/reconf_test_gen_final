reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32892,DS-d305a6cc-1d91-418a-a818-86a3fd42bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-89e332f6-0685-4d03-bc71-cfe5874e2c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-89e332f6-0685-4d03-bc71-cfe5874e2c27,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-d305a6cc-1d91-418a-a818-86a3fd42bcc8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32892,DS-d305a6cc-1d91-418a-a818-86a3fd42bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-89e332f6-0685-4d03-bc71-cfe5874e2c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-89e332f6-0685-4d03-bc71-cfe5874e2c27,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-d305a6cc-1d91-418a-a818-86a3fd42bcc8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-126b1d0b-cd37-4096-975e-f1fa748ed088,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-0533c48a-41c1-4415-9e30-29f8662586b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-126b1d0b-cd37-4096-975e-f1fa748ed088,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-0533c48a-41c1-4415-9e30-29f8662586b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-126b1d0b-cd37-4096-975e-f1fa748ed088,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-0533c48a-41c1-4415-9e30-29f8662586b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-126b1d0b-cd37-4096-975e-f1fa748ed088,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-0533c48a-41c1-4415-9e30-29f8662586b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-3c80f0bd-cdf5-4c98-9613-d9339bbcafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-de389459-4fe5-46fe-94fe-aabcde40277d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-3c80f0bd-cdf5-4c98-9613-d9339bbcafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-de389459-4fe5-46fe-94fe-aabcde40277d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-3c80f0bd-cdf5-4c98-9613-d9339bbcafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-de389459-4fe5-46fe-94fe-aabcde40277d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-3c80f0bd-cdf5-4c98-9613-d9339bbcafa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-de389459-4fe5-46fe-94fe-aabcde40277d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-29d0b60c-a8d9-4ca4-91ee-2a5312ab548c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-04971685-25e1-41a9-8d72-319465f983b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-29d0b60c-a8d9-4ca4-91ee-2a5312ab548c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-04971685-25e1-41a9-8d72-319465f983b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-29d0b60c-a8d9-4ca4-91ee-2a5312ab548c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-04971685-25e1-41a9-8d72-319465f983b7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43006,DS-29d0b60c-a8d9-4ca4-91ee-2a5312ab548c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-04971685-25e1-41a9-8d72-319465f983b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-d0cbbca4-a45e-4511-a686-e8ee77f5ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-33abd803-488b-477f-897d-5264086ba764,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-33abd803-488b-477f-897d-5264086ba764,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-d0cbbca4-a45e-4511-a686-e8ee77f5ff65,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-d0cbbca4-a45e-4511-a686-e8ee77f5ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-33abd803-488b-477f-897d-5264086ba764,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40700,DS-33abd803-488b-477f-897d-5264086ba764,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-d0cbbca4-a45e-4511-a686-e8ee77f5ff65,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-d3b4fea5-ec28-4903-8f73-65cf2cb9f490,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-7467e18d-bb4f-4381-8dbf-faf0812ed703,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-7467e18d-bb4f-4381-8dbf-faf0812ed703,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-d3b4fea5-ec28-4903-8f73-65cf2cb9f490,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-d3b4fea5-ec28-4903-8f73-65cf2cb9f490,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-7467e18d-bb4f-4381-8dbf-faf0812ed703,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-7467e18d-bb4f-4381-8dbf-faf0812ed703,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-d3b4fea5-ec28-4903-8f73-65cf2cb9f490,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-5196ead8-201f-4950-b3fe-bcdeef3149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-c788e8d2-2c58-4088-ba82-cdc92cc20c9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-c788e8d2-2c58-4088-ba82-cdc92cc20c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-5196ead8-201f-4950-b3fe-bcdeef3149d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-5196ead8-201f-4950-b3fe-bcdeef3149d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-c788e8d2-2c58-4088-ba82-cdc92cc20c9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-c788e8d2-2c58-4088-ba82-cdc92cc20c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-5196ead8-201f-4950-b3fe-bcdeef3149d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-eaca133c-ab2c-4e65-9822-d1bd8419823e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ad041074-efe8-4fa2-b55c-d470862982c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-eaca133c-ab2c-4e65-9822-d1bd8419823e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ad041074-efe8-4fa2-b55c-d470862982c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-eaca133c-ab2c-4e65-9822-d1bd8419823e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ad041074-efe8-4fa2-b55c-d470862982c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-eaca133c-ab2c-4e65-9822-d1bd8419823e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-ad041074-efe8-4fa2-b55c-d470862982c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36366,DS-71a555c2-d636-4959-9329-1d2908b0878e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-b2593f03-f6b4-4ff2-a465-ab7ecd127f92,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-b2593f03-f6b4-4ff2-a465-ab7ecd127f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-71a555c2-d636-4959-9329-1d2908b0878e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36366,DS-71a555c2-d636-4959-9329-1d2908b0878e,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-b2593f03-f6b4-4ff2-a465-ab7ecd127f92,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-b2593f03-f6b4-4ff2-a465-ab7ecd127f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-71a555c2-d636-4959-9329-1d2908b0878e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-bc3313e3-a5f6-4055-abc3-9d0c9581869d,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-d0e6cee1-1f39-43d4-a4b9-b42ef00ea25c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-d0e6cee1-1f39-43d4-a4b9-b42ef00ea25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-bc3313e3-a5f6-4055-abc3-9d0c9581869d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-bc3313e3-a5f6-4055-abc3-9d0c9581869d,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-d0e6cee1-1f39-43d4-a4b9-b42ef00ea25c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-d0e6cee1-1f39-43d4-a4b9-b42ef00ea25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-bc3313e3-a5f6-4055-abc3-9d0c9581869d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 11
v1v1v2v2 failed with probability 0 out of 11
result: might be true error
Total execution time in seconds : 2360
