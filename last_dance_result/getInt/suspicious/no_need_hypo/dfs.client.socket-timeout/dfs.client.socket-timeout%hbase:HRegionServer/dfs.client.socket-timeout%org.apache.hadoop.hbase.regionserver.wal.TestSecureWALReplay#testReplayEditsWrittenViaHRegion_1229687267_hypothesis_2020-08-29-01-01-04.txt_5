reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-c3dbf83a-da6e-4b5a-8f25-b54a8c3842ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-feeaee27-dc0c-45bd-aa5d-34a08b39b77f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-feeaee27-dc0c-45bd-aa5d-34a08b39b77f,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-c3dbf83a-da6e-4b5a-8f25-b54a8c3842ba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35360,DS-c3dbf83a-da6e-4b5a-8f25-b54a8c3842ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-feeaee27-dc0c-45bd-aa5d-34a08b39b77f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-feeaee27-dc0c-45bd-aa5d-34a08b39b77f,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-c3dbf83a-da6e-4b5a-8f25-b54a8c3842ba,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-6804b4a2-f14c-4e7d-8522-d8ae51ab59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-f3bf1a4f-e886-4697-a2a1-838280d42432,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-6804b4a2-f14c-4e7d-8522-d8ae51ab59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-f3bf1a4f-e886-4697-a2a1-838280d42432,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-6804b4a2-f14c-4e7d-8522-d8ae51ab59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-f3bf1a4f-e886-4697-a2a1-838280d42432,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-6804b4a2-f14c-4e7d-8522-d8ae51ab59c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-f3bf1a4f-e886-4697-a2a1-838280d42432,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-f2077986-2e68-499a-b0d8-5063a9384da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-5559ef07-8442-4cac-a76a-4581d5920672,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-f2077986-2e68-499a-b0d8-5063a9384da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-5559ef07-8442-4cac-a76a-4581d5920672,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-f2077986-2e68-499a-b0d8-5063a9384da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-5559ef07-8442-4cac-a76a-4581d5920672,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-f2077986-2e68-499a-b0d8-5063a9384da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-5559ef07-8442-4cac-a76a-4581d5920672,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-9654d2c6-9b4c-446b-bf96-7c432bfeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2b88a63d-27a2-42a1-a6ba-83b367f22b95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-9654d2c6-9b4c-446b-bf96-7c432bfeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2b88a63d-27a2-42a1-a6ba-83b367f22b95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-9654d2c6-9b4c-446b-bf96-7c432bfeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2b88a63d-27a2-42a1-a6ba-83b367f22b95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-9654d2c6-9b4c-446b-bf96-7c432bfeb40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-2b88a63d-27a2-42a1-a6ba-83b367f22b95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-ba5c25c1-abe0-40b6-8af5-a1c454f4c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7587d228-0eef-42d0-951f-d77043e4a499,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-7587d228-0eef-42d0-951f-d77043e4a499,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-ba5c25c1-abe0-40b6-8af5-a1c454f4c5d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42936,DS-ba5c25c1-abe0-40b6-8af5-a1c454f4c5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7587d228-0eef-42d0-951f-d77043e4a499,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-7587d228-0eef-42d0-951f-d77043e4a499,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-ba5c25c1-abe0-40b6-8af5-a1c454f4c5d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1211ff7e-7945-4ebf-87ba-67b1a53c400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-73818a21-0ad8-4baf-b59c-417dbcc0d94d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1211ff7e-7945-4ebf-87ba-67b1a53c400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-73818a21-0ad8-4baf-b59c-417dbcc0d94d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1211ff7e-7945-4ebf-87ba-67b1a53c400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-73818a21-0ad8-4baf-b59c-417dbcc0d94d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-1211ff7e-7945-4ebf-87ba-67b1a53c400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-73818a21-0ad8-4baf-b59c-417dbcc0d94d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-8223f148-c75b-419f-8432-3b1c52aaff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-4467fd76-db35-4419-aace-541867108af4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-8223f148-c75b-419f-8432-3b1c52aaff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-4467fd76-db35-4419-aace-541867108af4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-8223f148-c75b-419f-8432-3b1c52aaff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-4467fd76-db35-4419-aace-541867108af4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-8223f148-c75b-419f-8432-3b1c52aaff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-4467fd76-db35-4419-aace-541867108af4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-f67da943-c77f-4154-ba24-33d6016ed019,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-96fba6c9-c475-47d8-bbfb-e7226584ad57,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-f67da943-c77f-4154-ba24-33d6016ed019,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-96fba6c9-c475-47d8-bbfb-e7226584ad57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-f67da943-c77f-4154-ba24-33d6016ed019,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-96fba6c9-c475-47d8-bbfb-e7226584ad57,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-f67da943-c77f-4154-ba24-33d6016ed019,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-96fba6c9-c475-47d8-bbfb-e7226584ad57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-9a947628-3623-409d-ac4f-f7f33f09cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-ea44d239-bfb5-4070-85b3-333db65bd84a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-ea44d239-bfb5-4070-85b3-333db65bd84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-9a947628-3623-409d-ac4f-f7f33f09cd90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-9a947628-3623-409d-ac4f-f7f33f09cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-ea44d239-bfb5-4070-85b3-333db65bd84a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-ea44d239-bfb5-4070-85b3-333db65bd84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-9a947628-3623-409d-ac4f-f7f33f09cd90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-8d2bd8db-3e4e-4270-ba58-1b8013b16bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c52e45a-f79e-40d7-8d4e-9fe9a3c825e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-8d2bd8db-3e4e-4270-ba58-1b8013b16bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c52e45a-f79e-40d7-8d4e-9fe9a3c825e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-8d2bd8db-3e4e-4270-ba58-1b8013b16bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c52e45a-f79e-40d7-8d4e-9fe9a3c825e6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-8d2bd8db-3e4e-4270-ba58-1b8013b16bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-6c52e45a-f79e-40d7-8d4e-9fe9a3c825e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2134
