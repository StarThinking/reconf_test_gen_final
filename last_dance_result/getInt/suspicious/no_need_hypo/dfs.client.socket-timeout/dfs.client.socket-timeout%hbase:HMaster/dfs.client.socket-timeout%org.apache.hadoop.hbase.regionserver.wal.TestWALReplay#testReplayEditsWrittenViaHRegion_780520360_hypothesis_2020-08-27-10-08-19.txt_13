reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-d3576513-831e-4205-93d1-39919dedec82,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-3014acdb-d412-4c5e-bc40-41f07eb1017d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40720,DS-3014acdb-d412-4c5e-bc40-41f07eb1017d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-d3576513-831e-4205-93d1-39919dedec82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35761,DS-d3576513-831e-4205-93d1-39919dedec82,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-3014acdb-d412-4c5e-bc40-41f07eb1017d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40720,DS-3014acdb-d412-4c5e-bc40-41f07eb1017d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-d3576513-831e-4205-93d1-39919dedec82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-a60b501f-2345-4c28-8d7f-c470305f213d,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-335f1813-b856-4566-b428-4fe8fd6046f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-335f1813-b856-4566-b428-4fe8fd6046f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-a60b501f-2345-4c28-8d7f-c470305f213d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-a60b501f-2345-4c28-8d7f-c470305f213d,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-335f1813-b856-4566-b428-4fe8fd6046f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-335f1813-b856-4566-b428-4fe8fd6046f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-a60b501f-2345-4c28-8d7f-c470305f213d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-958a8e4a-dbf2-4153-9d02-9444e620807b,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-49b7859a-6e4c-4c0a-8bda-3fd0025b76e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-49b7859a-6e4c-4c0a-8bda-3fd0025b76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-958a8e4a-dbf2-4153-9d02-9444e620807b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-958a8e4a-dbf2-4153-9d02-9444e620807b,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-49b7859a-6e4c-4c0a-8bda-3fd0025b76e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-49b7859a-6e4c-4c0a-8bda-3fd0025b76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-958a8e4a-dbf2-4153-9d02-9444e620807b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8533259c-de68-4e2b-8bc5-e84b6904c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96b901f2-9d44-49a6-a390-942a53cf4df5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8533259c-de68-4e2b-8bc5-e84b6904c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96b901f2-9d44-49a6-a390-942a53cf4df5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8533259c-de68-4e2b-8bc5-e84b6904c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96b901f2-9d44-49a6-a390-942a53cf4df5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8533259c-de68-4e2b-8bc5-e84b6904c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-96b901f2-9d44-49a6-a390-942a53cf4df5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-fe125d84-05c4-49c1-aa5f-cbc393646ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-52110378-da3f-4ef2-9878-356b737ec4ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-fe125d84-05c4-49c1-aa5f-cbc393646ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-52110378-da3f-4ef2-9878-356b737ec4ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-fe125d84-05c4-49c1-aa5f-cbc393646ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-52110378-da3f-4ef2-9878-356b737ec4ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43706,DS-fe125d84-05c4-49c1-aa5f-cbc393646ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-52110378-da3f-4ef2-9878-356b737ec4ce,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-010f748e-cfc8-4bd4-97fd-262a50ad0866,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-11fba3f6-3baf-45c1-bd2b-cd38f4f5a39c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-010f748e-cfc8-4bd4-97fd-262a50ad0866,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-11fba3f6-3baf-45c1-bd2b-cd38f4f5a39c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-010f748e-cfc8-4bd4-97fd-262a50ad0866,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-11fba3f6-3baf-45c1-bd2b-cd38f4f5a39c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-010f748e-cfc8-4bd4-97fd-262a50ad0866,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-11fba3f6-3baf-45c1-bd2b-cd38f4f5a39c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-066fa5d5-8410-4d2c-9cfd-99bc5abea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dc02601d-612c-44da-b147-b3b91e095967,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-066fa5d5-8410-4d2c-9cfd-99bc5abea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dc02601d-612c-44da-b147-b3b91e095967,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-066fa5d5-8410-4d2c-9cfd-99bc5abea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dc02601d-612c-44da-b147-b3b91e095967,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-066fa5d5-8410-4d2c-9cfd-99bc5abea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-dc02601d-612c-44da-b147-b3b91e095967,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: region: testReplayEditsWrittenViaHRegion,,1598523874279.91d686a983fca4b28901f6d4b1cb5536.
stackTrace: org.apache.hadoop.hbase.DroppedSnapshotException: region: testReplayEditsWrittenViaHRegion,,1598523874279.91d686a983fca4b28901f6d4b1cb5536.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2858)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2527)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2499)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2389)
	at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2292)
	at org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.testReplayEditsWrittenViaHRegion(AbstractTestWALReplay.java:498)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=15, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	... 1 more
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-d9fe18d3-c14e-4dca-8bf0-c46c0a71467a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-61c5e9d0-f22e-40f4-b5e0-421b1728d2c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-d9fe18d3-c14e-4dca-8bf0-c46c0a71467a,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-61c5e9d0-f22e-40f4-b5e0-421b1728d2c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-6f65c318-d77b-4e81-a7f5-90029123c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d8079a1b-20b9-4718-b376-a380e9714d9c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-6f65c318-d77b-4e81-a7f5-90029123c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d8079a1b-20b9-4718-b376-a380e9714d9c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-6f65c318-d77b-4e81-a7f5-90029123c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d8079a1b-20b9-4718-b376-a380e9714d9c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-6f65c318-d77b-4e81-a7f5-90029123c1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-d8079a1b-20b9-4718-b376-a380e9714d9c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-15503d0d-bd7e-4394-b10b-41c9c7465cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b0f5a1ab-11cd-4539-9630-c413c4174c44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-15503d0d-bd7e-4394-b10b-41c9c7465cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b0f5a1ab-11cd-4539-9630-c413c4174c44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-15503d0d-bd7e-4394-b10b-41c9c7465cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b0f5a1ab-11cd-4539-9630-c413c4174c44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-15503d0d-bd7e-4394-b10b-41c9c7465cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-b0f5a1ab-11cd-4539-9630-c413c4174c44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-9ddcd29b-f984-4dcf-8ed3-b553dfeaa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-358cd767-a28a-4592-95f0-403e9dd0ffb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-9ddcd29b-f984-4dcf-8ed3-b553dfeaa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-358cd767-a28a-4592-95f0-403e9dd0ffb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-9ddcd29b-f984-4dcf-8ed3-b553dfeaa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-358cd767-a28a-4592-95f0-403e9dd0ffb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44803,DS-9ddcd29b-f984-4dcf-8ed3-b553dfeaa8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-358cd767-a28a-4592-95f0-403e9dd0ffb1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-bbaeeebb-1c77-4416-a5b5-b2a141814a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-17b34811-455a-47a4-bfe7-614ec0bef380,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-bbaeeebb-1c77-4416-a5b5-b2a141814a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-17b34811-455a-47a4-bfe7-614ec0bef380,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-bbaeeebb-1c77-4416-a5b5-b2a141814a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-17b34811-455a-47a4-bfe7-614ec0bef380,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-bbaeeebb-1c77-4416-a5b5-b2a141814a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-17b34811-455a-47a4-bfe7-614ec0bef380,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-bdbf62ed-c9e6-4a09-bb1d-7f432e2ec610,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-dff1d335-20d3-4940-bf48-baf21d096c9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-bdbf62ed-c9e6-4a09-bb1d-7f432e2ec610,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-dff1d335-20d3-4940-bf48-baf21d096c9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-bdbf62ed-c9e6-4a09-bb1d-7f432e2ec610,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-dff1d335-20d3-4940-bf48-baf21d096c9f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-bdbf62ed-c9e6-4a09-bb1d-7f432e2ec610,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-dff1d335-20d3-4940-bf48-baf21d096c9f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-643209cb-3836-41fb-b166-4191d3a88bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-cc9544f8-dcd7-49f3-a1e9-b3207cb63160,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-cc9544f8-dcd7-49f3-a1e9-b3207cb63160,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-643209cb-3836-41fb-b166-4191d3a88bc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-643209cb-3836-41fb-b166-4191d3a88bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-cc9544f8-dcd7-49f3-a1e9-b3207cb63160,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-cc9544f8-dcd7-49f3-a1e9-b3207cb63160,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-643209cb-3836-41fb-b166-4191d3a88bc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-87dfa3f8-7bad-4246-8275-593034d8b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-efc1e123-dc2c-4b4e-bb3d-75976e2a5974,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44278,DS-efc1e123-dc2c-4b4e-bb3d-75976e2a5974,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-87dfa3f8-7bad-4246-8275-593034d8b58b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35326,DS-87dfa3f8-7bad-4246-8275-593034d8b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-efc1e123-dc2c-4b4e-bb3d-75976e2a5974,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44278,DS-efc1e123-dc2c-4b4e-bb3d-75976e2a5974,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-87dfa3f8-7bad-4246-8275-593034d8b58b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-8e99f0d0-7a5a-4e65-b88c-e580d08aa98c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-8caa1e58-e84d-4348-b181-515abc0816c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-8caa1e58-e84d-4348-b181-515abc0816c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-8e99f0d0-7a5a-4e65-b88c-e580d08aa98c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-8e99f0d0-7a5a-4e65-b88c-e580d08aa98c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-8caa1e58-e84d-4348-b181-515abc0816c5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-8caa1e58-e84d-4348-b181-515abc0816c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-8e99f0d0-7a5a-4e65-b88c-e580d08aa98c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=3, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=3, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-9b73ba5c-cc88-43d9-9701-ea22e55dc020,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-9c22cb9d-8659-4e92-9026-b8c696add4b9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-9b73ba5c-cc88-43d9-9701-ea22e55dc020,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-9c22cb9d-8659-4e92-9026-b8c696add4b9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-429729b5-8c5a-4baa-9ba8-fad627953aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5a429a28-dd7a-4ab6-b82a-6b27db2bb103,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-429729b5-8c5a-4baa-9ba8-fad627953aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5a429a28-dd7a-4ab6-b82a-6b27db2bb103,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-429729b5-8c5a-4baa-9ba8-fad627953aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5a429a28-dd7a-4ab6-b82a-6b27db2bb103,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35333,DS-429729b5-8c5a-4baa-9ba8-fad627953aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5a429a28-dd7a-4ab6-b82a-6b27db2bb103,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-4ed522b5-117e-452a-aa03-da2e781c5e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-67cc79ca-70e9-43f4-a200-da9709622ff2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46251,DS-67cc79ca-70e9-43f4-a200-da9709622ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-4ed522b5-117e-452a-aa03-da2e781c5e15,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-4ed522b5-117e-452a-aa03-da2e781c5e15,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-67cc79ca-70e9-43f4-a200-da9709622ff2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46251,DS-67cc79ca-70e9-43f4-a200-da9709622ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-4ed522b5-117e-452a-aa03-da2e781c5e15,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-aef68955-d5f9-4d01-8140-b8e228860eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-5c8c68c7-baab-47c1-931f-05fbb2d3123e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-5c8c68c7-baab-47c1-931f-05fbb2d3123e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-aef68955-d5f9-4d01-8140-b8e228860eb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-aef68955-d5f9-4d01-8140-b8e228860eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-5c8c68c7-baab-47c1-931f-05fbb2d3123e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38590,DS-5c8c68c7-baab-47c1-931f-05fbb2d3123e,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-aef68955-d5f9-4d01-8140-b8e228860eb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-824d8dfb-1a7b-441b-a18e-cd2155840e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-bbce6c6d-cbb8-42df-9048-bffd4d2c0fa0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-824d8dfb-1a7b-441b-a18e-cd2155840e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-bbce6c6d-cbb8-42df-9048-bffd4d2c0fa0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-824d8dfb-1a7b-441b-a18e-cd2155840e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-bbce6c6d-cbb8-42df-9048-bffd4d2c0fa0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37893,DS-824d8dfb-1a7b-441b-a18e-cd2155840e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-bbce6c6d-cbb8-42df-9048-bffd4d2c0fa0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=3, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=3, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-a44f9893-219b-40c9-817c-ee60353e211e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-a44f9893-219b-40c9-817c-ee60353e211e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-0d4b846e-0249-4862-8d84-154fef0c2161,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0a579686-0b64-43a5-8342-193f844bcb41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-0d4b846e-0249-4862-8d84-154fef0c2161,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0a579686-0b64-43a5-8342-193f844bcb41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-0d4b846e-0249-4862-8d84-154fef0c2161,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0a579686-0b64-43a5-8342-193f844bcb41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35630,DS-0d4b846e-0249-4862-8d84-154fef0c2161,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0a579686-0b64-43a5-8342-193f844bcb41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-28480152-f28d-4439-b4f5-4883b4a917e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-aeee24e3-6d5f-4138-8bd1-2984b4f24cf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-aeee24e3-6d5f-4138-8bd1-2984b4f24cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-28480152-f28d-4439-b4f5-4883b4a917e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-28480152-f28d-4439-b4f5-4883b4a917e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-aeee24e3-6d5f-4138-8bd1-2984b4f24cf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-aeee24e3-6d5f-4138-8bd1-2984b4f24cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-28480152-f28d-4439-b4f5-4883b4a917e9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-20db2a34-91e5-4df6-8eb7-74728a116484,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-89509236-d22f-47e7-af46-9f739074cd21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-20db2a34-91e5-4df6-8eb7-74728a116484,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-89509236-d22f-47e7-af46-9f739074cd21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-20db2a34-91e5-4df6-8eb7-74728a116484,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-89509236-d22f-47e7-af46-9f739074cd21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41608,DS-20db2a34-91e5-4df6-8eb7-74728a116484,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-89509236-d22f-47e7-af46-9f739074cd21,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-ba591bf0-8c9d-43fa-bbe5-87b7e7d7ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-84b065bb-dc67-4257-92f2-0f3a88f1fe08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-84b065bb-dc67-4257-92f2-0f3a88f1fe08,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-ba591bf0-8c9d-43fa-bbe5-87b7e7d7ade1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-ba591bf0-8c9d-43fa-bbe5-87b7e7d7ade1,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-84b065bb-dc67-4257-92f2-0f3a88f1fe08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-84b065bb-dc67-4257-92f2-0f3a88f1fe08,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-ba591bf0-8c9d-43fa-bbe5-87b7e7d7ade1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-35ab1301-b3c8-489a-b85c-30f900bacd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-2a6974a2-e6da-4b43-a8b7-26ac8ee23f0f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-35ab1301-b3c8-489a-b85c-30f900bacd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-2a6974a2-e6da-4b43-a8b7-26ac8ee23f0f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-35ab1301-b3c8-489a-b85c-30f900bacd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-2a6974a2-e6da-4b43-a8b7-26ac8ee23f0f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-35ab1301-b3c8-489a-b85c-30f900bacd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-2a6974a2-e6da-4b43-a8b7-26ac8ee23f0f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-2f0339e2-bc55-414e-94af-c3c9e0a0d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-6c84345e-2bff-450c-843a-53e105271311,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-6c84345e-2bff-450c-843a-53e105271311,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2f0339e2-bc55-414e-94af-c3c9e0a0d4c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-2f0339e2-bc55-414e-94af-c3c9e0a0d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-6c84345e-2bff-450c-843a-53e105271311,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-6c84345e-2bff-450c-843a-53e105271311,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-2f0339e2-bc55-414e-94af-c3c9e0a0d4c3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-94374663-cb88-45ed-b7bc-d600a6ad56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-5e293566-d8cd-43ec-acc2-8ec608ba2e96,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-94374663-cb88-45ed-b7bc-d600a6ad56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-5e293566-d8cd-43ec-acc2-8ec608ba2e96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-94374663-cb88-45ed-b7bc-d600a6ad56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-5e293566-d8cd-43ec-acc2-8ec608ba2e96,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43503,DS-94374663-cb88-45ed-b7bc-d600a6ad56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-5e293566-d8cd-43ec-acc2-8ec608ba2e96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-06710b5f-6fc1-4814-9886-a0b8c0014241,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-e8f5a89f-2b99-4243-8eac-03c13a157d78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-e8f5a89f-2b99-4243-8eac-03c13a157d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-06710b5f-6fc1-4814-9886-a0b8c0014241,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37344,DS-06710b5f-6fc1-4814-9886-a0b8c0014241,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-e8f5a89f-2b99-4243-8eac-03c13a157d78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39700,DS-e8f5a89f-2b99-4243-8eac-03c13a157d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-06710b5f-6fc1-4814-9886-a0b8c0014241,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-152da642-1515-46cd-a172-4ee6a739f4ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-152da642-1515-46cd-a172-4ee6a739f4ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-152da642-1515-46cd-a172-4ee6a739f4ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-152da642-1515-46cd-a172-4ee6a739f4ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-278f48bc-a731-49b0-b1ab-a3f3dc2cf931,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-321ca095-b516-4576-8073-900ff16f8a06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-278f48bc-a731-49b0-b1ab-a3f3dc2cf931,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-321ca095-b516-4576-8073-900ff16f8a06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-278f48bc-a731-49b0-b1ab-a3f3dc2cf931,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-321ca095-b516-4576-8073-900ff16f8a06,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-278f48bc-a731-49b0-b1ab-a3f3dc2cf931,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-321ca095-b516-4576-8073-900ff16f8a06,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-3537c56d-9893-4177-8f2c-a61a25f34a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e0f95348-9e57-4ec1-a226-beea89afa3eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-3537c56d-9893-4177-8f2c-a61a25f34a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e0f95348-9e57-4ec1-a226-beea89afa3eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-3537c56d-9893-4177-8f2c-a61a25f34a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e0f95348-9e57-4ec1-a226-beea89afa3eb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-3537c56d-9893-4177-8f2c-a61a25f34a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-e0f95348-9e57-4ec1-a226-beea89afa3eb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-a1f19d28-8654-4ad3-be5e-dc2652d7b474,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-7374bb2e-84bf-4e9e-9b83-454aaae9ce2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-a1f19d28-8654-4ad3-be5e-dc2652d7b474,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-7374bb2e-84bf-4e9e-9b83-454aaae9ce2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-a1f19d28-8654-4ad3-be5e-dc2652d7b474,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-7374bb2e-84bf-4e9e-9b83-454aaae9ce2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-a1f19d28-8654-4ad3-be5e-dc2652d7b474,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-7374bb2e-84bf-4e9e-9b83-454aaae9ce2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-f02552c7-aac8-49f2-9c26-6118c778f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-8bc3564a-c407-49df-b521-e7c78519272f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-f02552c7-aac8-49f2-9c26-6118c778f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-8bc3564a-c407-49df-b521-e7c78519272f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-f02552c7-aac8-49f2-9c26-6118c778f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-8bc3564a-c407-49df-b521-e7c78519272f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-f02552c7-aac8-49f2-9c26-6118c778f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-8bc3564a-c407-49df-b521-e7c78519272f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-deb0ae88-1b11-42f8-a97d-8ebcc6ae508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-339b6c8a-04e5-4cda-af0c-c89628f54e08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-deb0ae88-1b11-42f8-a97d-8ebcc6ae508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-339b6c8a-04e5-4cda-af0c-c89628f54e08,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-deb0ae88-1b11-42f8-a97d-8ebcc6ae508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-339b6c8a-04e5-4cda-af0c-c89628f54e08,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-deb0ae88-1b11-42f8-a97d-8ebcc6ae508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-339b6c8a-04e5-4cda-af0c-c89628f54e08,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-3db13bb6-bb18-490b-8dd9-4f96f99fed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-cd3a373d-dd01-464d-a3d7-3282113c05f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-3db13bb6-bb18-490b-8dd9-4f96f99fed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-cd3a373d-dd01-464d-a3d7-3282113c05f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-3db13bb6-bb18-490b-8dd9-4f96f99fed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-cd3a373d-dd01-464d-a3d7-3282113c05f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40268,DS-3db13bb6-bb18-490b-8dd9-4f96f99fed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-cd3a373d-dd01-464d-a3d7-3282113c05f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-538de5de-9851-44d4-b6cd-8ee1595db0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5b19cbc6-c3f5-4685-bd8c-647ae9728569,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-538de5de-9851-44d4-b6cd-8ee1595db0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5b19cbc6-c3f5-4685-bd8c-647ae9728569,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-538de5de-9851-44d4-b6cd-8ee1595db0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5b19cbc6-c3f5-4685-bd8c-647ae9728569,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41517,DS-538de5de-9851-44d4-b6cd-8ee1595db0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-5b19cbc6-c3f5-4685-bd8c-647ae9728569,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-37943f38-5065-4497-b3fa-fb96b13616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-172307f5-826c-4025-a2b5-2b5383ba37d4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-172307f5-826c-4025-a2b5-2b5383ba37d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-37943f38-5065-4497-b3fa-fb96b13616b6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-37943f38-5065-4497-b3fa-fb96b13616b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-172307f5-826c-4025-a2b5-2b5383ba37d4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40337,DS-172307f5-826c-4025-a2b5-2b5383ba37d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-37943f38-5065-4497-b3fa-fb96b13616b6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-b4f49830-fa61-4b3a-92ad-d02209b4e924,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6ff73e2f-d6b2-44dc-899c-c36a18a34530,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-6ff73e2f-d6b2-44dc-899c-c36a18a34530,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-b4f49830-fa61-4b3a-92ad-d02209b4e924,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-b4f49830-fa61-4b3a-92ad-d02209b4e924,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6ff73e2f-d6b2-44dc-899c-c36a18a34530,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-6ff73e2f-d6b2-44dc-899c-c36a18a34530,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-b4f49830-fa61-4b3a-92ad-d02209b4e924,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-433c8165-4ddb-47dc-a67c-c9a26a8dca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a305fc98-0085-48b2-9d42-0c93d62d7bb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-433c8165-4ddb-47dc-a67c-c9a26a8dca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a305fc98-0085-48b2-9d42-0c93d62d7bb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-433c8165-4ddb-47dc-a67c-c9a26a8dca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a305fc98-0085-48b2-9d42-0c93d62d7bb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38915,DS-433c8165-4ddb-47dc-a67c-c9a26a8dca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-a305fc98-0085-48b2-9d42-0c93d62d7bb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-cd73e49e-057f-4a72-a351-917824a638e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-aa33f520-c781-4f52-a68b-1978207aaddd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-cd73e49e-057f-4a72-a351-917824a638e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-aa33f520-c781-4f52-a68b-1978207aaddd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-cd73e49e-057f-4a72-a351-917824a638e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-aa33f520-c781-4f52-a68b-1978207aaddd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-cd73e49e-057f-4a72-a351-917824a638e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-aa33f520-c781-4f52-a68b-1978207aaddd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-db110be8-0de7-44d1-89cd-9285dc4e3ce5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-db110be8-0de7-44d1-89cd-9285dc4e3ce5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-db110be8-0de7-44d1-89cd-9285dc4e3ce5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-db110be8-0de7-44d1-89cd-9285dc4e3ce5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-e551525e-b5a0-4d06-9bca-1af2605dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-8f5e6a87-d698-4415-8767-76dce70a155d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-e551525e-b5a0-4d06-9bca-1af2605dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-8f5e6a87-d698-4415-8767-76dce70a155d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-e551525e-b5a0-4d06-9bca-1af2605dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-8f5e6a87-d698-4415-8767-76dce70a155d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-e551525e-b5a0-4d06-9bca-1af2605dcde4,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-8f5e6a87-d698-4415-8767-76dce70a155d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-0064eea7-bec0-4d7e-9543-d6c25c006347,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-30bc374c-b123-4f45-b9e0-cf56031ddded,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-0064eea7-bec0-4d7e-9543-d6c25c006347,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-30bc374c-b123-4f45-b9e0-cf56031ddded,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-0064eea7-bec0-4d7e-9543-d6c25c006347,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-30bc374c-b123-4f45-b9e0-cf56031ddded,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-0064eea7-bec0-4d7e-9543-d6c25c006347,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-30bc374c-b123-4f45-b9e0-cf56031ddded,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-d96db61b-17e2-4dea-9351-cbf24a8f3417,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-74340091-f629-43c6-abe3-360172198e80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-d96db61b-17e2-4dea-9351-cbf24a8f3417,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-74340091-f629-43c6-abe3-360172198e80,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-d96db61b-17e2-4dea-9351-cbf24a8f3417,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-74340091-f629-43c6-abe3-360172198e80,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-d96db61b-17e2-4dea-9351-cbf24a8f3417,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-74340091-f629-43c6-abe3-360172198e80,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-97ec323b-232a-44da-9082-926b7f9c89f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-0eff6992-e0f8-44cb-a930-3a95b0eef0de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-0eff6992-e0f8-44cb-a930-3a95b0eef0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-97ec323b-232a-44da-9082-926b7f9c89f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-97ec323b-232a-44da-9082-926b7f9c89f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-0eff6992-e0f8-44cb-a930-3a95b0eef0de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-0eff6992-e0f8-44cb-a930-3a95b0eef0de,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-97ec323b-232a-44da-9082-926b7f9c89f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-362eb1a4-a1e4-4b42-9252-bc9a088877dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-39e6c901-81cd-4543-a2b8-9a2ef3f3f723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-362eb1a4-a1e4-4b42-9252-bc9a088877dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-39e6c901-81cd-4543-a2b8-9a2ef3f3f723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-362eb1a4-a1e4-4b42-9252-bc9a088877dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-39e6c901-81cd-4543-a2b8-9a2ef3f3f723,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-362eb1a4-a1e4-4b42-9252-bc9a088877dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-39e6c901-81cd-4543-a2b8-9a2ef3f3f723,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-2ebd3e9c-2e77-4e7e-87b2-9161fa3eb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a39d4831-a770-4ff5-ab2e-907b54708456,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-2ebd3e9c-2e77-4e7e-87b2-9161fa3eb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a39d4831-a770-4ff5-ab2e-907b54708456,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-2ebd3e9c-2e77-4e7e-87b2-9161fa3eb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a39d4831-a770-4ff5-ab2e-907b54708456,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-2ebd3e9c-2e77-4e7e-87b2-9161fa3eb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a39d4831-a770-4ff5-ab2e-907b54708456,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40725,DS-66ac92aa-69a1-4a95-ade2-d1e2dc0fc660,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-9386d6d9-babb-4bd5-ad96-e2310f646f44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40725,DS-66ac92aa-69a1-4a95-ade2-d1e2dc0fc660,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-9386d6d9-babb-4bd5-ad96-e2310f646f44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40725,DS-66ac92aa-69a1-4a95-ade2-d1e2dc0fc660,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-9386d6d9-babb-4bd5-ad96-e2310f646f44,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40725,DS-66ac92aa-69a1-4a95-ade2-d1e2dc0fc660,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-9386d6d9-babb-4bd5-ad96-e2310f646f44,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a12ca7a-d168-4b60-b578-a58712d611c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4756a976-8f41-44e6-b812-2c4347cff529,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-4756a976-8f41-44e6-b812-2c4347cff529,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a12ca7a-d168-4b60-b578-a58712d611c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a12ca7a-d168-4b60-b578-a58712d611c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-4756a976-8f41-44e6-b812-2c4347cff529,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43324,DS-4756a976-8f41-44e6-b812-2c4347cff529,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-9a12ca7a-d168-4b60-b578-a58712d611c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-7d342e02-bc84-45d9-8435-46b4e2d12417,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6f4c1442-c691-4b13-86c7-a4fe37690e11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-7d342e02-bc84-45d9-8435-46b4e2d12417,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6f4c1442-c691-4b13-86c7-a4fe37690e11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-7d342e02-bc84-45d9-8435-46b4e2d12417,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6f4c1442-c691-4b13-86c7-a4fe37690e11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35406,DS-7d342e02-bc84-45d9-8435-46b4e2d12417,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6f4c1442-c691-4b13-86c7-a4fe37690e11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-822c26f7-09d4-4c69-aa97-106a047355ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-cfbf71ba-be99-48bb-83a4-af400fa6107a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-822c26f7-09d4-4c69-aa97-106a047355ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-cfbf71ba-be99-48bb-83a4-af400fa6107a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-822c26f7-09d4-4c69-aa97-106a047355ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-cfbf71ba-be99-48bb-83a4-af400fa6107a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-822c26f7-09d4-4c69-aa97-106a047355ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-cfbf71ba-be99-48bb-83a4-af400fa6107a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-49c5b672-80c8-46a2-8a67-1bf1d4f4ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-295673ca-7fba-4293-8a05-1ba854913e5c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-49c5b672-80c8-46a2-8a67-1bf1d4f4ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-295673ca-7fba-4293-8a05-1ba854913e5c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-49c5b672-80c8-46a2-8a67-1bf1d4f4ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-295673ca-7fba-4293-8a05-1ba854913e5c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-49c5b672-80c8-46a2-8a67-1bf1d4f4ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-295673ca-7fba-4293-8a05-1ba854913e5c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-8c2ce232-321f-40e3-b9ee-000eb0829def,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-32ef2a7f-1a9d-41b2-a5d0-67ef44a08f1d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-8c2ce232-321f-40e3-b9ee-000eb0829def,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-32ef2a7f-1a9d-41b2-a5d0-67ef44a08f1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-8c2ce232-321f-40e3-b9ee-000eb0829def,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-32ef2a7f-1a9d-41b2-a5d0-67ef44a08f1d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-8c2ce232-321f-40e3-b9ee-000eb0829def,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-32ef2a7f-1a9d-41b2-a5d0-67ef44a08f1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-97c79c63-177e-460e-8db8-0484cc570c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5be70b32-de11-40c4-a5b8-65c4f405732c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-97c79c63-177e-460e-8db8-0484cc570c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5be70b32-de11-40c4-a5b8-65c4f405732c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-97c79c63-177e-460e-8db8-0484cc570c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5be70b32-de11-40c4-a5b8-65c4f405732c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-97c79c63-177e-460e-8db8-0484cc570c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-5be70b32-de11-40c4-a5b8-65c4f405732c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-530748a7-2ddf-4b5a-917c-9ac3e5755a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9b6ec52d-7eab-414c-bf56-3cfcaa20a71f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-530748a7-2ddf-4b5a-917c-9ac3e5755a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9b6ec52d-7eab-414c-bf56-3cfcaa20a71f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-530748a7-2ddf-4b5a-917c-9ac3e5755a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9b6ec52d-7eab-414c-bf56-3cfcaa20a71f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38053,DS-530748a7-2ddf-4b5a-917c-9ac3e5755a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-9b6ec52d-7eab-414c-bf56-3cfcaa20a71f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-9a6c92a9-7176-49cc-8eb7-458c1d09c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-3acaae37-956b-4740-bcad-0590d1d3daf2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-9a6c92a9-7176-49cc-8eb7-458c1d09c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-3acaae37-956b-4740-bcad-0590d1d3daf2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-9a6c92a9-7176-49cc-8eb7-458c1d09c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-3acaae37-956b-4740-bcad-0590d1d3daf2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-9a6c92a9-7176-49cc-8eb7-458c1d09c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-3acaae37-956b-4740-bcad-0590d1d3daf2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-91e2170d-634d-4f4e-8b40-8c3a7df8bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4ea6e180-72e8-416f-9faa-93eeaf266455,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-91e2170d-634d-4f4e-8b40-8c3a7df8bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4ea6e180-72e8-416f-9faa-93eeaf266455,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-91e2170d-634d-4f4e-8b40-8c3a7df8bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4ea6e180-72e8-416f-9faa-93eeaf266455,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-91e2170d-634d-4f4e-8b40-8c3a7df8bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-4ea6e180-72e8-416f-9faa-93eeaf266455,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-56217446-b6d8-4aa0-b4e4-7cae91c82c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-96420764-16f5-440e-84a5-f013b620d614,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-56217446-b6d8-4aa0-b4e4-7cae91c82c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-96420764-16f5-440e-84a5-f013b620d614,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-56217446-b6d8-4aa0-b4e4-7cae91c82c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-96420764-16f5-440e-84a5-f013b620d614,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-56217446-b6d8-4aa0-b4e4-7cae91c82c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-96420764-16f5-440e-84a5-f013b620d614,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-467d9c8b-a3aa-47c9-b11c-e0a444558c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-4f428b23-3326-4e1a-9627-893accf8de33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-467d9c8b-a3aa-47c9-b11c-e0a444558c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-4f428b23-3326-4e1a-9627-893accf8de33,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-467d9c8b-a3aa-47c9-b11c-e0a444558c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-4f428b23-3326-4e1a-9627-893accf8de33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-467d9c8b-a3aa-47c9-b11c-e0a444558c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-4f428b23-3326-4e1a-9627-893accf8de33,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-1b21aae7-435f-4ed0-843c-c04424a8b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-5c3bba79-0a35-4940-a22d-533fc17ee4ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-1b21aae7-435f-4ed0-843c-c04424a8b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-5c3bba79-0a35-4940-a22d-533fc17ee4ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-1b21aae7-435f-4ed0-843c-c04424a8b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-5c3bba79-0a35-4940-a22d-533fc17ee4ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-1b21aae7-435f-4ed0-843c-c04424a8b7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-5c3bba79-0a35-4940-a22d-533fc17ee4ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-1d3739ea-2971-4244-8f18-c613522644a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-46edbeb3-1543-46c3-a588-3a1235caeb47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-1d3739ea-2971-4244-8f18-c613522644a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-46edbeb3-1543-46c3-a588-3a1235caeb47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-1d3739ea-2971-4244-8f18-c613522644a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-46edbeb3-1543-46c3-a588-3a1235caeb47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-1d3739ea-2971-4244-8f18-c613522644a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-46edbeb3-1543-46c3-a588-3a1235caeb47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-a65502a0-a828-4924-9274-05a75f703a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8d17c45d-afc6-41f6-8904-9d686220c284,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-a65502a0-a828-4924-9274-05a75f703a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8d17c45d-afc6-41f6-8904-9d686220c284,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-a65502a0-a828-4924-9274-05a75f703a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8d17c45d-afc6-41f6-8904-9d686220c284,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-a65502a0-a828-4924-9274-05a75f703a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-8d17c45d-afc6-41f6-8904-9d686220c284,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-6a6ee641-aaa7-4216-8d73-59699b3debe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-311da0a6-c61a-4a30-b53c-91f465bc7993,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-6a6ee641-aaa7-4216-8d73-59699b3debe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-311da0a6-c61a-4a30-b53c-91f465bc7993,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-6a6ee641-aaa7-4216-8d73-59699b3debe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-311da0a6-c61a-4a30-b53c-91f465bc7993,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-6a6ee641-aaa7-4216-8d73-59699b3debe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-311da0a6-c61a-4a30-b53c-91f465bc7993,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-903f2425-8ff8-4c56-94d4-2ec25f225946,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-fcfdfb34-36cd-4d49-bc1c-75c73d261812,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-903f2425-8ff8-4c56-94d4-2ec25f225946,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-fcfdfb34-36cd-4d49-bc1c-75c73d261812,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-903f2425-8ff8-4c56-94d4-2ec25f225946,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-fcfdfb34-36cd-4d49-bc1c-75c73d261812,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-903f2425-8ff8-4c56-94d4-2ec25f225946,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-fcfdfb34-36cd-4d49-bc1c-75c73d261812,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: might be true error
Total execution time in seconds : 11229
