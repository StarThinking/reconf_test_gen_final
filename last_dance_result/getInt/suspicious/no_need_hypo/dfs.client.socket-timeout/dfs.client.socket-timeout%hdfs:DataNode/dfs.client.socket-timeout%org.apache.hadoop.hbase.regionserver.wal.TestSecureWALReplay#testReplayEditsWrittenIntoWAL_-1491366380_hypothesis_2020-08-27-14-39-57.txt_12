reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39812,DS-030235ec-9b4c-4fa9-b0b5-3c61f6e6c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-083d5fad-0cb5-4fae-aaa4-de19958d0c8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38058,DS-083d5fad-0cb5-4fae-aaa4-de19958d0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-030235ec-9b4c-4fa9-b0b5-3c61f6e6c72f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39812,DS-030235ec-9b4c-4fa9-b0b5-3c61f6e6c72f,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-083d5fad-0cb5-4fae-aaa4-de19958d0c8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38058,DS-083d5fad-0cb5-4fae-aaa4-de19958d0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-030235ec-9b4c-4fa9-b0b5-3c61f6e6c72f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-602ef6b1-e47a-4bd7-97a3-aec0c5c15041,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-8a224236-99ec-4293-8ad9-036ae3a7afff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-8a224236-99ec-4293-8ad9-036ae3a7afff,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-602ef6b1-e47a-4bd7-97a3-aec0c5c15041,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-602ef6b1-e47a-4bd7-97a3-aec0c5c15041,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-8a224236-99ec-4293-8ad9-036ae3a7afff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36356,DS-8a224236-99ec-4293-8ad9-036ae3a7afff,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-602ef6b1-e47a-4bd7-97a3-aec0c5c15041,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-b47a64f3-06c6-4f52-912c-bf93b56e3637,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-3b4a1b1c-cac5-4719-9d67-21a3e4dc90fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-3b4a1b1c-cac5-4719-9d67-21a3e4dc90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-b47a64f3-06c6-4f52-912c-bf93b56e3637,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40687,DS-b47a64f3-06c6-4f52-912c-bf93b56e3637,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-3b4a1b1c-cac5-4719-9d67-21a3e4dc90fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-3b4a1b1c-cac5-4719-9d67-21a3e4dc90fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-b47a64f3-06c6-4f52-912c-bf93b56e3637,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-efbd768c-ef6d-4848-8d28-e97113828286,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-ee07edcf-24b2-4d81-8832-86f72783d469,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-efbd768c-ef6d-4848-8d28-e97113828286,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-ee07edcf-24b2-4d81-8832-86f72783d469,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-efbd768c-ef6d-4848-8d28-e97113828286,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-ee07edcf-24b2-4d81-8832-86f72783d469,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-efbd768c-ef6d-4848-8d28-e97113828286,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-ee07edcf-24b2-4d81-8832-86f72783d469,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-e850ca38-78c7-4fc9-a5c1-ba3ccda6ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f77d11b9-b5de-4b37-aceb-3459aebb20a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-e850ca38-78c7-4fc9-a5c1-ba3ccda6ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f77d11b9-b5de-4b37-aceb-3459aebb20a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-e850ca38-78c7-4fc9-a5c1-ba3ccda6ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f77d11b9-b5de-4b37-aceb-3459aebb20a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-e850ca38-78c7-4fc9-a5c1-ba3ccda6ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-f77d11b9-b5de-4b37-aceb-3459aebb20a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-8155d6fa-2259-4341-a65d-57541f83b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-267e9b28-dfb1-487b-a489-ef2d3aee7535,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-8155d6fa-2259-4341-a65d-57541f83b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-267e9b28-dfb1-487b-a489-ef2d3aee7535,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-8155d6fa-2259-4341-a65d-57541f83b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-267e9b28-dfb1-487b-a489-ef2d3aee7535,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-8155d6fa-2259-4341-a65d-57541f83b92e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-267e9b28-dfb1-487b-a489-ef2d3aee7535,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-997cba70-bd00-4cf5-8e9b-c35c68ae78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-42c4dd7d-e7c2-4437-b684-a31c201bb718,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-997cba70-bd00-4cf5-8e9b-c35c68ae78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-42c4dd7d-e7c2-4437-b684-a31c201bb718,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-997cba70-bd00-4cf5-8e9b-c35c68ae78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-42c4dd7d-e7c2-4437-b684-a31c201bb718,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-997cba70-bd00-4cf5-8e9b-c35c68ae78d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-42c4dd7d-e7c2-4437-b684-a31c201bb718,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-f3862555-6fa7-4965-9e96-6af46ed42674,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0df7827b-a060-4465-855e-b242910676f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-0df7827b-a060-4465-855e-b242910676f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-f3862555-6fa7-4965-9e96-6af46ed42674,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-f3862555-6fa7-4965-9e96-6af46ed42674,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0df7827b-a060-4465-855e-b242910676f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-0df7827b-a060-4465-855e-b242910676f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-f3862555-6fa7-4965-9e96-6af46ed42674,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-96c78cfc-9350-4d1d-aa07-26a7e7abdae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-5b660da3-a134-432f-aa57-ad3c9979c20d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-5b660da3-a134-432f-aa57-ad3c9979c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-96c78cfc-9350-4d1d-aa07-26a7e7abdae6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-96c78cfc-9350-4d1d-aa07-26a7e7abdae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-5b660da3-a134-432f-aa57-ad3c9979c20d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34053,DS-5b660da3-a134-432f-aa57-ad3c9979c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-96c78cfc-9350-4d1d-aa07-26a7e7abdae6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-b3cb4c39-7c95-4d38-94f8-c918c390e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04e1211e-aa3a-4dea-8410-db74463964f0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-b3cb4c39-7c95-4d38-94f8-c918c390e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04e1211e-aa3a-4dea-8410-db74463964f0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-b3cb4c39-7c95-4d38-94f8-c918c390e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04e1211e-aa3a-4dea-8410-db74463964f0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36704,DS-b3cb4c39-7c95-4d38-94f8-c918c390e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04e1211e-aa3a-4dea-8410-db74463964f0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2189
