reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-49cd4482-92ea-432a-a298-f85829bbb261,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-8bb2b39c-5b5a-4415-b9d1-1fe4ca4b10a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-49cd4482-92ea-432a-a298-f85829bbb261,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-8bb2b39c-5b5a-4415-b9d1-1fe4ca4b10a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-49cd4482-92ea-432a-a298-f85829bbb261,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-8bb2b39c-5b5a-4415-b9d1-1fe4ca4b10a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-49cd4482-92ea-432a-a298-f85829bbb261,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-8bb2b39c-5b5a-4415-b9d1-1fe4ca4b10a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-e37a5dd2-4679-4edc-83ff-af96bd3491ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-57420d5a-2d1a-4aa2-9d85-b62fd17a29e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-e37a5dd2-4679-4edc-83ff-af96bd3491ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-57420d5a-2d1a-4aa2-9d85-b62fd17a29e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-e37a5dd2-4679-4edc-83ff-af96bd3491ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-57420d5a-2d1a-4aa2-9d85-b62fd17a29e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-e37a5dd2-4679-4edc-83ff-af96bd3491ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-57420d5a-2d1a-4aa2-9d85-b62fd17a29e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-ceb10f50-b918-43df-8a6b-774f7e429543,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-1a2c91d8-4b94-4e2d-bb6e-d79dac3a476e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-1a2c91d8-4b94-4e2d-bb6e-d79dac3a476e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-ceb10f50-b918-43df-8a6b-774f7e429543,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-ceb10f50-b918-43df-8a6b-774f7e429543,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-1a2c91d8-4b94-4e2d-bb6e-d79dac3a476e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-1a2c91d8-4b94-4e2d-bb6e-d79dac3a476e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-ceb10f50-b918-43df-8a6b-774f7e429543,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-bfe2af4a-8954-4157-a853-c8df8429e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-eafebcc3-60b2-4d7d-91a3-630e85ea275b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-bfe2af4a-8954-4157-a853-c8df8429e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-eafebcc3-60b2-4d7d-91a3-630e85ea275b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-bfe2af4a-8954-4157-a853-c8df8429e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-eafebcc3-60b2-4d7d-91a3-630e85ea275b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-bfe2af4a-8954-4157-a853-c8df8429e05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-eafebcc3-60b2-4d7d-91a3-630e85ea275b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37624,DS-48b2d5c5-612c-4e5a-a512-a7468fdf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b1490bdc-efe6-4e04-9962-b870c7a06e99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37624,DS-48b2d5c5-612c-4e5a-a512-a7468fdf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b1490bdc-efe6-4e04-9962-b870c7a06e99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37624,DS-48b2d5c5-612c-4e5a-a512-a7468fdf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b1490bdc-efe6-4e04-9962-b870c7a06e99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37624,DS-48b2d5c5-612c-4e5a-a512-a7468fdf19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-b1490bdc-efe6-4e04-9962-b870c7a06e99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-f9615d32-296b-4cf6-bed4-ca8649445d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-594da878-a2d9-49fb-bbba-8a42de71682b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-594da878-a2d9-49fb-bbba-8a42de71682b,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-f9615d32-296b-4cf6-bed4-ca8649445d47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36223,DS-f9615d32-296b-4cf6-bed4-ca8649445d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-594da878-a2d9-49fb-bbba-8a42de71682b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-594da878-a2d9-49fb-bbba-8a42de71682b,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-f9615d32-296b-4cf6-bed4-ca8649445d47,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-a225a2e7-b7cf-4639-a321-213e0f872be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9fcd007d-775e-4183-822a-4a2cf46277d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-a225a2e7-b7cf-4639-a321-213e0f872be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9fcd007d-775e-4183-822a-4a2cf46277d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-a225a2e7-b7cf-4639-a321-213e0f872be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9fcd007d-775e-4183-822a-4a2cf46277d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-a225a2e7-b7cf-4639-a321-213e0f872be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9fcd007d-775e-4183-822a-4a2cf46277d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-08498412-084b-489c-b16f-2c2aad77e510,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c11862b0-1fee-429f-a011-faa257599a4f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-08498412-084b-489c-b16f-2c2aad77e510,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c11862b0-1fee-429f-a011-faa257599a4f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-08498412-084b-489c-b16f-2c2aad77e510,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c11862b0-1fee-429f-a011-faa257599a4f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-08498412-084b-489c-b16f-2c2aad77e510,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c11862b0-1fee-429f-a011-faa257599a4f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-62db5265-277f-4b1f-95eb-910b950c9bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-71d59ba0-b985-4d44-904c-7d62b2206c0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-62db5265-277f-4b1f-95eb-910b950c9bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-71d59ba0-b985-4d44-904c-7d62b2206c0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-62db5265-277f-4b1f-95eb-910b950c9bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-71d59ba0-b985-4d44-904c-7d62b2206c0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-62db5265-277f-4b1f-95eb-910b950c9bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-71d59ba0-b985-4d44-904c-7d62b2206c0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testSnapshotsForOpenFilesAndDeletion
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-12fd3f79-0aca-4a0c-9b15-3caee13803dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-1638aa2e-e1f8-4eb4-8c15-c4b88cbd6b1c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-1638aa2e-e1f8-4eb4-8c15-c4b88cbd6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-12fd3f79-0aca-4a0c-9b15-3caee13803dd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46013,DS-12fd3f79-0aca-4a0c-9b15-3caee13803dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-1638aa2e-e1f8-4eb4-8c15-c4b88cbd6b1c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-1638aa2e-e1f8-4eb4-8c15-c4b88cbd6b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-12fd3f79-0aca-4a0c-9b15-3caee13803dd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 773
