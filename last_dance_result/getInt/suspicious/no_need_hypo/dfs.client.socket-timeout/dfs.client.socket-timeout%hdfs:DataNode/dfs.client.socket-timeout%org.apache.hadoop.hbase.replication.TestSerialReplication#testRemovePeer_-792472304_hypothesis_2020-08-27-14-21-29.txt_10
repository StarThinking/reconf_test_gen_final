reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-a8dc335e-2d4d-4219-8066-4b44cb07162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-2317da2e-8241-47a5-bb0a-2bfef9bdced6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-a8dc335e-2d4d-4219-8066-4b44cb07162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-2317da2e-8241-47a5-bb0a-2bfef9bdced6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-a8dc335e-2d4d-4219-8066-4b44cb07162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-2317da2e-8241-47a5-bb0a-2bfef9bdced6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-a8dc335e-2d4d-4219-8066-4b44cb07162b,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-2317da2e-8241-47a5-bb0a-2bfef9bdced6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45589,DS-fabaea7e-0df4-490a-b0e8-7414a038539f,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-0223d172-b841-40c9-a423-d7845a60f4b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-0223d172-b841-40c9-a423-d7845a60f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-fabaea7e-0df4-490a-b0e8-7414a038539f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45589,DS-fabaea7e-0df4-490a-b0e8-7414a038539f,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-0223d172-b841-40c9-a423-d7845a60f4b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33799,DS-0223d172-b841-40c9-a423-d7845a60f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-fabaea7e-0df4-490a-b0e8-7414a038539f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-e83379fe-f7ad-4e40-a0b7-19ed48fce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e11e6c01-47b2-445f-9e45-b547593b35a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-e83379fe-f7ad-4e40-a0b7-19ed48fce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e11e6c01-47b2-445f-9e45-b547593b35a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-e83379fe-f7ad-4e40-a0b7-19ed48fce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e11e6c01-47b2-445f-9e45-b547593b35a9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46011,DS-e83379fe-f7ad-4e40-a0b7-19ed48fce68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e11e6c01-47b2-445f-9e45-b547593b35a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-fdbe38d3-069a-469c-82ea-b235cf1cdb72,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-9d77931f-575c-41b8-8955-8c733e940cb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-9d77931f-575c-41b8-8955-8c733e940cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fdbe38d3-069a-469c-82ea-b235cf1cdb72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-fdbe38d3-069a-469c-82ea-b235cf1cdb72,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-9d77931f-575c-41b8-8955-8c733e940cb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-9d77931f-575c-41b8-8955-8c733e940cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-fdbe38d3-069a-469c-82ea-b235cf1cdb72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b68b83a7-df43-4a00-854d-6a7e04d5cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-38315228-0873-446a-8158-29ade27de930,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b68b83a7-df43-4a00-854d-6a7e04d5cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-38315228-0873-446a-8158-29ade27de930,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b68b83a7-df43-4a00-854d-6a7e04d5cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-38315228-0873-446a-8158-29ade27de930,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-b68b83a7-df43-4a00-854d-6a7e04d5cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-38315228-0873-446a-8158-29ade27de930,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-df93b027-df76-4540-8a66-8af8750571a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19abedf5-2905-4b87-b682-efc303fcc3cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-df93b027-df76-4540-8a66-8af8750571a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19abedf5-2905-4b87-b682-efc303fcc3cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-df93b027-df76-4540-8a66-8af8750571a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19abedf5-2905-4b87-b682-efc303fcc3cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-df93b027-df76-4540-8a66-8af8750571a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-19abedf5-2905-4b87-b682-efc303fcc3cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-30f3374f-f750-49d7-84d2-4148c8ce16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-d80b28f7-2709-4079-b4a8-411cfc6e6e11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-30f3374f-f750-49d7-84d2-4148c8ce16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-d80b28f7-2709-4079-b4a8-411cfc6e6e11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-30f3374f-f750-49d7-84d2-4148c8ce16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-d80b28f7-2709-4079-b4a8-411cfc6e6e11,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37831,DS-30f3374f-f750-49d7-84d2-4148c8ce16d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-d80b28f7-2709-4079-b4a8-411cfc6e6e11,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-260252d3-bd8a-4f9a-85e3-9b3c4c162650,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-95b4ff7f-65dd-4995-8b6c-31bc78ec2e43,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-260252d3-bd8a-4f9a-85e3-9b3c4c162650,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-95b4ff7f-65dd-4995-8b6c-31bc78ec2e43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-260252d3-bd8a-4f9a-85e3-9b3c4c162650,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-95b4ff7f-65dd-4995-8b6c-31bc78ec2e43,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39557,DS-260252d3-bd8a-4f9a-85e3-9b3c4c162650,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-95b4ff7f-65dd-4995-8b6c-31bc78ec2e43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-912ef79b-d593-47b2-922c-2bc8da42b683,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e0406125-5383-4c53-873a-f06446950589,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-912ef79b-d593-47b2-922c-2bc8da42b683,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e0406125-5383-4c53-873a-f06446950589,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-912ef79b-d593-47b2-922c-2bc8da42b683,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e0406125-5383-4c53-873a-f06446950589,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-912ef79b-d593-47b2-922c-2bc8da42b683,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e0406125-5383-4c53-873a-f06446950589,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.replication.TestSerialReplication#testRemovePeer
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-191cf0c1-8e07-468c-98f2-540568d58e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-25862722-5445-4354-8ab8-956275a8ab55,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-25862722-5445-4354-8ab8-956275a8ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-191cf0c1-8e07-468c-98f2-540568d58e3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42865,DS-191cf0c1-8e07-468c-98f2-540568d58e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-25862722-5445-4354-8ab8-956275a8ab55,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-25862722-5445-4354-8ab8-956275a8ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-191cf0c1-8e07-468c-98f2-540568d58e3e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2143
