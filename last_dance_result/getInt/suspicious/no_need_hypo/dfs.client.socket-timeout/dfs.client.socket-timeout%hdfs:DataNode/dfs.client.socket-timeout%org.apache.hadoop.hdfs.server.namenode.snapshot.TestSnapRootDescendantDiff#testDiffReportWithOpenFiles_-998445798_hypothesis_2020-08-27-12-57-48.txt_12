reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-3a29ff70-a725-4381-9ee2-0e7d83338d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-f187f48c-08cc-41ea-8583-d08568323534,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-3a29ff70-a725-4381-9ee2-0e7d83338d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-f187f48c-08cc-41ea-8583-d08568323534,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-3a29ff70-a725-4381-9ee2-0e7d83338d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-f187f48c-08cc-41ea-8583-d08568323534,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-3a29ff70-a725-4381-9ee2-0e7d83338d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-f187f48c-08cc-41ea-8583-d08568323534,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-52f299e5-bca0-4ccc-aeb0-f49a024eecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-8f305998-c143-4e74-a880-dc47c767148d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-8f305998-c143-4e74-a880-dc47c767148d,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-52f299e5-bca0-4ccc-aeb0-f49a024eecbf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-52f299e5-bca0-4ccc-aeb0-f49a024eecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-8f305998-c143-4e74-a880-dc47c767148d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-8f305998-c143-4e74-a880-dc47c767148d,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-52f299e5-bca0-4ccc-aeb0-f49a024eecbf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-9690407c-e1f5-43b5-aaea-e443a6907fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-bae1a577-4146-4ef0-b7c1-a909808e1fc6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-bae1a577-4146-4ef0-b7c1-a909808e1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-9690407c-e1f5-43b5-aaea-e443a6907fee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-9690407c-e1f5-43b5-aaea-e443a6907fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-bae1a577-4146-4ef0-b7c1-a909808e1fc6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44953,DS-bae1a577-4146-4ef0-b7c1-a909808e1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-9690407c-e1f5-43b5-aaea-e443a6907fee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-4b2f6927-fb91-4e9f-87d8-0a3e7c1d7570,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-8312a1ab-d606-4685-ab9c-27821b8f3eea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-8312a1ab-d606-4685-ab9c-27821b8f3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-4b2f6927-fb91-4e9f-87d8-0a3e7c1d7570,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-4b2f6927-fb91-4e9f-87d8-0a3e7c1d7570,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-8312a1ab-d606-4685-ab9c-27821b8f3eea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41311,DS-8312a1ab-d606-4685-ab9c-27821b8f3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-4b2f6927-fb91-4e9f-87d8-0a3e7c1d7570,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-5730de4d-7b36-4e61-a605-7c757a2a3eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f723ad1-10d9-49b1-b995-c9284560e8ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-5730de4d-7b36-4e61-a605-7c757a2a3eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f723ad1-10d9-49b1-b995-c9284560e8ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-5730de4d-7b36-4e61-a605-7c757a2a3eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f723ad1-10d9-49b1-b995-c9284560e8ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-5730de4d-7b36-4e61-a605-7c757a2a3eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1f723ad1-10d9-49b1-b995-c9284560e8ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-7d36aad3-58b8-4991-bbae-8a667d84d709,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4ed93a11-a9e9-4e78-a8f2-4ff192857e10,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-7d36aad3-58b8-4991-bbae-8a667d84d709,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4ed93a11-a9e9-4e78-a8f2-4ff192857e10,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-7d36aad3-58b8-4991-bbae-8a667d84d709,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4ed93a11-a9e9-4e78-a8f2-4ff192857e10,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-7d36aad3-58b8-4991-bbae-8a667d84d709,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-4ed93a11-a9e9-4e78-a8f2-4ff192857e10,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-7b4e0d87-e4fa-403e-9bf6-2a124783f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a39c13-2b61-4636-bea2-94a982ed5656,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-7b4e0d87-e4fa-403e-9bf6-2a124783f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a39c13-2b61-4636-bea2-94a982ed5656,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-7b4e0d87-e4fa-403e-9bf6-2a124783f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a39c13-2b61-4636-bea2-94a982ed5656,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-7b4e0d87-e4fa-403e-9bf6-2a124783f23c,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-b0a39c13-2b61-4636-bea2-94a982ed5656,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e6d988d8-e6f1-4b77-ab72-5cf0389cb13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-50db862f-ee76-4eb0-8b01-90022c216575,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e6d988d8-e6f1-4b77-ab72-5cf0389cb13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-50db862f-ee76-4eb0-8b01-90022c216575,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e6d988d8-e6f1-4b77-ab72-5cf0389cb13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-50db862f-ee76-4eb0-8b01-90022c216575,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e6d988d8-e6f1-4b77-ab72-5cf0389cb13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-50db862f-ee76-4eb0-8b01-90022c216575,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-e513aa40-4da1-4863-95fa-fa7701a20212,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-1c7d99e0-ef1d-4959-9fe7-b174a950d42a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-1c7d99e0-ef1d-4959-9fe7-b174a950d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-e513aa40-4da1-4863-95fa-fa7701a20212,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42695,DS-e513aa40-4da1-4863-95fa-fa7701a20212,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-1c7d99e0-ef1d-4959-9fe7-b174a950d42a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-1c7d99e0-ef1d-4959-9fe7-b174a950d42a,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-e513aa40-4da1-4863-95fa-fa7701a20212,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapRootDescendantDiff#testDiffReportWithOpenFiles
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-0bc1f339-a074-488c-9c7e-52e859213eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-376d2808-dd6c-4338-9b62-2ecdfde798f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-0bc1f339-a074-488c-9c7e-52e859213eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-376d2808-dd6c-4338-9b62-2ecdfde798f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-0bc1f339-a074-488c-9c7e-52e859213eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-376d2808-dd6c-4338-9b62-2ecdfde798f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-0bc1f339-a074-488c-9c7e-52e859213eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-376d2808-dd6c-4338-9b62-2ecdfde798f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 786
