reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-612cde0b-43fe-4bc5-a257-be59207e2a41,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-8fca2573-c672-444b-ad70-32b0f6ff9d54,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-8fca2573-c672-444b-ad70-32b0f6ff9d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-612cde0b-43fe-4bc5-a257-be59207e2a41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-612cde0b-43fe-4bc5-a257-be59207e2a41,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-8fca2573-c672-444b-ad70-32b0f6ff9d54,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-8fca2573-c672-444b-ad70-32b0f6ff9d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-612cde0b-43fe-4bc5-a257-be59207e2a41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-f336e508-683f-42d2-bd68-11902bfedc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3fa0212c-ba9a-448d-b522-dccba831fd1f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-f336e508-683f-42d2-bd68-11902bfedc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3fa0212c-ba9a-448d-b522-dccba831fd1f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-f336e508-683f-42d2-bd68-11902bfedc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3fa0212c-ba9a-448d-b522-dccba831fd1f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-f336e508-683f-42d2-bd68-11902bfedc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-3fa0212c-ba9a-448d-b522-dccba831fd1f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-8c6f2219-7446-46f5-bba2-8904129d5607,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e7d563e4-6763-4ff9-9d76-4744655c6bf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-8c6f2219-7446-46f5-bba2-8904129d5607,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e7d563e4-6763-4ff9-9d76-4744655c6bf5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-8c6f2219-7446-46f5-bba2-8904129d5607,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e7d563e4-6763-4ff9-9d76-4744655c6bf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-8c6f2219-7446-46f5-bba2-8904129d5607,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-e7d563e4-6763-4ff9-9d76-4744655c6bf5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-ea695bf3-0bf8-499e-b845-6741f0331c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca6b1630-1b88-4888-9472-3527b25ae8ba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca6b1630-1b88-4888-9472-3527b25ae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-ea695bf3-0bf8-499e-b845-6741f0331c0a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-ea695bf3-0bf8-499e-b845-6741f0331c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca6b1630-1b88-4888-9472-3527b25ae8ba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca6b1630-1b88-4888-9472-3527b25ae8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-ea695bf3-0bf8-499e-b845-6741f0331c0a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-3c14c820-e502-4984-bad1-aac976510a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-09bd2e4f-0260-48ae-8d63-05cc48dc8b9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-3c14c820-e502-4984-bad1-aac976510a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-09bd2e4f-0260-48ae-8d63-05cc48dc8b9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-3c14c820-e502-4984-bad1-aac976510a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-09bd2e4f-0260-48ae-8d63-05cc48dc8b9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34977,DS-3c14c820-e502-4984-bad1-aac976510a52,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-09bd2e4f-0260-48ae-8d63-05cc48dc8b9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37299,DS-8ad3229c-467c-42d2-8405-17058abc75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ff38c1e8-a362-4c2e-be59-329e2ce46370,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-ff38c1e8-a362-4c2e-be59-329e2ce46370,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-8ad3229c-467c-42d2-8405-17058abc75b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37299,DS-8ad3229c-467c-42d2-8405-17058abc75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ff38c1e8-a362-4c2e-be59-329e2ce46370,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-ff38c1e8-a362-4c2e-be59-329e2ce46370,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-8ad3229c-467c-42d2-8405-17058abc75b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0872247e-e9f9-429c-a3bc-8768ff5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-920b70d7-9da3-4115-8132-9fc2f31697c9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0872247e-e9f9-429c-a3bc-8768ff5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-920b70d7-9da3-4115-8132-9fc2f31697c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0872247e-e9f9-429c-a3bc-8768ff5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-920b70d7-9da3-4115-8132-9fc2f31697c9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0872247e-e9f9-429c-a3bc-8768ff5550df,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-920b70d7-9da3-4115-8132-9fc2f31697c9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-39ec2f03-6cb2-48fb-b0b4-11e6fd34b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-711e1921-2c23-43f4-9297-b9390efa9ec0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-39ec2f03-6cb2-48fb-b0b4-11e6fd34b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-711e1921-2c23-43f4-9297-b9390efa9ec0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-39ec2f03-6cb2-48fb-b0b4-11e6fd34b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-711e1921-2c23-43f4-9297-b9390efa9ec0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-39ec2f03-6cb2-48fb-b0b4-11e6fd34b12b,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-711e1921-2c23-43f4-9297-b9390efa9ec0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-d95b1a45-2d39-477b-9155-556409939edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-da65cedd-c3ad-4f46-865b-86dc302105bf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-da65cedd-c3ad-4f46-865b-86dc302105bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-d95b1a45-2d39-477b-9155-556409939edd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-d95b1a45-2d39-477b-9155-556409939edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-da65cedd-c3ad-4f46-865b-86dc302105bf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41955,DS-da65cedd-c3ad-4f46-865b-86dc302105bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-d95b1a45-2d39-477b-9155-556409939edd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFlushSequenceIdIsGreaterThanAllEditsInHFile
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-27354577-ff68-4e2f-9d92-6a77007682a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068f3d8-749e-4c0d-a855-4261a6e7462a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-27354577-ff68-4e2f-9d92-6a77007682a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068f3d8-749e-4c0d-a855-4261a6e7462a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-27354577-ff68-4e2f-9d92-6a77007682a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068f3d8-749e-4c0d-a855-4261a6e7462a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37298,DS-27354577-ff68-4e2f-9d92-6a77007682a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068f3d8-749e-4c0d-a855-4261a6e7462a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1581
