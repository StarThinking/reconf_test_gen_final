reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-45ff308d-80f0-49d5-a501-14b1ec44b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-061ec452-6c6b-480e-a256-ee510cd12b96,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-45ff308d-80f0-49d5-a501-14b1ec44b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-061ec452-6c6b-480e-a256-ee510cd12b96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-45ff308d-80f0-49d5-a501-14b1ec44b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-061ec452-6c6b-480e-a256-ee510cd12b96,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43968,DS-45ff308d-80f0-49d5-a501-14b1ec44b787,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-061ec452-6c6b-480e-a256-ee510cd12b96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-837a65bd-ce61-40b0-8713-d71fbb6e7723,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7175d3c2-faf3-47f5-9b8f-c19d8020c9fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-837a65bd-ce61-40b0-8713-d71fbb6e7723,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7175d3c2-faf3-47f5-9b8f-c19d8020c9fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-837a65bd-ce61-40b0-8713-d71fbb6e7723,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7175d3c2-faf3-47f5-9b8f-c19d8020c9fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-837a65bd-ce61-40b0-8713-d71fbb6e7723,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7175d3c2-faf3-47f5-9b8f-c19d8020c9fd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-5fa84a21-cbbb-4176-8ae9-0f581d2545cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cb62c9ee-b0f9-4d68-8e90-a89679b4de23,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-5fa84a21-cbbb-4176-8ae9-0f581d2545cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cb62c9ee-b0f9-4d68-8e90-a89679b4de23,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-5fa84a21-cbbb-4176-8ae9-0f581d2545cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cb62c9ee-b0f9-4d68-8e90-a89679b4de23,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38157,DS-5fa84a21-cbbb-4176-8ae9-0f581d2545cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-cb62c9ee-b0f9-4d68-8e90-a89679b4de23,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-0fb8eac4-ad18-45d1-8b8b-f464029ca5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9a1afc94-d5ef-4c29-bb45-a5c3d6e21df3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-0fb8eac4-ad18-45d1-8b8b-f464029ca5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9a1afc94-d5ef-4c29-bb45-a5c3d6e21df3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-0fb8eac4-ad18-45d1-8b8b-f464029ca5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9a1afc94-d5ef-4c29-bb45-a5c3d6e21df3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-0fb8eac4-ad18-45d1-8b8b-f464029ca5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-9a1afc94-d5ef-4c29-bb45-a5c3d6e21df3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-48bf0c55-3d33-4240-9384-e2bea47e406c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-a755d55f-0de8-4096-bd11-5dd2c9f6ab22,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-48bf0c55-3d33-4240-9384-e2bea47e406c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-a755d55f-0de8-4096-bd11-5dd2c9f6ab22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-48bf0c55-3d33-4240-9384-e2bea47e406c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-a755d55f-0de8-4096-bd11-5dd2c9f6ab22,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36338,DS-48bf0c55-3d33-4240-9384-e2bea47e406c,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-a755d55f-0de8-4096-bd11-5dd2c9f6ab22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d50c6b-6015-4130-adf2-32b3edbce623,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-8ad5a581-1e9a-4144-9f69-62a9eae1b21b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d50c6b-6015-4130-adf2-32b3edbce623,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-8ad5a581-1e9a-4144-9f69-62a9eae1b21b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d50c6b-6015-4130-adf2-32b3edbce623,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-8ad5a581-1e9a-4144-9f69-62a9eae1b21b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42181,DS-71d50c6b-6015-4130-adf2-32b3edbce623,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-8ad5a581-1e9a-4144-9f69-62a9eae1b21b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-57f5143b-a276-4bd9-b992-006f04e5ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-758ce275-5c44-4642-b858-ca3ef9dcc3d4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-57f5143b-a276-4bd9-b992-006f04e5ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-758ce275-5c44-4642-b858-ca3ef9dcc3d4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-57f5143b-a276-4bd9-b992-006f04e5ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-758ce275-5c44-4642-b858-ca3ef9dcc3d4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-57f5143b-a276-4bd9-b992-006f04e5ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-758ce275-5c44-4642-b858-ca3ef9dcc3d4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-527f9589-2d9b-46a1-b0bf-f996ce25ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-47c1b35e-3794-416d-843e-bedf7bb58358,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-527f9589-2d9b-46a1-b0bf-f996ce25ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-47c1b35e-3794-416d-843e-bedf7bb58358,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-527f9589-2d9b-46a1-b0bf-f996ce25ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-47c1b35e-3794-416d-843e-bedf7bb58358,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-527f9589-2d9b-46a1-b0bf-f996ce25ec26,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-47c1b35e-3794-416d-843e-bedf7bb58358,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-b5140bd0-fe4d-4a4e-9eb5-af1f6428bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-004fb8d8-1bf0-476b-a3ba-44143c20e557,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-b5140bd0-fe4d-4a4e-9eb5-af1f6428bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-004fb8d8-1bf0-476b-a3ba-44143c20e557,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-b5140bd0-fe4d-4a4e-9eb5-af1f6428bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-004fb8d8-1bf0-476b-a3ba-44143c20e557,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-b5140bd0-fe4d-4a4e-9eb5-af1f6428bb93,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-004fb8d8-1bf0-476b-a3ba-44143c20e557,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 5000
v2: 60
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testWALCoprocessorLoaded
reconfPoint: -3
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-d26ddc94-c12e-423b-ba1b-0ba019d08c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-af1fa5fd-47af-4d7e-b6ba-f57bfc2d999a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-af1fa5fd-47af-4d7e-b6ba-f57bfc2d999a,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-d26ddc94-c12e-423b-ba1b-0ba019d08c02,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38039,DS-d26ddc94-c12e-423b-ba1b-0ba019d08c02,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-af1fa5fd-47af-4d7e-b6ba-f57bfc2d999a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-af1fa5fd-47af-4d7e-b6ba-f57bfc2d999a,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-d26ddc94-c12e-423b-ba1b-0ba019d08c02,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1435
