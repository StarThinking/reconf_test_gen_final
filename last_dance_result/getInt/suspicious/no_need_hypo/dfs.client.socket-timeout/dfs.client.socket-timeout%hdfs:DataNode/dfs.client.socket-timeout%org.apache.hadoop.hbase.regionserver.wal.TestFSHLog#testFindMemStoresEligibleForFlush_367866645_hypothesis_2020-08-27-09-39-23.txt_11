reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-28dcf5da-714c-4f10-8490-379d63563da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-22cbae93-33c5-4d74-9a37-44c471e0a011,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-28dcf5da-714c-4f10-8490-379d63563da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-22cbae93-33c5-4d74-9a37-44c471e0a011,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-28dcf5da-714c-4f10-8490-379d63563da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-22cbae93-33c5-4d74-9a37-44c471e0a011,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-28dcf5da-714c-4f10-8490-379d63563da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-22cbae93-33c5-4d74-9a37-44c471e0a011,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-180d1c61-d70f-4096-96c3-a1db44db3e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-bd85c4fa-4810-4cc0-aa89-57ff5d91c352,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-180d1c61-d70f-4096-96c3-a1db44db3e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-bd85c4fa-4810-4cc0-aa89-57ff5d91c352,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-180d1c61-d70f-4096-96c3-a1db44db3e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-bd85c4fa-4810-4cc0-aa89-57ff5d91c352,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-180d1c61-d70f-4096-96c3-a1db44db3e13,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-bd85c4fa-4810-4cc0-aa89-57ff5d91c352,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-824707d4-a6f4-407f-a74a-3832f4bf60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-30c0e167-f398-4fce-bda1-0f68590ef59b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-824707d4-a6f4-407f-a74a-3832f4bf60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-30c0e167-f398-4fce-bda1-0f68590ef59b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-824707d4-a6f4-407f-a74a-3832f4bf60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-30c0e167-f398-4fce-bda1-0f68590ef59b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-824707d4-a6f4-407f-a74a-3832f4bf60ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-30c0e167-f398-4fce-bda1-0f68590ef59b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-b327f64a-cfe1-4533-9b7b-7c9fb1001ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-49e0153d-85c3-4094-9de3-ca79ce99d7b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-49e0153d-85c3-4094-9de3-ca79ce99d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-b327f64a-cfe1-4533-9b7b-7c9fb1001ed3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-b327f64a-cfe1-4533-9b7b-7c9fb1001ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-49e0153d-85c3-4094-9de3-ca79ce99d7b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-49e0153d-85c3-4094-9de3-ca79ce99d7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-b327f64a-cfe1-4533-9b7b-7c9fb1001ed3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-ff9992a1-f780-4b0a-9b22-8080d5261904,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-7d5d3525-f003-4de9-b81a-72ea51a6cd03,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-ff9992a1-f780-4b0a-9b22-8080d5261904,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-7d5d3525-f003-4de9-b81a-72ea51a6cd03,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-ff9992a1-f780-4b0a-9b22-8080d5261904,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-7d5d3525-f003-4de9-b81a-72ea51a6cd03,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40849,DS-ff9992a1-f780-4b0a-9b22-8080d5261904,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-7d5d3525-f003-4de9-b81a-72ea51a6cd03,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-efb67442-9d2e-413d-bbed-94a47e9678bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-95f3bcfb-7ee7-478b-ba58-ba80c043fd5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-efb67442-9d2e-413d-bbed-94a47e9678bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-95f3bcfb-7ee7-478b-ba58-ba80c043fd5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-efb67442-9d2e-413d-bbed-94a47e9678bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-95f3bcfb-7ee7-478b-ba58-ba80c043fd5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45778,DS-efb67442-9d2e-413d-bbed-94a47e9678bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-95f3bcfb-7ee7-478b-ba58-ba80c043fd5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8dff51c-a36d-4cd4-96b5-12142d891b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-a75dd4b8-5791-4ccf-8076-91b02993d907,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8dff51c-a36d-4cd4-96b5-12142d891b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-a75dd4b8-5791-4ccf-8076-91b02993d907,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8dff51c-a36d-4cd4-96b5-12142d891b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-a75dd4b8-5791-4ccf-8076-91b02993d907,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-a8dff51c-a36d-4cd4-96b5-12142d891b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-a75dd4b8-5791-4ccf-8076-91b02993d907,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e1f9e8d-1f63-49fd-8feb-bb5e44cd9fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-3667945b-5ac0-49c6-9760-0996ba8d3fa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-3667945b-5ac0-49c6-9760-0996ba8d3fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e1f9e8d-1f63-49fd-8feb-bb5e44cd9fdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e1f9e8d-1f63-49fd-8feb-bb5e44cd9fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-3667945b-5ac0-49c6-9760-0996ba8d3fa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-3667945b-5ac0-49c6-9760-0996ba8d3fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-2e1f9e8d-1f63-49fd-8feb-bb5e44cd9fdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-3e666355-428d-4ce9-9221-b0ee6a1e1859,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-c8e5f0a9-7500-4c4e-ba6b-754527b18d14,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-c8e5f0a9-7500-4c4e-ba6b-754527b18d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-3e666355-428d-4ce9-9221-b0ee6a1e1859,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-3e666355-428d-4ce9-9221-b0ee6a1e1859,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-c8e5f0a9-7500-4c4e-ba6b-754527b18d14,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-c8e5f0a9-7500-4c4e-ba6b-754527b18d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-3e666355-428d-4ce9-9221-b0ee6a1e1859,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-950e9626-14b5-4511-8d1d-b2de3a792119,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-0605cca0-e2d1-4ee3-8de9-177fc984c171,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-0605cca0-e2d1-4ee3-8de9-177fc984c171,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-950e9626-14b5-4511-8d1d-b2de3a792119,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-950e9626-14b5-4511-8d1d-b2de3a792119,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-0605cca0-e2d1-4ee3-8de9-177fc984c171,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-0605cca0-e2d1-4ee3-8de9-177fc984c171,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-950e9626-14b5-4511-8d1d-b2de3a792119,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-4cdd1269-3cdb-463b-a769-b824671b90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1219be2a-3eff-45e4-8074-86ef9c1f634f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-4cdd1269-3cdb-463b-a769-b824671b90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1219be2a-3eff-45e4-8074-86ef9c1f634f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-4cdd1269-3cdb-463b-a769-b824671b90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1219be2a-3eff-45e4-8074-86ef9c1f634f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-4cdd1269-3cdb-463b-a769-b824671b90c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1219be2a-3eff-45e4-8074-86ef9c1f634f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-ac5003df-3ff6-4ccf-9524-edc6fd27d241,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-6de08356-a789-4ca1-bcc0-550d95cb8cb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-6de08356-a789-4ca1-bcc0-550d95cb8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-ac5003df-3ff6-4ccf-9524-edc6fd27d241,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-ac5003df-3ff6-4ccf-9524-edc6fd27d241,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-6de08356-a789-4ca1-bcc0-550d95cb8cb1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41317,DS-6de08356-a789-4ca1-bcc0-550d95cb8cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-ac5003df-3ff6-4ccf-9524-edc6fd27d241,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-99e0050d-244d-4c5c-bf46-99336d790788,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-79872340-b27c-4697-a9ec-322dd4dc6fb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-99e0050d-244d-4c5c-bf46-99336d790788,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-79872340-b27c-4697-a9ec-322dd4dc6fb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-99e0050d-244d-4c5c-bf46-99336d790788,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-79872340-b27c-4697-a9ec-322dd4dc6fb9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-99e0050d-244d-4c5c-bf46-99336d790788,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-79872340-b27c-4697-a9ec-322dd4dc6fb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-cff769b0-c369-4d4d-992e-06af5c4528bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-714e3581-4b5b-460f-8ac6-1f7e961762ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35466,DS-714e3581-4b5b-460f-8ac6-1f7e961762ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-cff769b0-c369-4d4d-992e-06af5c4528bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-cff769b0-c369-4d4d-992e-06af5c4528bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-714e3581-4b5b-460f-8ac6-1f7e961762ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35466,DS-714e3581-4b5b-460f-8ac6-1f7e961762ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-cff769b0-c369-4d4d-992e-06af5c4528bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-8fa0c1e4-cfce-4b1a-a6c0-859bbe77cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac769c30-592f-437f-a6b3-eb45e72c1fd8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-8fa0c1e4-cfce-4b1a-a6c0-859bbe77cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac769c30-592f-437f-a6b3-eb45e72c1fd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-8fa0c1e4-cfce-4b1a-a6c0-859bbe77cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac769c30-592f-437f-a6b3-eb45e72c1fd8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-8fa0c1e4-cfce-4b1a-a6c0-859bbe77cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac769c30-592f-437f-a6b3-eb45e72c1fd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-0e1f285b-d619-4b30-b7d6-acb076de86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-d2a7d522-ab65-4298-b997-ad614ec59a55,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-d2a7d522-ab65-4298-b997-ad614ec59a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-0e1f285b-d619-4b30-b7d6-acb076de86a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-0e1f285b-d619-4b30-b7d6-acb076de86a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-d2a7d522-ab65-4298-b997-ad614ec59a55,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38761,DS-d2a7d522-ab65-4298-b997-ad614ec59a55,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-0e1f285b-d619-4b30-b7d6-acb076de86a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-6adf1cb1-8476-4d72-995c-3c5fc2a07348,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c5737aca-0552-4c13-87fb-b0e67ef0c49e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46131,DS-c5737aca-0552-4c13-87fb-b0e67ef0c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-6adf1cb1-8476-4d72-995c-3c5fc2a07348,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44476,DS-6adf1cb1-8476-4d72-995c-3c5fc2a07348,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c5737aca-0552-4c13-87fb-b0e67ef0c49e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46131,DS-c5737aca-0552-4c13-87fb-b0e67ef0c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-6adf1cb1-8476-4d72-995c-3c5fc2a07348,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-7084fb8d-3fa0-41af-aea2-a02267e48111,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-30fc8a77-717c-416a-b32c-0cd0297a9dd1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-7084fb8d-3fa0-41af-aea2-a02267e48111,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-30fc8a77-717c-416a-b32c-0cd0297a9dd1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-7084fb8d-3fa0-41af-aea2-a02267e48111,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-30fc8a77-717c-416a-b32c-0cd0297a9dd1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-7084fb8d-3fa0-41af-aea2-a02267e48111,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-30fc8a77-717c-416a-b32c-0cd0297a9dd1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-c4e997ef-0d12-4a97-aea7-8fbaa9246142,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-8fb6c1d5-fe86-46b4-bbe1-f5a21eab1d2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-c4e997ef-0d12-4a97-aea7-8fbaa9246142,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-8fb6c1d5-fe86-46b4-bbe1-f5a21eab1d2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-c4e997ef-0d12-4a97-aea7-8fbaa9246142,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-8fb6c1d5-fe86-46b4-bbe1-f5a21eab1d2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-c4e997ef-0d12-4a97-aea7-8fbaa9246142,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-8fb6c1d5-fe86-46b4-bbe1-f5a21eab1d2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-29e7ce8e-bc7c-464f-bf98-52dcdfb312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-141ed9f4-2281-438b-a9cf-30707493411d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-29e7ce8e-bc7c-464f-bf98-52dcdfb312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-141ed9f4-2281-438b-a9cf-30707493411d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-29e7ce8e-bc7c-464f-bf98-52dcdfb312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-141ed9f4-2281-438b-a9cf-30707493411d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-29e7ce8e-bc7c-464f-bf98-52dcdfb312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-141ed9f4-2281-438b-a9cf-30707493411d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-9433075f-47c7-44c2-96cb-e737c2d1f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-02a74608-0e64-48f5-a754-c5d1c12d1762,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-9433075f-47c7-44c2-96cb-e737c2d1f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-02a74608-0e64-48f5-a754-c5d1c12d1762,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-9433075f-47c7-44c2-96cb-e737c2d1f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-02a74608-0e64-48f5-a754-c5d1c12d1762,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34822,DS-9433075f-47c7-44c2-96cb-e737c2d1f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-02a74608-0e64-48f5-a754-c5d1c12d1762,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-f55c0dc7-66a5-44c0-aa87-ebfb247f8273,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-e83d690c-dc77-4e24-8d20-5cbfe3d13b6b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-f55c0dc7-66a5-44c0-aa87-ebfb247f8273,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-e83d690c-dc77-4e24-8d20-5cbfe3d13b6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-f55c0dc7-66a5-44c0-aa87-ebfb247f8273,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-e83d690c-dc77-4e24-8d20-5cbfe3d13b6b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-f55c0dc7-66a5-44c0-aa87-ebfb247f8273,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-e83d690c-dc77-4e24-8d20-5cbfe3d13b6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-9cd6ae45-2cd5-4e06-9fe7-15c9bee9f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5e25bf8c-4de3-40da-956a-e9c99447365b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-9cd6ae45-2cd5-4e06-9fe7-15c9bee9f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5e25bf8c-4de3-40da-956a-e9c99447365b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-9cd6ae45-2cd5-4e06-9fe7-15c9bee9f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5e25bf8c-4de3-40da-956a-e9c99447365b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36004,DS-9cd6ae45-2cd5-4e06-9fe7-15c9bee9f36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-5e25bf8c-4de3-40da-956a-e9c99447365b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-3ac872d0-7db7-4758-9a86-3f55a3ac6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7b736a1e-1869-4c5f-a0c3-7071646e1ecc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-3ac872d0-7db7-4758-9a86-3f55a3ac6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7b736a1e-1869-4c5f-a0c3-7071646e1ecc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-3ac872d0-7db7-4758-9a86-3f55a3ac6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7b736a1e-1869-4c5f-a0c3-7071646e1ecc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-3ac872d0-7db7-4758-9a86-3f55a3ac6a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-7b736a1e-1869-4c5f-a0c3-7071646e1ecc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-9fad4331-55a4-454c-b35a-c8e0103bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f072eeac-777e-4678-910f-56f2c7766686,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-9fad4331-55a4-454c-b35a-c8e0103bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f072eeac-777e-4678-910f-56f2c7766686,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-9fad4331-55a4-454c-b35a-c8e0103bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f072eeac-777e-4678-910f-56f2c7766686,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33929,DS-9fad4331-55a4-454c-b35a-c8e0103bbe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-f072eeac-777e-4678-910f-56f2c7766686,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-82182dda-3051-4b49-b04b-6c79d4fe0cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-47d0bef0-07b9-4011-ad44-c72ce7e59000,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-47d0bef0-07b9-4011-ad44-c72ce7e59000,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-82182dda-3051-4b49-b04b-6c79d4fe0cea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-82182dda-3051-4b49-b04b-6c79d4fe0cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-47d0bef0-07b9-4011-ad44-c72ce7e59000,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-47d0bef0-07b9-4011-ad44-c72ce7e59000,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-82182dda-3051-4b49-b04b-6c79d4fe0cea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-5a822829-7905-488e-b290-896d0d338867,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f43fd21a-0e11-46cf-b5d7-4212b9155c72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-5a822829-7905-488e-b290-896d0d338867,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f43fd21a-0e11-46cf-b5d7-4212b9155c72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-5a822829-7905-488e-b290-896d0d338867,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f43fd21a-0e11-46cf-b5d7-4212b9155c72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43013,DS-5a822829-7905-488e-b290-896d0d338867,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-f43fd21a-0e11-46cf-b5d7-4212b9155c72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-5248c132-7596-4355-9745-da29d03efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-634878de-12d0-44e9-86a8-edf9a06d9a69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-5248c132-7596-4355-9745-da29d03efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-634878de-12d0-44e9-86a8-edf9a06d9a69,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-5248c132-7596-4355-9745-da29d03efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-634878de-12d0-44e9-86a8-edf9a06d9a69,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-5248c132-7596-4355-9745-da29d03efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-634878de-12d0-44e9-86a8-edf9a06d9a69,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40209,DS-e6b5ff83-74c1-4724-b32f-6ffc88854cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b53f8b3e-c26f-4de9-b899-0db09cb5008f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40209,DS-e6b5ff83-74c1-4724-b32f-6ffc88854cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b53f8b3e-c26f-4de9-b899-0db09cb5008f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40209,DS-e6b5ff83-74c1-4724-b32f-6ffc88854cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b53f8b3e-c26f-4de9-b899-0db09cb5008f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40209,DS-e6b5ff83-74c1-4724-b32f-6ffc88854cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b53f8b3e-c26f-4de9-b899-0db09cb5008f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-784d3c88-2a1d-414d-ae71-a6ecb0066d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-e642cd63-2067-4baf-b0c1-cceba34a7f78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-784d3c88-2a1d-414d-ae71-a6ecb0066d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-e642cd63-2067-4baf-b0c1-cceba34a7f78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-784d3c88-2a1d-414d-ae71-a6ecb0066d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-e642cd63-2067-4baf-b0c1-cceba34a7f78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-784d3c88-2a1d-414d-ae71-a6ecb0066d47,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-e642cd63-2067-4baf-b0c1-cceba34a7f78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e6894228-0970-4731-9bbb-0f4088bd3122,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d7d17025-ad9f-49db-a552-424d1e95048b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e6894228-0970-4731-9bbb-0f4088bd3122,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d7d17025-ad9f-49db-a552-424d1e95048b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e6894228-0970-4731-9bbb-0f4088bd3122,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d7d17025-ad9f-49db-a552-424d1e95048b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e6894228-0970-4731-9bbb-0f4088bd3122,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-d7d17025-ad9f-49db-a552-424d1e95048b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-312869b9-538c-47cc-91f6-d650faad744b,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-7acd92f6-921a-433d-b70e-7fb2989147da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-7acd92f6-921a-433d-b70e-7fb2989147da,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-312869b9-538c-47cc-91f6-d650faad744b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41386,DS-312869b9-538c-47cc-91f6-d650faad744b,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-7acd92f6-921a-433d-b70e-7fb2989147da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43278,DS-7acd92f6-921a-433d-b70e-7fb2989147da,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-312869b9-538c-47cc-91f6-d650faad744b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-61a5baf2-b00a-47ae-a0ed-532da5c1c830,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-7cccdf48-7247-422a-b7f4-9fdafd0717da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-61a5baf2-b00a-47ae-a0ed-532da5c1c830,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-7cccdf48-7247-422a-b7f4-9fdafd0717da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-61a5baf2-b00a-47ae-a0ed-532da5c1c830,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-7cccdf48-7247-422a-b7f4-9fdafd0717da,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-61a5baf2-b00a-47ae-a0ed-532da5c1c830,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-7cccdf48-7247-422a-b7f4-9fdafd0717da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-82bdcd02-11ae-41f5-bb29-0d7a2a75359f,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-213b7eaf-f0fb-4865-8eed-b51bb6d15070,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-213b7eaf-f0fb-4865-8eed-b51bb6d15070,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-82bdcd02-11ae-41f5-bb29-0d7a2a75359f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41979,DS-82bdcd02-11ae-41f5-bb29-0d7a2a75359f,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-213b7eaf-f0fb-4865-8eed-b51bb6d15070,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-213b7eaf-f0fb-4865-8eed-b51bb6d15070,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-82bdcd02-11ae-41f5-bb29-0d7a2a75359f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40578,DS-f24d5ceb-1180-4039-8341-7d6d5e06babe,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-676fe062-cdcd-4f12-8bc7-b289a2221612,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-676fe062-cdcd-4f12-8bc7-b289a2221612,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-f24d5ceb-1180-4039-8341-7d6d5e06babe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40578,DS-f24d5ceb-1180-4039-8341-7d6d5e06babe,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-676fe062-cdcd-4f12-8bc7-b289a2221612,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-676fe062-cdcd-4f12-8bc7-b289a2221612,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-f24d5ceb-1180-4039-8341-7d6d5e06babe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-619ccfb9-017c-4169-bca9-ca1acdfe9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-5eb570a0-3ce2-49c2-bab0-7274115503a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-5eb570a0-3ce2-49c2-bab0-7274115503a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-619ccfb9-017c-4169-bca9-ca1acdfe9d90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39585,DS-619ccfb9-017c-4169-bca9-ca1acdfe9d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-5eb570a0-3ce2-49c2-bab0-7274115503a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40247,DS-5eb570a0-3ce2-49c2-bab0-7274115503a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-619ccfb9-017c-4169-bca9-ca1acdfe9d90,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-86ddab60-0ada-4065-a8b8-f54aed56c090,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-b6a23a7b-e504-40e0-9175-621a6e988330,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-b6a23a7b-e504-40e0-9175-621a6e988330,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-86ddab60-0ada-4065-a8b8-f54aed56c090,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-86ddab60-0ada-4065-a8b8-f54aed56c090,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-b6a23a7b-e504-40e0-9175-621a6e988330,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-b6a23a7b-e504-40e0-9175-621a6e988330,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-86ddab60-0ada-4065-a8b8-f54aed56c090,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-6f0c1efc-a896-431e-93f8-7494c27641b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-f5a1aaf3-66f4-4fc2-aa4e-e3953b3d3e0f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-f5a1aaf3-66f4-4fc2-aa4e-e3953b3d3e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-6f0c1efc-a896-431e-93f8-7494c27641b2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-6f0c1efc-a896-431e-93f8-7494c27641b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-f5a1aaf3-66f4-4fc2-aa4e-e3953b3d3e0f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-f5a1aaf3-66f4-4fc2-aa4e-e3953b3d3e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-6f0c1efc-a896-431e-93f8-7494c27641b2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-42960c4f-0e70-4b9c-8e10-f90953a9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-79117245-14a7-4a2c-8383-6db1520678d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-42960c4f-0e70-4b9c-8e10-f90953a9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-79117245-14a7-4a2c-8383-6db1520678d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-42960c4f-0e70-4b9c-8e10-f90953a9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-79117245-14a7-4a2c-8383-6db1520678d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-42960c4f-0e70-4b9c-8e10-f90953a9a834,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-79117245-14a7-4a2c-8383-6db1520678d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-65f10fae-31db-4945-a59f-94142dbcf2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-9c2da03c-5810-45c6-b9e9-ab0d750b1ebf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-65f10fae-31db-4945-a59f-94142dbcf2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-9c2da03c-5810-45c6-b9e9-ab0d750b1ebf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-65f10fae-31db-4945-a59f-94142dbcf2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-9c2da03c-5810-45c6-b9e9-ab0d750b1ebf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-65f10fae-31db-4945-a59f-94142dbcf2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-9c2da03c-5810-45c6-b9e9-ab0d750b1ebf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45582,DS-42e647cd-fb71-428f-b8a2-d3acb8777af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-0a7d4bda-a135-4839-bb18-558d6fcd8ed1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-0a7d4bda-a135-4839-bb18-558d6fcd8ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-42e647cd-fb71-428f-b8a2-d3acb8777af0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45582,DS-42e647cd-fb71-428f-b8a2-d3acb8777af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-0a7d4bda-a135-4839-bb18-558d6fcd8ed1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-0a7d4bda-a135-4839-bb18-558d6fcd8ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-42e647cd-fb71-428f-b8a2-d3acb8777af0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-60d62c61-00a4-4d80-84b2-28f3cea27d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2422cf3f-3e54-4f0a-8377-924c4689e766,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-60d62c61-00a4-4d80-84b2-28f3cea27d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2422cf3f-3e54-4f0a-8377-924c4689e766,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-60d62c61-00a4-4d80-84b2-28f3cea27d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2422cf3f-3e54-4f0a-8377-924c4689e766,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39685,DS-60d62c61-00a4-4d80-84b2-28f3cea27d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-2422cf3f-3e54-4f0a-8377-924c4689e766,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-f72e5418-5671-4a21-80a8-90995a6c77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-d60ab486-2c42-4961-8e02-9fda34e7d5a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38814,DS-d60ab486-2c42-4961-8e02-9fda34e7d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f72e5418-5671-4a21-80a8-90995a6c77cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45454,DS-f72e5418-5671-4a21-80a8-90995a6c77cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-d60ab486-2c42-4961-8e02-9fda34e7d5a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38814,DS-d60ab486-2c42-4961-8e02-9fda34e7d5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-f72e5418-5671-4a21-80a8-90995a6c77cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d811730e-8810-4b46-80d8-7fa362acebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-8b2531fa-d710-43ba-aa39-f92d8584ca3f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d811730e-8810-4b46-80d8-7fa362acebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-8b2531fa-d710-43ba-aa39-f92d8584ca3f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d811730e-8810-4b46-80d8-7fa362acebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-8b2531fa-d710-43ba-aa39-f92d8584ca3f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d811730e-8810-4b46-80d8-7fa362acebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-8b2531fa-d710-43ba-aa39-f92d8584ca3f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44212,DS-26f28f54-d71b-4916-a030-3c00adf348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b9e0533f-6750-4f33-b883-84e2e634e03e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-b9e0533f-6750-4f33-b883-84e2e634e03e,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-26f28f54-d71b-4916-a030-3c00adf348e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44212,DS-26f28f54-d71b-4916-a030-3c00adf348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b9e0533f-6750-4f33-b883-84e2e634e03e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-b9e0533f-6750-4f33-b883-84e2e634e03e,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-26f28f54-d71b-4916-a030-3c00adf348e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-1542f328-8986-42bd-8282-359aa4acd4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0a7c20b-c9e9-4592-a1fa-0fdee9bbcba6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-1542f328-8986-42bd-8282-359aa4acd4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0a7c20b-c9e9-4592-a1fa-0fdee9bbcba6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-1542f328-8986-42bd-8282-359aa4acd4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0a7c20b-c9e9-4592-a1fa-0fdee9bbcba6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-1542f328-8986-42bd-8282-359aa4acd4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-c0a7c20b-c9e9-4592-a1fa-0fdee9bbcba6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-74c392c8-a2cd-4473-b278-de21f0ed7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-adecfc31-637f-47a4-bc07-54d6952b2670,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-74c392c8-a2cd-4473-b278-de21f0ed7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-adecfc31-637f-47a4-bc07-54d6952b2670,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-74c392c8-a2cd-4473-b278-de21f0ed7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-adecfc31-637f-47a4-bc07-54d6952b2670,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43325,DS-74c392c8-a2cd-4473-b278-de21f0ed7d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-adecfc31-637f-47a4-bc07-54d6952b2670,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-3fdce568-9602-488d-842e-974076ab8887,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9e15f867-03c9-4bf8-8aa3-f7770803076e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-3fdce568-9602-488d-842e-974076ab8887,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9e15f867-03c9-4bf8-8aa3-f7770803076e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-3fdce568-9602-488d-842e-974076ab8887,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9e15f867-03c9-4bf8-8aa3-f7770803076e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-3fdce568-9602-488d-842e-974076ab8887,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-9e15f867-03c9-4bf8-8aa3-f7770803076e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-b14a99a8-aebf-492a-ac55-fef886440b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-e9feff78-f621-4323-b4b5-15da277ea54c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-e9feff78-f621-4323-b4b5-15da277ea54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-b14a99a8-aebf-492a-ac55-fef886440b4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-b14a99a8-aebf-492a-ac55-fef886440b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-e9feff78-f621-4323-b4b5-15da277ea54c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38319,DS-e9feff78-f621-4323-b4b5-15da277ea54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-b14a99a8-aebf-492a-ac55-fef886440b4a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-16abdc05-11bc-49ac-a8d7-456ee3280287,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5022b94e-1ec2-4b12-a5fe-e3fe9a10001a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-16abdc05-11bc-49ac-a8d7-456ee3280287,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5022b94e-1ec2-4b12-a5fe-e3fe9a10001a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-16abdc05-11bc-49ac-a8d7-456ee3280287,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5022b94e-1ec2-4b12-a5fe-e3fe9a10001a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-16abdc05-11bc-49ac-a8d7-456ee3280287,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5022b94e-1ec2-4b12-a5fe-e3fe9a10001a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-356aa7f3-1267-430c-92ca-369e65098fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-745a50a6-61b3-408b-a2bf-9eae82c13ee4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-745a50a6-61b3-408b-a2bf-9eae82c13ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-356aa7f3-1267-430c-92ca-369e65098fd0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-356aa7f3-1267-430c-92ca-369e65098fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-745a50a6-61b3-408b-a2bf-9eae82c13ee4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-745a50a6-61b3-408b-a2bf-9eae82c13ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-356aa7f3-1267-430c-92ca-369e65098fd0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-5933d307-1287-41d3-89ec-d25056e3ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1cd0ef7-fe3b-43fc-83ea-79eea7eba46d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1cd0ef7-fe3b-43fc-83ea-79eea7eba46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-5933d307-1287-41d3-89ec-d25056e3ba89,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-5933d307-1287-41d3-89ec-d25056e3ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1cd0ef7-fe3b-43fc-83ea-79eea7eba46d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1cd0ef7-fe3b-43fc-83ea-79eea7eba46d,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-5933d307-1287-41d3-89ec-d25056e3ba89,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60
v2: 5000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestFSHLog#testFindMemStoresEligibleForFlush
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f286dd02-c6d6-4e3c-90e4-3af750e4edea,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-312124db-3296-439d-8122-2c7ef1d1b779,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-312124db-3296-439d-8122-2c7ef1d1b779,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-f286dd02-c6d6-4e3c-90e4-3af750e4edea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32775,DS-f286dd02-c6d6-4e3c-90e4-3af750e4edea,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-312124db-3296-439d-8122-2c7ef1d1b779,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-312124db-3296-439d-8122-2c7ef1d1b779,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-f286dd02-c6d6-4e3c-90e4-3af750e4edea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 7284
